{
  "hash": "6662aa70d65143ed59c4b2af67391d31",
  "result": {
    "markdown": "---\ntitle: \"Ordinal scales\"\neditor_options: \n  chunk_output_type: inline\n---\n\n\n\n\n## Ordinal scales\n\nOrdinal scales are organized as rank-ordered numeric classes, with a finite number of such classes. The utilization of ordinal scales is often due to their convenience and speed of rating [@madden2007]. In plant pathological research, there are two commonly used types of ordinal scales: quantitative and qualitative [@Chiang2022].\n\n### Quantitative ordinal\n\nIn the quantitative ordinal scale, each score signifies a defined interval of the percentage scale. The most renowned quantitative ordinal scale is the Horsfall-Barratt (HB) scale, which was developed in the early 1940s when the science of plant pathology was transitioning towards more quantitative methodologies [@hebert1982]. The HB scale partitions the percentage scale into twelve successive, logarithmic-based intervals of severity ranging from 0 to 100%. The intervals increase in size from 0 to 50% and decrease from 50 to 100%.\n\n::: callout-warning\n## Controversy of the H-B scale\n\nThe divisions of the H-B scale were established on two assumptions. The first was the logarithmic relationship between the intensity of a stimulus and the subsequent sensation. The second was the propensity of a rater to focus on smaller objects when observing objects of two colors [@madden2007]. This foundation is based on the so-called Weber-Fechner law. However, there is limited experimental evidence supporting these assumptions. Current evidence indicates a linear relationship, rather than a logarithmic one, between visually estimated and actual severity [@nutter2006a]. Additionally, these authors demonstrated that raters more accurately discriminated disease severity between 25% and 50% than what the H-B scale allowed. New scale structures have been proposed to address the issues associated with the H-B scale [@liu2019; @chiang2014]. The Chiang scale follows a linear relationship with the percentage area diseased at severities greater than 10% (class 6 on the scale).\n:::\n\nLet's input the HB scale data and store as a data frame in R so we can prepare a table and a plot.\n\n\n\n\n::: {#tbl-HB .cell tbl-cap='The Horsfal-Barrat quantitative ordinal scale used as a tool for assessing plant disease severity ' hash='data-ordinal_cache/epub/tbl-HB_ce6c18786e0cd80ab9309d6017b9cf5f'}\n\n```{.r .cell-code}\nHB <- tibble::tribble(\n  ~ordinal, ~'range', ~midpoint,\n  0,          '0',    0,   \n  1,    '0+ to 3',  1.5,   \n  2,    '3+ to 6',  4.5,   \n  3,   '6+ to 12',  9.0,  \n  4,  '12+ to 25', 18.5, \n  5,  '25+ to 50', 37.5, \n  6,  '50+ to 75', 62.5, \n  7,  '75+ to 88', 81.5, \n  8,  '88+ to 94', 91.0, \n  9,  '94+ to 97', 95.5, \n  10,'97+ to 100', 98.5,  \n  11,      '100',   100 \n  )\nknitr::kable(HB, align = \"c\")\n```\n\n::: {.cell-output-display}\n| ordinal |   range    | midpoint |\n|:-------:|:----------:|:--------:|\n|    0    |     0      |   0.0    |\n|    1    |  0+ to 3   |   1.5    |\n|    2    |  3+ to 6   |   4.5    |\n|    3    |  6+ to 12  |   9.0    |\n|    4    | 12+ to 25  |   18.5   |\n|    5    | 25+ to 50  |   37.5   |\n|    6    | 50+ to 75  |   62.5   |\n|    7    | 75+ to 88  |   81.5   |\n|    8    | 88+ to 94  |   91.0   |\n|    9    | 94+ to 97  |   95.5   |\n|   10    | 97+ to 100 |   98.5   |\n|   11    |    100     |  100.0   |\n:::\n:::\n\n\n\n\nLet's visualize the different sizes of the percent interval encompassing each score.\n\n\n\n\n::: {.cell hash='data-ordinal_cache/epub/fig-hb_f29f167bd7ae55e135c0d086aef39e19'}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(tidyverse)\nlibrary(r4pde)\nHB |> \n  ggplot(aes(midpoint, ordinal))+\n  geom_point(size =2)+\n  geom_line()+\n  scale_x_continuous(breaks = c(0, 3, 6, 12, 25, 50, 75, 88, 94, 97))+\n  scale_y_continuous(breaks = c(1:12))+\n  geom_vline(aes(xintercept = 3), linetype = 2)+\n  geom_vline(aes(xintercept = 6), linetype = 2)+\n  geom_vline(aes(xintercept = 12), linetype = 2)+\n  geom_vline(aes(xintercept = 25), linetype = 2)+\n  geom_vline(aes(xintercept = 50), linetype = 2)+\n  geom_vline(aes(xintercept = 75), linetype = 2)+\n  geom_vline(aes(xintercept = 88), linetype = 2)+\n  geom_vline(aes(xintercept = 94), linetype = 2)+\n  geom_vline(aes(xintercept = 97), linetype = 2)+\n  labs(x = \"Percent severity\", y = \"HB score\")+\n  theme_r4pde()\n```\n\n::: {.cell-output-display}\n![Ordinal scores of the Horsfal-Barrat scale](data-ordinal_files/figure-epub/fig-hb-1.png){#fig-hb}\n:::\n:::\n\n\n\n\nWe can repeat those procedures to visualize the Chiang scale.\n\n\n\n\n::: {#tbl-chiang .cell tbl-cap='The Chiang quantitative ordinal scale used as a tool for assessing plant disease severity ' hash='data-ordinal_cache/epub/tbl-chiang_9b493e0eb6e8940fc3fa9f2fcba36d46'}\n\n```{.r .cell-code}\nchiang <- tibble::tribble(\n  ~ordinal, ~'range', ~midpoint,\n  0,          '0',     0,   \n  1,  '0+ to 0.1',  0.05,   \n  2,'0.1+ to 0.5',   0.3,   \n  3,  '0.5+ to 1',  0.75,  \n  4,    '1+ to 2',   1.5, \n  5,    '2+ to 5',     3, \n  6,   '5+ to 10',   7.5, \n  7,  '10+ to 20',    15, \n  8,  '20+ to 30',    25, \n  9,  '30+ to 40',    35, \n  10, '40+ to 50',    45,  \n  11, '50+ to 60',    55,\n  12, '60+ to 70',    65,\n  13, '70+ to 80',    75,\n  14, '80+ to 90',    85,\n  15,'90+ to 100',   95\n  )\nknitr::kable(chiang, align = \"c\")\n```\n\n::: {.cell-output-display}\n| ordinal |    range    | midpoint |\n|:-------:|:-----------:|:--------:|\n|    0    |      0      |   0.00   |\n|    1    |  0+ to 0.1  |   0.05   |\n|    2    | 0.1+ to 0.5 |   0.30   |\n|    3    |  0.5+ to 1  |   0.75   |\n|    4    |   1+ to 2   |   1.50   |\n|    5    |   2+ to 5   |   3.00   |\n|    6    |  5+ to 10   |   7.50   |\n|    7    |  10+ to 20  |  15.00   |\n|    8    |  20+ to 30  |  25.00   |\n|    9    |  30+ to 40  |  35.00   |\n|   10    |  40+ to 50  |  45.00   |\n|   11    |  50+ to 60  |  55.00   |\n|   12    |  60+ to 70  |  65.00   |\n|   13    |  70+ to 80  |  75.00   |\n|   14    |  80+ to 90  |  85.00   |\n|   15    | 90+ to 100  |  95.00   |\n:::\n:::\n\n::: {.cell hash='data-ordinal_cache/epub/fig-chiagn_5d54ae8bc5737d62d6c5bfff5fc73b9a'}\n\n```{.r .cell-code  code-fold=\"false\"}\nchiang |> \n  ggplot(aes(midpoint, ordinal))+\n  geom_point(size =2)+\n  geom_line()+\n  scale_y_continuous(breaks = c(0:15))+\n  scale_x_continuous(breaks = c(0, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100))+\n  geom_vline(aes(xintercept = 0), linetype = 2)+\n  geom_vline(aes(xintercept = 0.1), linetype = 2)+\n  geom_vline(aes(xintercept = 0.5), linetype = 2)+\n  geom_vline(aes(xintercept = 1), linetype = 2)+\n  geom_vline(aes(xintercept = 2), linetype = 2)+\n  geom_vline(aes(xintercept = 5), linetype = 2)+\n  geom_vline(aes(xintercept = 10), linetype = 2)+\n  geom_vline(aes(xintercept = 20), linetype = 2)+\n  geom_vline(aes(xintercept = 30), linetype = 2)+\n   geom_vline(aes(xintercept = 40), linetype = 2)+\n   geom_vline(aes(xintercept = 50), linetype = 2)+\n   geom_vline(aes(xintercept = 60), linetype = 2)+\n   geom_vline(aes(xintercept = 70), linetype = 2)+\n   geom_vline(aes(xintercept = 80), linetype = 2)+\n   geom_vline(aes(xintercept = 90), linetype = 2)+\n   geom_vline(aes(xintercept = 100), linetype = 2)+\n  labs(x = \"Percent severity\", y = \"Chiang score\")+\n  theme_r4pde()\n```\n\n::: {.cell-output-display}\n![Ordinal scores of the Chiang scale](data-ordinal_files/figure-epub/fig-chiagn-1.png){#fig-chiagn}\n:::\n:::\n\n\n\n\n### Qualitative ordinal\n\nIn the qualitative ordinal scale, each class provides a description of the symptoms. An example is the ordinal 0-3 scale for rating eyespot of wheat developed by [@scott1974].\n\n| Class | Description                                                                                                 |\n|-----------------------|------------------------------------------------|\n| 0     | uninfected                                                                                                  |\n| 1     | slight eyespot (or or more small lesion occupying in total less than half of the circumference of the stem) |\n| 2     | moderate eyespot (one or more lesions occupying at least half the circumference of the stem)                |\n| 3     | severe eyespot (stem completely girdled by lesions; tissue softened so that lodging would really occur)     |\n\n: Ordinal scale for rating eyespot of wheat [@scott1974]\n\n## Disease severity index (DSI)\n\nUsually, when quantitative or qualitative ordinal scales are used, the scores are transformed into an index on a percentage basis, such as the disease severity index (DSI) which is used in data analysis. The DSI is a single number that summarizes a large amount of information on disease severity [@chester1950]. The formula for a DSI (%) can be written as follows:\n\n$DSI = \\frac{∑(class \\ freq. \\ ✕ \\ score \\  of \\ class)} {total \\ n \\ ✕ \\ maximal \\ class} ✕ 100$\n\nThe `DSI()` and `DSI2()` are part of the *r4pde* package. Let's see how each function works.\n\nThe `DSI()` allows to automate the calculation of the disease severity index (DSI) in a series of units (e.g. leaves) that are further classified according to ordinal scores. The function requires three arguments:\n\n-   unit = the vector of the number of each unit\n\n-   class = the vector of the scores for the units\n\n-   max = the maximum value of the scale\n\nLet's create a toy data set composed of 12 units where each received an ordinal score. The vectors were arranged as a data frame named scores.\n\n\n\n\n::: {.cell hash='data-ordinal_cache/epub/unnamed-chunk-5_0b50855ecf2286e95964ae113b38d9bf'}\n\n```{.r .cell-code}\nunit <- c(1:12)\nclass <- c(2,3,1,1,3,4,5,0,2,5,2,1)\nratings <- data.frame(unit, class)\nknitr::kable(ratings)\n```\n\n::: {.cell-output-display}\n| unit| class|\n|----:|-----:|\n|    1|     2|\n|    2|     3|\n|    3|     1|\n|    4|     1|\n|    5|     3|\n|    6|     4|\n|    7|     5|\n|    8|     0|\n|    9|     2|\n|   10|     5|\n|   11|     2|\n|   12|     1|\n:::\n:::\n\n\n\n\nThe ordinal score used in this example has 6 as the maximum score. The function returns the DSI value.\n\n\n\n\n::: {.cell hash='data-ordinal_cache/epub/unnamed-chunk-6_a4ade235a3c66be608f2a635a3066a83'}\n\n```{.r .cell-code}\nlibrary(r4pde)\nDSI(ratings$unit, ratings$class, 6)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 40.27778\n```\n:::\n:::\n\n\n\n\nLet's now deal with a situation of multiple plots (five replicates) where a fixed number of 12 samples were taken and assessed using an ordinal score. Let's input the data using the `tribble()` function. Note that the data is in the wide format.\n\n\n\n\n::: {.cell hash='data-ordinal_cache/epub/unnamed-chunk-7_dc4fd2bca27bb1ac280d33323e43a406'}\n\n```{.r .cell-code}\nexp <- tibble::tribble(\n  ~rep, ~`1`, ~`2`, ~`3`, ~`4`, ~`5`, ~`6`, ~`7`, ~`8`, ~`9`, ~`10`, ~`11`,~`12`,\n  1, 2, 3, 1, 1, 3, 4, 5, 0, 2, 5, 2, 1,\n  2, 3, 4, 4, 6, 5, 4, 4, 0, 2, 1, 1, 5,\n  3, 5, 6, 6, 5, 4, 2, 0, 0, 0, 0, 2, 0,\n  4, 5, 6, 0, 0, 0, 3, 3, 2, 1, 0, 2, 3, \n  5, 0, 0, 0, 0, 2, 3, 2, 5, 6, 2, 1, 0,\n)\nknitr::kable(exp)\n```\n\n::: {.cell-output-display}\n| rep|  1|  2|  3|  4|  5|  6|  7|  8|  9| 10| 11| 12|\n|---:|--:|--:|--:|--:|--:|--:|--:|--:|--:|--:|--:|--:|\n|   1|  2|  3|  1|  1|  3|  4|  5|  0|  2|  5|  2|  1|\n|   2|  3|  4|  4|  6|  5|  4|  4|  0|  2|  1|  1|  5|\n|   3|  5|  6|  6|  5|  4|  2|  0|  0|  0|  0|  2|  0|\n|   4|  5|  6|  0|  0|  0|  3|  3|  2|  1|  0|  2|  3|\n|   5|  0|  0|  0|  0|  2|  3|  2|  5|  6|  2|  1|  0|\n:::\n:::\n\n\n\n\nAfter reshaping the data to the long format, we can calculate the DSI for each plot/replicate as follows:\n\n\n\n\n::: {.cell hash='data-ordinal_cache/epub/unnamed-chunk-8_f8d5b33f45bb6487c162ea50b2400021'}\n\n```{.r .cell-code}\nres <- exp |> \n  pivot_longer(2:13, names_to = \"unit\", values_to = \"class\") |>\n  group_by(rep) |> \n  summarise(DSI = DSI(unit, class, 6))\n```\n:::\n\n\n\n\nAnd here we have the results of the DSI for each replicate.\n\n\n\n\n::: {.cell hash='data-ordinal_cache/epub/unnamed-chunk-9_c02416c7af785038693eeb33daa35581'}\n\n```{.r .cell-code}\nknitr::kable(res, align = \"c\")\n```\n\n::: {.cell-output-display}\n| rep |   DSI    |\n|:---:|:--------:|\n|  1  | 40.27778 |\n|  2  | 54.16667 |\n|  3  | 41.66667 |\n|  4  | 34.72222 |\n|  5  | 29.16667 |\n:::\n:::\n\n\n\n\nNow our data set is organized as the frequency of each class as follows:\n\n\n\n\n::: {.cell hash='data-ordinal_cache/epub/unnamed-chunk-10_fb03db78206512effc7ec9996a287f39'}\n\n```{.r .cell-code}\nratings2 <- ratings |> \n  dplyr::count(class)\n\nratings2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  class n\n1     0 1\n2     1 3\n3     2 3\n4     3 2\n5     4 1\n6     5 2\n```\n:::\n:::\n\n\n\n\nNow we can apply the `DSI2()` function. The function requires three arguments:\n\n-   class = the number of the respective class\n-   freq = the frequency of the class\n-   max = the maximum value of the scale\n\n\n\n\n::: {.cell hash='data-ordinal_cache/epub/unnamed-chunk-11_332c2404450b77481be25fed04215dda'}\n\n```{.r .cell-code}\nlibrary(r4pde)\nDSI2(ratings2$class, ratings2$n, 6)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 40.27778\n```\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}