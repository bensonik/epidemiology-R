{
  "hash": "9d854ca0d7539d9e85c23bc4f562b1e7",
  "result": {
    "markdown": "---\ntitle: \"Image analysis\"\n---\n\n\n## The actual severity measure\n\nAmong the various methods to express plant disease severity, the percent area affected (or symptomatic) by the disease is one of the most common, especially when dealing with diseases that affect leaves. In order to evaluate whether visual estimates of plant disease severity are sufficiently accurate (as discussed in the previous chapter), one requires the actual severity values. These are also essential when creating Standard Area Diagrams (SADs), which are diagrammatic representations of severity values used as a reference either before or during visual assessment to standardize and produce more accurate results across different raters [@delponte2017].\n\nThe actual severity values are typically approximated using image analysis, wherein the image is segmented, and each pixel is categorized into one of three classes:\n\n1. Diseased (or symptomatic)\n2. Non-diseased (or healthy)\n3. Background (the non-plant portion of the image)\n\nThe ratio of the diseased area to the total area of the unit (e.g., the entire plant organ or section of the image) yields the proportion of the diseased area, or the percent area affected (when multiplied by 100). Researchers have employed various proprietary or open-source software to determine the actual severity, as documented in a review on Standard Area Diagrams [@delponte2017].\n\nIn this section, we will utilize the `measure_disease()` function from the *pliman* (Plant IMage ANalysis) R package [@olivoto2022a] to measure the percent area affected. The package was compared with other software for determining plant disease severity across five different plant diseases and was shown to produce accurate results in most cases [@olivoto2022].\n\nThere are essentially two methods to measure severity. The first is predicated on image palettes that define each class of the image. The second relies on RGB-based indices [@alves2021]. Letâ€™s explore the first method, as well as an interactive approach to setting color palettes.\n\n## Image palettes\n\nhe most crucial step is the initial one, where the user needs to correctly define the color palettes for each class. In pliman, the palettes are separate images representing each of the three classes: background (b), symptomatic (s), and healthy (h).\n\nThe reference image palettes can be constructed by manually sampling small areas of the image and creating a composite image. Naturally, the results may vary depending on how these areas are selected. A study that validated pliman for determining disease severity demonstrated the effect of different palettes prepared independently by three researchers [@olivoto2022]. During the calibration of the palettes, examining the processed masks is crucial to create reference palettes that are the most representative of the respective class.\n\nIn this example, I manually selected and pasted several sections of images representing each class from a few leaves into a Google slide. Once the image palette was ready, I exported each one as a separate PNG image file (JPG also works). These files were named: sbr_b.png, sbr_h.png, and sbr_s.png. They can be found [here in this folder](https://github.com/emdelponte/epidemiology-R/tree/main/imgs) for downloading.\n\n[![Preparation of image palettes by manually sampling fraction of the images that represent background, heatlhy leaf and lesions](imgs/pliman1.png){#fig-pliman1 style=\"margin: 15px\" fig-align=\"center\"}](Fig_palettes)\n\nNow that we have the image palettes, we need to import them into the environment, using `image_import()` function for further analysis. Let's create an image object for each palette named h (healthy), s (symptoms) and b (background).\n\n\n::: {.cell hash='data-actual-severity_cache/html/unnamed-chunk-1_b598b97d359cac503ca53b51504aa206'}\n\n```{.r .cell-code}\nlibrary(pliman)\nh <- image_import(\"imgs/sbr_h.png\")\ns <- image_import(\"imgs/sbr_s.png\")\nb <- image_import(\"imgs/sbr_b.png\")\n```\n:::\n\n\nWe can visualize the imported image palettes using the `image_combine()` function.\n\n\n::: {.cell hash='data-actual-severity_cache/html/fig-palettes_d4183d2ef6b41ac34c7060309e0ecdb0'}\n\n```{.r .cell-code}\nimage_combine(h, s, b, ncol =3)\n```\n\n::: {.cell-output-display}\n![Image palettes created to segment images into background, sypomtoms and healthy area of the image](data-actual-severity_files/figure-html/fig-palettes-1.png){#fig-palettes width=672}\n:::\n:::\n\n\n## Measuring severity\n\n### Single image\n\nTo determine severity in a single image (e.g. img46.png), the image file needs to be loaded and assigned to an object using the same `image_import()` function used to load the palettes. We can then visualize the image, again using `image_combine()`.\n\n::: callout-tip\nThe collection of images used in this chapter can be found [here](https://github.com/emdelponte/epidemiology-R/tree/main/imgs/originals).\n:::\n\n\n::: {.cell hash='data-actual-severity_cache/html/fig-img_e87c623f9a26c3acce6b42891c64591b'}\n\n```{.r .cell-code}\nimg <- image_import(\"imgs/originals/img46.png\")\nimage_combine(img)\n```\n\n::: {.cell-output-display}\n![Imported image for further analysis](data-actual-severity_files/figure-html/fig-img-1.png){#fig-img width=672}\n:::\n:::\n\n\nNow the engaging part starts with the `measure_disease()` function. Four arguments are required when using the reference image palettes: the image representing the target image and the three images of the color palettes. As the author of the package states, \"pliman will take care of all the details!\" The severity is the value displayed under 'symptomatic' in the output.\n\n\n::: {.cell hash='data-actual-severity_cache/html/unnamed-chunk-4_cc40258b7578c8dbed8eae720cd31967'}\n\n```{.r .cell-code}\nset.seed(123)\nmeasure_disease(\n  img = img,\n  img_healthy = h,\n  img_symptoms = s,\n  img_background = b\n)\n```\n\n::: {.cell-output-display}\n![](data-actual-severity_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n$severity\n   healthy symptomatic\n1 92.68077    7.319234\n\n$shape\nNULL\n\n$statistics\nNULL\n\nattr(,\"class\")\n[1] \"plm_disease\"\n```\n:::\n:::\n\n\n### Multiple images\n\nMeasuring severity in single images is indeed engaging, but we often deal with multiple images, not just one. Using the above procedure to process each image individually would be time-consuming and potentially tedious.\n\nTo automate the process, *pliman* offers a batch processing approach. Instead of using the `img` argument, one can use the `pattern` argument and define the prefix of the image names. Moreover, we also need to specify the directory where the original files are located.\n\nIf the user wants to save the processed masks, they should set the `save_image` argument to TRUE and also specify the directory where the images will be saved. Here's an example of how to process 10 images of soybean rust symptoms. The output is a `list` object with the measures of the percent healthy and percent symptomatic area for each leaf in the `severity` object.\n\n\n::: {.cell hash='data-actual-severity_cache/html/unnamed-chunk-5_e7ab2c8fa9316d4ba7fa50323bd56822'}\n\n```{.r .cell-code}\npliman <- measure_disease(\n  pattern = \"img\",\n  dir_original = \"imgs/originals\" ,\n  dir_processed = \"imgs/processed\",\n  save_image = TRUE,\n  img_healthy = h,\n  img_symptoms = s,\n  img_background = b\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nProcessing image img11 |====                                     | 10% 00:00:00 \n```\n:::\n\n::: {.cell-output-display}\n![](data-actual-severity_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nProcessing image img35 |========                                 | 20% 00:00:03 \n```\n:::\n\n::: {.cell-output-display}\n![](data-actual-severity_files/figure-html/unnamed-chunk-5-2.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nProcessing image img37 |============                             | 30% 00:00:04 \n```\n:::\n\n::: {.cell-output-display}\n![](data-actual-severity_files/figure-html/unnamed-chunk-5-3.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nProcessing image img38 |================                         | 40% 00:00:05 \n```\n:::\n\n::: {.cell-output-display}\n![](data-actual-severity_files/figure-html/unnamed-chunk-5-4.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nProcessing image img46 |====================                     | 50% 00:00:06 \n```\n:::\n\n::: {.cell-output-display}\n![](data-actual-severity_files/figure-html/unnamed-chunk-5-5.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nProcessing image img5 |=========================                 | 60% 00:00:08 \n```\n:::\n\n::: {.cell-output-display}\n![](data-actual-severity_files/figure-html/unnamed-chunk-5-6.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nProcessing image img63 |=============================            | 70% 00:00:11 \n```\n:::\n\n::: {.cell-output-display}\n![](data-actual-severity_files/figure-html/unnamed-chunk-5-7.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nProcessing image img67 |=================================        | 80% 00:00:14 \n```\n:::\n\n::: {.cell-output-display}\n![](data-actual-severity_files/figure-html/unnamed-chunk-5-8.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nProcessing image img70 |=====================================    | 90% 00:00:16 \n```\n:::\n\n::: {.cell-output-display}\n![](data-actual-severity_files/figure-html/unnamed-chunk-5-9.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nProcessing image img75 |=========================================| 100% 00:00:17 \n```\n:::\n\n::: {.cell-output-display}\n![](data-actual-severity_files/figure-html/unnamed-chunk-5-10.png){width=672}\n:::\n\n```{.r .cell-code}\nseverity <- pliman$severity\nseverity\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     img  healthy symptomatic\n1  img11 70.79655  29.2034481\n2  img35 46.94177  53.0582346\n3  img37 60.47440  39.5256013\n4  img38 79.14060  20.8594011\n5  img46 93.14958   6.8504220\n6   img5 20.53175  79.4682534\n7  img63 97.15669   2.8433141\n8  img67 99.83720   0.1627959\n9  img70 35.56684  64.4331583\n10 img75 93.04453   6.9554686\n```\n:::\n:::\n\n\nWhen the argument `save_image` is set to TRUE, the images are all saved in the folder with the standard prefix \"proc.\"\n\n[![Images created by pliman and exported to a specific folder](imgs/pliman2.png){#fig-pliman2 style=\"margin: 15px\" fig-align=\"center\"}](fig_folder)\n\nLet's have a look at one of the processed images.\n\n[![Figure created by pliman after batch processing to segment the images and calculate percent area covered by symptoms. The symptomatic area is delinated in the image.](imgs/processed/proc_img46.jpg){#fig-processed style=\"margin: 15px\" fig-align=\"center\" width=\"452\"}](fig_proc1)\n\n## How good are these measurements?\n\nThese 10 images were previously processed in QUANT software for measuring severity which is also based on image threshold. Let's create a tibble for the image code and respective \"actual\" severity - assuming QUANT measures as reference.\n\n\n::: {.cell hash='data-actual-severity_cache/html/unnamed-chunk-6_c48e27f95b2b90a50c2c17cd92cdfca1'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nquant <- tribble(\n  ~img, ~actual,\n   \"img5\",     75,\n  \"img11\",     24,\n  \"img35\",     52,\n  \"img37\",     38,\n  \"img38\",     17,\n  \"img46\",      7,\n  \"img63\",    2.5,\n  \"img67\",   0.25,\n  \"img70\",     67,\n  \"img75\",     10\n  )\n```\n:::\n\n\nWe can now combine the two dataframes and produce a scatter plot relating the two measures.\n\n\n::: {.cell hash='data-actual-severity_cache/html/fig-scatter_fdcd33663f842c8abb6ae470618c58c0'}\n\n```{.r .cell-code}\ndat <- left_join(severity, quant)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(img)`\n```\n:::\n\n```{.r .cell-code}\ndat %>%\n  ggplot(aes(actual, symptomatic)) +\n  geom_point(size = 3, shape = 16, color = \"gray20\") +\n  ylim(0, 100) +\n  xlim(0, 100) +\n  geom_abline(slope = 1, intercept = 0) +\n  labs(x = \"Quant\",\n       y = \"pliman\")\n```\n\n::: {.cell-output-display}\n![Scatter plot for the relationship between severity values measured by pliman and Quant software](data-actual-severity_files/figure-html/fig-scatter-1.png){#fig-scatter width=672}\n:::\n:::\n\n\nThe concordance correlation coefficient is a test for agreement between two observers or two methods (see previous chapter). It is an indication of how accurate the *pliman* measures are compared with a standard. The coefficient is greater than 0.99 (1.0 is perfect concordance), suggesting an excellent agreement!\n\n\n::: {.cell hash='data-actual-severity_cache/html/unnamed-chunk-8_ae361bd07a4c75acc60a044b3c0658de'}\n\n```{.r .cell-code}\nlibrary(epiR)\nccc <- epi.ccc(dat$actual, dat$symptomatic)\nccc$rho.c\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        est     lower     upper\n1 0.9940835 0.9774587 0.9984566\n```\n:::\n:::\n\n\nIn conclusion, as mentioned earlier, the most critical step is defining the reference image palettes. A few preliminary runs may be necessary for some images to ensure that the segmentation is being carried out correctly, based on visual judgment. This is not different from any other color-threshold based methods, where the choices made by the user impact the final result and contribute to variation among assessors. The drawbacks are the same as those encountered with direct competitors, namely, the need for images to be taken under uniform and controlled conditions, especially with a contrasting background.\n\n## Creating palettes interactively\n\nPliman offers another function `measure_disease_iter()` which allows the user to pick up samples in the image to create the color palettes for each required class (background, healthy and symptoms). Check the video below.\n\n\n{{< video https://www.youtube.com/embed/fI_Mm-GlPyw >}}\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}