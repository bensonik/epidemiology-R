[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R4PDE",
    "section": "",
    "text": "Welcome\nR for Plant Disease Epidemiology (R4PDE) is a dynamic book project rooted in the teachings of the annual graduate course, FIP 602 - Plant Disease Epidemiology, a key part of the curriculum in the Graduate Program in Plant Pathology at Universidade Federal de Viçosa.\nDesigned for those passionate about studying and modeling plant disease epidemics with R, the book offers an exploration of diverse methods for describing, visualizing, and analyzing epidemic data collected over time or space. Readers should ideally have a foundational knowledge of R to best utilize the examples.\nHowever, R4PDE is not a resource for learning data science through R, there are already well-established books such as R for data science for that purpose. Portuguese-speaking readers are recommended Análises Ecológicas no R and Software R para avaliação de dados experimentais as excellent R learning resources, with an added focus on statistics using R.\nThe book often draws upon data and replicates analyses from The Study of Plant Disease Epidemics (Madden et al. 2017). A mix of general and specific R packages are utilized to conduct common plant disease epidemiology data analysis, notably epifitter and epiphy, both designed by plant pathologists. In conjunction with this book, a new R package r4pde has been developed and can be installed from GitHub using:\nAs a work in progress, the book is frequently updated and edited. The website is free to use, licensed under a Creative Commons licence, and the code for all analyses can be found on GitHub. While there are no immediate plans for a printed version, it is under consideration as the book further develops. The website is hosted by https://www.netlify.com/.\nContributions to R4PDE are subject to a Contributor Code of Conduct, and by contributing, you agree to adhere to its terms."
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "R4PDE",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nTo Helen Pennington for allowing me to use her painting of coffee leaf rust as book cover. Also to those who have contributed fixes and improvements via pull request or other form of contact: Adam Sparks (@adamhsparks), Remco Stam (@remco-stam)\n\n\n\n\nMadden, L. V., Hughes, G., and van den Bosch, F. 2017. The study of plant disease epidemics. The American Phytopathological Society. Available at: http://dx.doi.org/10.1094/9780890545058."
  },
  {
    "objectID": "author.html",
    "href": "author.html",
    "title": "About the author",
    "section": "",
    "text": "Emerson M. Del Ponte is a Professor at the Departamento de Fitopatologia, Universidade Federal de Viçosa in Brazil. His academic journey includes a DSc in Plant Pathology, obtained from Universidade Federal de Pelotas in 2004, and a year-long visit to Cornell University in the Bergstrom Lab. Following this, he spent nearly two years as a postdoctoral associate working on a project related to disease risk assessment and prediction at the Yang Lab, Iowa State University. This experience led him to the Universidade Federal do Rio Grande do Sul, Brazil, where he joined as an assistant professor of plant pathology.\nEmerson Del Ponte is a fervent advocate for an open and reproducible research model and culture, which he believes can lead to more accessible, transparent, and reliable scientific knowledge. This belief inspired him co-founding the Open Plant Pathology initiative alongside Adam Sparks. In his Lab, students use the R language for all statistics and data science-related activities. All data and computational codes generated during the research are made accessible before the peer-review process. The code can be located on GitHub."
  },
  {
    "objectID": "intro.html#defining-plant-disease",
    "href": "intro.html#defining-plant-disease",
    "title": "1  Introduction",
    "section": "1.1 Defining plant disease",
    "text": "1.1 Defining plant disease\nDisease in plants can be defined as any malfunctioning of host cells and tissues that results from continuous irritation by a pathogenic agent or environmental factor and leads to development of symptoms (Agrios 2005a). When caused by pathogenic agent, the disease results from the combination of three elements: susceptible host plant, a virulent pathogen, and favorable environmental conditions - the famous disease triangle. When a pathogen population establishes and causes disease in a host population, the phenomenon is called an epidemic, or the disease in populations. Among several definitions of epidemic, a comprehensive one is the change in disease intensity in a host population over time and space (Madden et al. 2017).\nThere exist numerous iterations of the disease triangle, incorporating additional elements (e.g., human intervention and time) as points and/or dimensions to provide a more comprehensive representation of an epidemic (Agrios 2005b). We find the disease prism particularly illustrative, where a sequence of stacked triangles represent the evolution of a plant disease through time (Francl 2001).\n\n\n\nFigure 1.1: The plant disease prism as a model of plant disease epidemics"
  },
  {
    "objectID": "intro.html#importance-of-epidemics",
    "href": "intro.html#importance-of-epidemics",
    "title": "1  Introduction",
    "section": "1.2 Importance of epidemics",
    "text": "1.2 Importance of epidemics\nEpidemics bear significant economic importance due to their potential to decrease crop yields, diminish product quality, and escalate control costs, contingent on their intensity level. Numerous historical examples of widespread epidemics, reaching pandemic levels and resulting in catastrophic effects on crops, have been documented (Agrios 2005b). The Irish potato famine of 1845–1847, caused by the late blight pathogen (Phytophthora infestans), is a famous example of a well-documented pandemic. This disease notably altered the course of history in Europe and the United States, and was pivotal in the evolution of the science of plant pathology. During the 1840s, the pathogen ravaged potato crops, which were a dietary staple for the Irish. The disease outbreak was triggered by the introduction of a novel, virulent pathogen population that found suitable environmental conditions (cool and wet weather) for infection and development within a dense population of susceptible hosts.\nHowever, there are several reasons why devastating epidemics may continue to unfold. Recent history has seen severe epidemics reaching pandemic levels due to the incursion of pathogens into regions where they had previously been absent (refer to Box 1). Alternatively, new pathogenic strains might emerge as a result of factors driving genetic diversity within the local pathogen population. A case in point is the Ug99 strain of the wheat stem rust, which poses a significant threat to global wheat production. First identified in Uganda in 1998, an asexual lineage has propagated through Africa and the Middle East, causing catastrophic epidemics. Research suggests that Ug99 emerged via somatic hybridization and nuclear exchange between isolates from different lineages (Li et al. 2019). Finally, disease emergence or re-emergence can be influenced by shifts in climatic patterns. For instance, the Fusarium head blight of wheat caused by the fungus Fusarium graminearum. In Southern Brazil, the increased frequency of severe epidemics resulting in greater yield loss since the early 1990s has been linked to alterations in rainfall patterns across decades (Duffeck et al. 2020).\n\n\n\n\n\n\nBox 1: Diseases on the move\n\n\n\nIn Brazil, the soybean rust pathogen (Phakopsora pachyrhizi) first reached southern Brazil in 2002 (Yorinori et al. 2005). The disease spread to all production regions of the country in the following few years, severely reducing yields. To overcome the problem, farmers have relied on massive applications of fungicides on soybeans, which dramatically increased the production costs with the need for sequential fungicide sprays to combat the disease. Total economic loss have been estimated at around US$ 2 billion yearly (Godoy et al. 2016). More recently, wheat blast, a disease that originated in the south of Brazil in 1984, and have been restricted to South America, was firstly spotted in South Asia, Bangladesh, in 2016. Blast epidemics in that occasion devastated more than 15,000 ha of wheat and reduced yield of wheat in the affected field up to 100% (Malaker et al. 2016; Islam et al. 2019). The disease was later found in Zambia, thus also becoming a threat to wheat production in Africa (Tembo et al. 2020). In Brazil, the wheat blast disease is a current threat to expansion of wheat cultivation in the tropics(Cruz and Valent 2017)."
  },
  {
    "objectID": "intro.html#history-of-epidemiology",
    "href": "intro.html#history-of-epidemiology",
    "title": "1  Introduction",
    "section": "1.3 History of Epidemiology",
    "text": "1.3 History of Epidemiology\nBotanical epidemiology, or the study of plant disease epidemics, is a discipline with roots tracing back to the early 1960s. However, its origins can be linked to events from centuries and decades prior. For instance, in 1728, Duhamel de Monceau presented the earliest known epidemiological work on a disease, referred to as ‘Death,’ that afflicted saffron crocus (Rhizoctonia violacea). Fast forward to 1858, a textbook detailing plant diseases, written by Julius Kuhn, made its debut, introducing the concept of an epidemic as illustrated by the Irish late blight epidemics of 1845-46. Subsequently, in 1901, H.M. Ward adopted an ecological perspective to the study of plant diseases in his seminal book, Disease in Plants. By 1946, Gäumann penned the first book exclusively devoted to plant disease epidemiology.\nFurther evolution of this field was marked by the publication of a chapter titled “Analysis of Epidemics” by J.E. Vanderplank in Plant Pathology, vol. 3, edited by Horsfall and Dimond, in 1960. Vanderplank elaborated on his pioneering ideas in his 1963 book, “Plant Diseases: Epidemics and Control”(Vanderplank 1963). He is universally recognized as the foundational figure of plant disease epidemiology (Zadoks and Schein 1988; Thresh 1998), his landmark book being the first to comprehensively describe and quantify plant disease epidemics, and offering a theoretical framework for epidemic analysis.\nIn the same year, the first International Epidemiology Workshop was convened in Pau, France. This event constitutes an important milestone in the historical narrative, significantly contributing to the molding of this emergent discipline.\n\n\n\nFigure 1.2: Group photo of the First International Epidemiology Workshop\n\n\nThe International Epidemiology Workshop (IEW) is the principal working group of plant disease epidemiology. This is an organization with a rich history whose members have met approximately every 5 years since 1963. Thus far, 13 meetings have been organized/planned:\n1963 - Pau, France\n1971 - Wageningen, The Netherlands\n1979 - Penn State, United States\n1983 - NC State, Raleigh, United States\n1986 - Jerusalem, Israel\n1990 - Giessen, Germany\n1994 - Papendal, The Netherlands\n2001 - Ouro Preto, Brazil\n2005 - Landerneau, France\n2009 - Cornell, Geneva, United States\n2013 - Beijing, China\n2018 - Lillehammer, Norway\n2024 - Iguassu Falls, Brazil"
  },
  {
    "objectID": "intro.html#other-resources",
    "href": "intro.html#other-resources",
    "title": "1  Introduction",
    "section": "1.4 Other resources",
    "text": "1.4 Other resources\n\n1.4.1 Books\n2006 - The Epidemiology of Plant Diseases\n2007 - The Study of Plant Disease Epidemics\n2017 - Exercises in Plant Disease Epidemiology\n2017 - Application of Information Theory to Epidemiology\n2020 - Emerging Plant Diseases and Global Security\n\n\n\n1.4.2 Online tutorials\nEcology and Epidemiology in R\nPlant Disease Epidemiology - Temporal aspects\nSimulation Modeling in Plant Disease Epidemiology and Crop Loss Analysis\n\n\n1.4.3 Software\nEpicrop - Simulation Modeling of Crop Diseases using a SEIR model\n\n\n\n\nAgrios, G. N. 2005a. INTRODUCTION. In Elsevier, p. 3–75. Available at: http://dx.doi.org/10.1016/b978-0-08-047378-9.50007-5.\n\n\nAgrios, G. N. 2005b. Plant disease epidemiology. In Elsevier, p. 265–291. Available at: http://dx.doi.org/10.1016/b978-0-08-047378-9.50014-2.\n\n\nCruz, C. D., and Valent, B. 2017. Wheat blast disease: danger on the move. Tropical Plant Pathology. 42:210–222 Available at: http://dx.doi.org/10.1007/s40858-017-0159-z.\n\n\nDuffeck, M. R., Santos Alves, K. dos, Machado, F. J., Esker, P. D., and Del Ponte, E. M. 2020. Modeling Yield Losses and Fungicide Profitability for Managing Fusarium Head Blight in Brazilian Spring Wheat. Phytopathology®. 110:370–378 Available at: http://dx.doi.org/10.1094/PHYTO-04-19-0122-R.\n\n\nFrancl, L. J. 2001. The..disease triangle: A plant pathological paradigm revisited. The Plant Health Instructor. Available at: http://dx.doi.org/10.1094/PHI-T-2001-0517-01.\n\n\nGodoy, C. V., Seixas, C. D. S., Soares, R. M., Marcelino-Guimarães, F. C., Meyer, M. C., and Costamilan, L. M. 2016. Asian soybean rust in brazil: Past, present, and future. Pesquisa Agropecuária Brasileira. 51:407–421 Available at: http://dx.doi.org/10.1590/S0100-204X2016000500002.\n\n\nIslam, M. T., Kim, K.-H., and Choi, J. 2019. Wheat Blast in Bangladesh: The Current Situation and Future Impacts. The Plant Pathology Journal. 35:1–10 Available at: http://dx.doi.org/10.5423/ppj.rw.08.2018.0168.\n\n\nLi, F., Upadhyaya, N. M., Sperschneider, J., Matny, O., Nguyen-Phuc, H., Mago, R., et al. 2019. Emergence of the Ug99 lineage of the wheat stem rust pathogen through somatic hybridisation. Nature Communications. 10 Available at: http://dx.doi.org/10.1038/s41467-019-12927-7.\n\n\nMadden, L. V., Hughes, G., and van den Bosch, F. 2017. The study of plant disease epidemics. The American Phytopathological Society. Available at: http://dx.doi.org/10.1094/9780890545058.\n\n\nMalaker, P. K., Barma, N. C. D., Tiwari, T. P., Collis, W. J., Duveiller, E., Singh, P. K., et al. 2016. First Report of Wheat Blast Caused by Magnaporthe oryzae Pathotype triticum in Bangladesh. Plant Disease. 100:2330–2330 Available at: http://dx.doi.org/10.1094/pdis-05-16-0666-pdn.\n\n\nTembo, B., Mulenga, R. M., Sichilima, S., M’siska, K. K., Mwale, M., Chikoti, P. C., et al. 2020. Detection and characterization of fungus (Magnaporthe oryzae pathotype Triticum) causing wheat blast disease on rain-fed grown wheat (Triticum aestivum L.) in Zambia ed. Zonghua Wang. PLOS ONE. 15:e0238724 Available at: http://dx.doi.org/10.1371/journal.pone.0238724.\n\n\nThresh, J. M. 1998. In memory of James Edward Vanderplank 19091997. Plant Pathology. 47:114–115 Available at: http://dx.doi.org/10.1046/j.1365-3059.2998.00220.x.\n\n\nVanderplank, J. 1963. Plant disease epidemics and control. Elsevier. Available at: http://dx.doi.org/10.1016/C2013-0-11642-X.\n\n\nYorinori, J. T., Paiva, W. M., Frederick, R. D., Costamilan, L. M., Bertagnolli, P. F., Hartman, G. E., et al. 2005. Epidemics of Soybean Rust (Phakopsora pachyrhizi) in Brazil and Paraguay from 2001 to 2003. Plant Disease. 89:675–677 Available at: http://dx.doi.org/10.1094/PD-89-0675.\n\n\nZadoks, J. C., and Schein, R. D. 1988. James Edward Vanderplank: Maverick* and Innovator. Annual Review of Phytopathology. 26:31–37 Available at: http://dx.doi.org/10.1146/annurev.py.26.090188.000335."
  },
  {
    "objectID": "data-terminology.html#disease-quantification",
    "href": "data-terminology.html#disease-quantification",
    "title": "2  Disease variables",
    "section": "2.1 Disease quantification",
    "text": "2.1 Disease quantification\nStudies on the temporal progression or spatial spread of epidemics cannot be conducted without field-collected data, or, in some cases, simulated data. The study of plant disease quantification, termed Phytopathometry, is a subdivision of plant pathology concerned with the science of disease measurement. It has strong ties to the field of epidemiology (Bock et al. 2021).\nTraditionally, disease quantification has been executed through visual evaluation. However, the past few decades have witnessed significant advancements in imaging and remote sensing technologies (which don’t necessitate contact with the object), leaving a profound impact on this field. As such, disease quantity can now be gauged through estimation (visually, by the human eye) or measurement (through remote sensing technologies such as RGB, MSI, and HSI) Figure 2.1.\nWhile the utilization of digital or remote sensing technology for disease measurement or estimation provides a more objective approach, visual assessment is largely subjective. It is known to vary among human raters, as these raters differ in their innate abilities, training, and how they are influenced by the chosen method (e.g., scales). Disease is estimated or measured on a specimen within a population, or on a sample of specimens drawn from that population. The specimen in question can be a plant organ, an individual plant, a group of plants, a field, or a farm. The specific specimen type also determines the terminology used to describe disease quantity.\n\n\n\nFigure 2.1: Different approaches used to obtain estimates or measures of plant disease. RGB = red, green, blue; MSI = multispectral imaging; HSI = hyperspectral imaging.\n\n\ninally, while developing new or refining existing disease assessment methods, it is crucial to evaluate the reliability of the assessments made by different raters or instruments, as well as their accuracy—specifically, how close the estimations or measurements are to the reference (or gold standard) values. Several methods are available for assessing the reliability, precision, and accuracy of these estimates or measurements (see definitions). The choice of methods depends on the objective of the work, but largely on the type or nature of the data. These considerations will be further discussed."
  },
  {
    "objectID": "data-terminology.html#disease-variables",
    "href": "data-terminology.html#disease-variables",
    "title": "2  Disease variables",
    "section": "2.2 Disease variables",
    "text": "2.2 Disease variables\nA common term used to reference the quantity of disease, irrespective of how it is expressed, is ‘disease intensity’. This term, however, has minimal practical value as it only implies that the disease is more or less “intense”. We require more specific terminology to standardize the reference to disease quantity and methodology. One of the primary tasks in disease assessment is classifying each specimen, often in a sample or within a population, as diseased or not diseased. This binary (yes/no or 1/0) evaluation may sufficiently express disease intensity if the goal is to ascertain the number or proportion of diseased specimens in a sample or a population.\nThis discussion brings us to two terms: disease incidence and prevalence. Incidence is typically used to denote the proportion or number (count) of plants (or their organs) deemed as observational units at the field scale or below. On the other hand, prevalence refers to the proportion or number of fields or farms with diseased plants within a larger production area or region (Nutter et al. 2006) Figure 2.2. Therefore, prevalence is analogous to incidence, with the only difference being the spatial scale of the sampling unit.\n\n\n\nFigure 2.2: Schematic representation of how prevalence and incidence of plant diseases are calculated depending on the spatial scale of the assessment\n\n\nIn many instances, it’s necessary to determine the degree to which a specimen is diseased, a concept defined as disease severity. In certain contexts, severity is narrowly defined as the proportion of the unit that exhibits symptoms (Nutter et al. 2006). However, a more expansive view of severity includes additional metrics such as nominal or ordinal scores, lesion count, and percent area affected (ratio scale). Ordinal scales are broken down into rank-ordered classes (see specific section), defined based on either a percentage scale or descriptions of symptoms (Bock et al. 2021). Occasionally, disease is expressed in terms of (average) lesion size or area, which could be regarded as a measure of severity. These variables represent different levels of measurements that provide varying degrees of information about the disease quantity - from low (nominal scale) to high (ratio scale) Figure 2.3.\n\n\n\nFigure 2.3: Scales and associated levels of measurement used to describe severity of plant diseases"
  },
  {
    "objectID": "data-terminology.html#data-types",
    "href": "data-terminology.html#data-types",
    "title": "2  Disease variables",
    "section": "2.3 Data types",
    "text": "2.3 Data types\nThe data used to express disease as incidence or any form of severity measurements can be discrete or continuous in nature.\nDiscrete variables are countable (involving integers) at a particular point in time. In other words, only a finite number of values (nominal or ordinal) is possible, and these cannot be subdivided. For instance, a plant or plant part can be either diseased or not diseased (nominal data). It’s not possible to count 1.5 diseased plants. Furthermore, a plant classified as diseased may exhibit a certain number of lesions (count data), or be categorized into a specific severity class (ordinal data, common in ordinal scales, e.g., 1-9). Disease data in the form of counts often relates to the number of infections per sampling units. Most commonly, these counts refer to the assessed pathogen population, such as the number of airborne or soilborne propagules.\nIn contrast to discrete variables, continuous variables can be measured on a scale and can assume any numeric value between two points. For example, the size of a lesion on a plant can be measured at a very precise scale (cm or mm). An estimate of severity on a percent scale (% diseased area) can take any value between non-zero and 100%. Although incidence at the individual level is discrete, at the sample level it can be treated as continuous, as it can assume any value in proportion or percentage.\nDisease variables can also be characterized by a statistical distribution, which are models that provide the probability of a specific value (or a range of values) being drawn from a particular distribution. Understanding statistical or mathematical distributions is a crucial step in improving our grasp of data collection methods, experiment design, and data analysis processes such as data summarization or hypothesis testing."
  },
  {
    "objectID": "data-terminology.html#statistical-distributions-and-simulation",
    "href": "data-terminology.html#statistical-distributions-and-simulation",
    "title": "2  Disease variables",
    "section": "2.4 Statistical distributions and simulation",
    "text": "2.4 Statistical distributions and simulation\n\n2.4.1 Binomial distribution\nFor incidence (and prevalence), the data is binary at the individual level, as there are only two possible outcomes in a trial: the plant or plant part is disease or not diseased. The statistical distribution that best describe the incidence data at the individual level is the binomial distribution.\nLet’s simulate the binomial outcomes for a range of probabilities in a sample of 100 units, using the rbinom() function in R. For a single trial (e.g., status of plants in a single plant row), the size argument is set to 1.\n\nlibrary(tidyverse)\ntheme_set(theme_gray()) # set global theme\n\nset.seed(123) # for reproducibility\nP.1 &lt;- rbinom(100, size = 1, prob = 0.1)\nP.3 &lt;- rbinom(100, size = 1, prob = 0.3)\nP.7 &lt;- rbinom(100, size = 1, prob = 0.7)\nP.9 &lt;- rbinom(100, size = 1, prob = 0.9)\nbinomial_data &lt;- data.frame(P.1, P.3, P.7, P.9)\n\nWe can then visualize the plots.\n\nbinomial_data |&gt;\n  pivot_longer(1:4, names_to = \"P\",\n               values_to = \"value\") |&gt;\n  ggplot(aes(value)) +\n  geom_histogram(fill = \"#339966\",\n                 bins = 10) +\n  facet_wrap( ~ P) \n\n\n\n\nFigure 2.4: Binomial distribution to describe binary data\n\n\n\n\n\n\n2.4.2 Beta distribution\nIn many studies, it’s often useful to express these quantities as a proportion of the total population or sample size, rather than absolute numbers. This helps standardize the data, making it easier to compare between different populations or different time periods.\nFor example, if we’re studying a plant disease, we could express disease incidence as the proportion of plants that are newly diseased during a given time period. Similarly, disease severity could be expressed as the proportion of each plant’s organ area that is affected by the disease. These proportions are ratio variables, as they can take on any value between 0 and 1, and ratios of these variables are meaningful.\nThe Beta distribution is a probability distribution that is defined between 0 and 1, which makes it ideal for modeling data that represents proportions. It’s a flexible distribution, as its shape can take many forms depending on the values of its two parameters, often denoted as alpha and beta.\nLet’s simulate some data using the rbeta() function.\n\nbeta1.5 &lt;- rbeta(n = 1000, shape1 = 1, shape2 = 5)\nbeta5.5 &lt;- rbeta(n = 1000, shape1 = 5, shape2 = 5)\nbeta_data &lt;- data.frame(beta1.5, beta5.5)\n\nNotice that there are two shape parameters in the beta distribution: shape1 and shape2 to be defined. This makes the distribution very flexible and with different potential shapes as we can see below.\n\nbeta_data |&gt;\n  pivot_longer(1:2, names_to = \"P\",\n               values_to = \"value\") |&gt;\n  ggplot(aes(value)) +\n  geom_histogram(fill = \"#339966\",\n                 color = \"white\",\n                 bins = 15) +\n  scale_x_continuous(limits = c(0, 1)) +\n  facet_wrap( ~ P) \n\n\n\n\nFigure 2.5: Binomial distribution to describe proportion data\n\n\n\n\n\n\n2.4.3 Beta-binomial distribution\nThe Beta-Binomial distribution is a mixture of the Binomial distribution with the Beta distribution acting as a prior on the probability parameter of the binomial. Disease probabilities can vary across trials due to a number of unobserved or unmeasured factors. This variability can result in overdispersion, a phenomenon where the observed variance in the data is greater than what the binomial distribution expects.\nThis is where the Beta-Binomial distribution comes in handy. By combining the Beta distribution’s flexibility in modeling probabilities with the Binomial distribution’s discrete event modeling, it provides an extra layer of variability to account for overdispersion. The Beta-Binomial distribution treats the probability of success (disease occurrence in this context) as a random variable itself, following a Beta distribution. This means the probability can vary from trial to trial.\nTherefore, when we observe data that shows more variance than the Beta distribution can account for, or when we believe there are underlying factors causing variability in the probability of disease occurrence, the Beta-Binomial distribution is a more appropriate model. It captures both the variability in success probability as well as the occurrence of the discrete event (disease incidence).\nWhen combined with the Binomial distribution, which handles discrete events (e.g. whether an individual is diseased or not), the Beta-Binomial distribution allows us to make probabilistic predictions about these events. For example, based on prior data (the Beta distribution), we can estimate the likelihood of a particular individual being diseased (the Binomial distribution).\nIn R, the rBetaBin function of the FlexReg package generates random values from the beta-binomial distribution. The arguments of the function are n, or the number of values to generate; if length(n) &gt; 1, the length is taken to be the number required. size is he total number of trials. mu is the mean parameter. It must lie in (0, 1). theta is the overdispersion parameter. It must lie in (0, 1). phi the precision parameter. It is an alternative way to specify the theta parameter. It must be a positive real value.\n\nlibrary(FlexReg) \nbetabin3.6 &lt;- rBetaBin(n = 100, size = 40, mu = .3, theta = .6)\nbetabin7.3 &lt;- rBetaBin(n = 100, size = 40, mu = .7, theta = .3)\nbetabin_data &lt;- data.frame(betabin3.6, betabin7.3)\n\n\nbetabin_data |&gt;\n  pivot_longer(1:2, names_to = \"P\",\n               values_to = \"value\") |&gt;\n  ggplot(aes(value)) +\n  geom_histogram(fill = \"#339966\",\n                 color = \"white\",\n                 bins = 15) +\n  facet_wrap( ~ P) \n\n\n\n\nFigure 2.6: Beta-binomial distribution to describe proportion data\n\n\n\n\n\n\n2.4.4 Poisson distribution\nWhen conducting studies in epidemiology, specifically plant diseases, researchers often collect data on the number of diseased plants, infected plant parts, or individual symptoms, such as lesions. These variables are counted in whole numbers - 1, 2, 3, etc., making them discrete variables. Discrete variables contrast with continuous variables that can take any value within a defined range and can include fractions or decimals. In addition to being discrete, these variables are also non-negative, meaning they cannot take negative values. After all, you can’t have a negative number of diseased plants or lesions. Given these characteristics, a suitable distribution to model such data is the Poisson distribution. This distribution is particularly suitable for counting the number of times an event occurs in a given time or space.\nIn R, we can used the rpois() function to obtain 100 random observations following a Poisson distribution. For such, we need to inform the number of observation (n = 100) and lambda, the vector of means.\n\npoisson5 &lt;- rpois(100, lambda = 10)\npoisson35 &lt;- rpois(100, lambda = 35)\npoisson_data &lt;- data.frame(poisson5, poisson35)\n\n\npoisson_data |&gt;\n  pivot_longer(1:2, names_to = \"P\",\n               values_to = \"value\") |&gt;\n  ggplot(aes(value)) +\n  geom_histogram(fill = \"#339966\",\n                 color = \"white\",\n                 bins = 15) +\n  facet_wrap( ~ P) \n\n\n\n\nFigure 2.7: Poisson distribution to describe count data\n\n\n\n\n\n\n2.4.5 Negative binomial distribution\nWhile the Poisson distribution is indeed suitable for modeling count data, it assumes that the mean and variance of the data are equal. However, in real-world scenarios, especially in epidemiology, it is common to encounter overdispersed data - where the variance is greater than the mean. This could occur, for instance, if there’s greater variability in disease incidence across different plant populations than would be expected under the Poisson assumption.\nIn such cases, the Negative Binomial distribution is a better alternative. The Negative Binomial distribution is a discrete probability distribution that models the number of successes in a sequence of independent and identically distributed Bernoulli trials before a specified (non-random) number of failures occurs.\nOne of the key features of the Negative Binomial distribution is its ability to handle overdispersion. Unlike the Poisson distribution, which has one parameter (lambda, representing the mean and variance), the Negative Binomial distribution has two parameters. One parameter is the mean, but the other (often denoted as ‘size’ or ‘shape’) governs the variance independently, allowing it to be larger than the mean if necessary. Thus, it provides greater flexibility than the Poisson distribution for modeling count data and can lead to more accurate results when overdispersion is present.\nIn R, we can use the rnbinom() function to generate random variates from a Negative Binomial distribution. This function requires the number of observations (n), the target for the number of successful trials (size), and the probability of each success (prob).\nHere’s an example:\n\n# Generate 100 random variables from a Negative Binomial distribution\nnegbin14.6 &lt;- rnbinom(n = 100, size = 14, prob = 0.6)\nnegbin50.6 &lt;- rnbinom(n = 100, size = 50, prob = 0.6)\nnegbin_data &lt;- data.frame(negbin14.6, negbin50.6)\n\n\nnegbin_data |&gt;\n  pivot_longer(1:2, names_to = \"P\",\n               values_to = \"value\") |&gt;\n  ggplot(aes(value)) +\n  geom_histogram(fill = \"#339966\",\n                 color = \"white\", bins = 15) +\n  facet_wrap( ~ P) \n\n\n\n\nFigure 2.8: Negative binomial distribution to describe overdispersed count data\n\n\n\n\n\n\n2.4.6 Gamma distribution\nIn plant disease epidemiology and other fields of study, we may often encounter continuous variables - these are variables that can take on any value within a given range, including both whole numbers and fractions. An example of a continuous variable in this context is lesion size, which can theoretically be any non-negative value.\nOften, researchers use the normal (Gaussian) distribution to model such continuous variables. The normal distribution is symmetric, bell-shaped, and is fully described by its mean and standard deviation. However, a fundamental characteristic of the normal distribution is that it extends from negative infinity to positive infinity. While this is not a problem for many applications, it becomes an issue when the variable being modeled cannot take on negative values - like the size of a lesion.\nThis is where the Gamma distribution can be a good alternative. The Gamma distribution is a two-parameter family of continuous probability distributions, which does not include negative values, making it an appropriate choice for modeling variables like lesion sizes. While it might seem a bit more complicated due to its two parameters, this also allows it a greater flexibility in terms of the variety of shapes and behaviors it can describe. The Gamma distribution is often used in various scientific disciplines, including queuing models, climatology, financial services, and of course, epidemiology. Its main parameters are the shape and scale (or alternatively shape and rate), which control the shape, spread and location of the distribution.\nWe can use the rgamma() function that requires the number of samples (n = 100 in our case) and the shape, or the mean value.\n\ngamma10 &lt;- rgamma(n = 100, shape = 10, scale = 1)\ngamma35 &lt;- rgamma(n = 100, shape = 35, scale = 1)\ngamma_data &lt;- data.frame(gamma10, gamma35)\n\n\ngamma_data |&gt;\n  pivot_longer(1:2, names_to = \"P\",\n               values_to = \"value\") |&gt;\n  ggplot(aes(value)) +\n  geom_histogram(fill = \"#339966\",\n                 color = \"white\",\n                 bins = 15) +\n  ylim(0, max(gamma_data$gamma35)) +\n  facet_wrap( ~ P) \n\n\n\n\nFigure 2.9: Gamma distribution to describe continuous data\n\n\n\n\n\n\n2.4.7 Simulating ordinal data\nOrdinal data is a statistical data type consisting of numerical scores that fall into a set of categories which are ordered in a meaningful way. This can include survey responses (e.g., strongly disagree to strongly agree), levels of achievement (e.g., poor, average, good, excellent), or, in the case of plant disease, disease severity scales (e.g., 0 to 5, where 0 represents a healthy plant and 5 represents a plant with severe symptoms).\nWhen working with ordinal data, we often need to make assumptions about the distribution of the data. However, unlike continuous data which might be modeled by a normal or Gamma distribution, or count data which might be modeled by a Poisson distribution, ordinal data is discrete and has a clear order but the distances between the categories are not necessarily equal or known. This makes the modeling process slightly different.\nWe can use the sample() function and define the probability associated with each rank. Let’s generate 30 units with a distinct ordinal score. In the first situation, the higher probabilities (0.5) are for scores 4 and 5 and lower (0.1) for scores 0 and 1, and in the second situation is the converse.\n\nordinal1 &lt;- sample(0:5, 30, replace = TRUE, prob = c(0.1, 0.1, 0.2, 0.2, 0.5, 0.5))\nordinal2 &lt;- sample(0:5, 30, replace = TRUE, prob = c(0.5, 0.5, 0.2, 0.2, 0.1, 0.1))\nordinal_data &lt;- data.frame(ordinal1, ordinal2)\n\n\nordinal_data |&gt;\n  pivot_longer(1:2, names_to = \"P\",\n               values_to = \"value\") |&gt;\n  ggplot(aes(value)) +\n  geom_histogram(fill = \"#339966\",\n                 color = \"white\",\n                 bins = 6) +\n  facet_wrap( ~ P) \n\n\n\n\nFigure 2.10: Sampling of ordinal data\n\n\n\n\n\n\n\n\nBock, C. H., Pethybridge, S. J., Barbedo, J. G. A., Esker, P. D., Mahlein, A.-K., and Del Ponte, E. M. 2021. A phytopathometry glossary for the twenty-first century: towards consistency and precision in intra- and inter-disciplinary dialogues. Tropical Plant Pathology. 47:14–24 Available at: http://dx.doi.org/10.1007/s40858-021-00454-0.\n\n\nNutter, F. W., Esker, P. D., and Netto, R. A. C. 2006. Disease Assessment Concepts and the Advancements Made in Improving the Accuracy and Precision of Plant Disease Data. European Journal of Plant Pathology. 115:95–103 Available at: http://dx.doi.org/10.1007/s10658-005-1230-z."
  },
  {
    "objectID": "data-ordinal.html#ordinal-scales",
    "href": "data-ordinal.html#ordinal-scales",
    "title": "3  Ordinal scales",
    "section": "3.1 Ordinal scales",
    "text": "3.1 Ordinal scales\nOrdinal scales are organized as rank-ordered numeric classes, with a finite number of such classes. The utilization of ordinal scales is often due to their convenience and speed of rating (Madden et al. 2017). In plant pathological research, there are two commonly used types of ordinal scales: quantitative and qualitative (Chiang and Bock 2021).\n\n3.1.1 Quantitative ordinal\nIn the quantitative ordinal scale, each score signifies a defined interval of the percentage scale. The most renowned quantitative ordinal scale is the Horsfall-Barratt (HB) scale, which was developed in the early 1940s when the science of plant pathology was transitioning towards more quantitative methodologies (Hebert 1982). The HB scale partitions the percentage scale into twelve successive, logarithmic-based intervals of severity ranging from 0 to 100%. The intervals increase in size from 0 to 50% and decrease from 50 to 100%.\n\n\n\n\n\n\nControversy of the H-B scale\n\n\n\nThe divisions of the H-B scale were established on two assumptions. The first was the logarithmic relationship between the intensity of a stimulus and the subsequent sensation. The second was the propensity of a rater to focus on smaller objects when observing objects of two colors (Madden et al. 2017). This foundation is based on the so-called Weber-Fechner law. However, there is limited experimental evidence supporting these assumptions. Current evidence indicates a linear relationship, rather than a logarithmic one, between visually estimated and actual severity (Nutter and Esker 2006). Additionally, these authors demonstrated that raters more accurately discriminated disease severity between 25% and 50% than what the H-B scale allowed. New scale structures have been proposed to address the issues associated with the H-B scale (Liu et al. 2019; Chiang et al. 2014). The Chiang scale follows a linear relationship with the percentage area diseased at severities greater than 10% (class 6 on the scale).\n\n\nLet’s input the HB scale data and store as a data frame in R so we can prepare a table and a plot.\n\nHB &lt;- tibble::tribble(\n  ~ordinal, ~'range', ~midpoint,\n  0,          '0',    0,   \n  1,    '0+ to 3',  1.5,   \n  2,    '3+ to 6',  4.5,   \n  3,   '6+ to 12',  9.0,  \n  4,  '12+ to 25', 18.5, \n  5,  '25+ to 50', 37.5, \n  6,  '50+ to 75', 62.5, \n  7,  '75+ to 88', 81.5, \n  8,  '88+ to 94', 91.0, \n  9,  '94+ to 97', 95.5, \n  10,'97+ to 100', 98.5,  \n  11,      '100',   100 \n  )\nknitr::kable(HB, align = \"c\")\n\n\n\nTable 3.1: The Horsfal-Barrat quantitative ordinal scale used as a tool for assessing plant disease severity\n\n\nordinal\nrange\nmidpoint\n\n\n\n\n0\n0\n0.0\n\n\n1\n0+ to 3\n1.5\n\n\n2\n3+ to 6\n4.5\n\n\n3\n6+ to 12\n9.0\n\n\n4\n12+ to 25\n18.5\n\n\n5\n25+ to 50\n37.5\n\n\n6\n50+ to 75\n62.5\n\n\n7\n75+ to 88\n81.5\n\n\n8\n88+ to 94\n91.0\n\n\n9\n94+ to 97\n95.5\n\n\n10\n97+ to 100\n98.5\n\n\n11\n100\n100.0\n\n\n\n\n\n\nLet’s visualize the different sizes of the percent interval encompassing each score.\n\n\nCode\nlibrary(tidyverse)\n\nHB |&gt; \n  ggplot(aes(midpoint, ordinal))+\n  geom_point(size =2)+\n  geom_line()+\n  scale_x_continuous(breaks = c(0, 3, 6, 12, 25, 50, 75, 88, 94, 97))+\n  scale_y_continuous(breaks = c(1:12))+\n  geom_vline(aes(xintercept = 3), linetype = 2)+\n  geom_vline(aes(xintercept = 6), linetype = 2)+\n  geom_vline(aes(xintercept = 12), linetype = 2)+\n  geom_vline(aes(xintercept = 25), linetype = 2)+\n  geom_vline(aes(xintercept = 50), linetype = 2)+\n  geom_vline(aes(xintercept = 75), linetype = 2)+\n  geom_vline(aes(xintercept = 88), linetype = 2)+\n  geom_vline(aes(xintercept = 94), linetype = 2)+\n  geom_vline(aes(xintercept = 97), linetype = 2)+\n  labs(x = \"Percent severity\", y = \"HB score\")\n\n\n\n\n\nFigure 3.1: Ordinal scores of the Horsfal-Barrat scale\n\n\n\n\nWe can repeat those procedures to visualize the Chiang scale.\n\nchiang &lt;- tibble::tribble(\n  ~ordinal, ~'range', ~midpoint,\n  0,          '0',     0,   \n  1,  '0+ to 0.1',  0.05,   \n  2,'0.1+ to 0.5',   0.3,   \n  3,  '0.5+ to 1',  0.75,  \n  4,    '1+ to 2',   1.5, \n  5,    '2+ to 5',     3, \n  6,   '5+ to 10',   7.5, \n  7,  '10+ to 20',    15, \n  8,  '20+ to 30',    25, \n  9,  '30+ to 40',    35, \n  10, '40+ to 50',    45,  \n  11, '50+ to 60',    55,\n  12, '60+ to 70',    65,\n  13, '70+ to 80',    75,\n  14, '80+ to 90',    85,\n  15,'90+ to 100',   95\n  )\nknitr::kable(chiang, align = \"c\")\n\n\n\nTable 3.2: The Chiang quantitative ordinal scale used as a tool for assessing plant disease severity\n\n\nordinal\nrange\nmidpoint\n\n\n\n\n0\n0\n0.00\n\n\n1\n0+ to 0.1\n0.05\n\n\n2\n0.1+ to 0.5\n0.30\n\n\n3\n0.5+ to 1\n0.75\n\n\n4\n1+ to 2\n1.50\n\n\n5\n2+ to 5\n3.00\n\n\n6\n5+ to 10\n7.50\n\n\n7\n10+ to 20\n15.00\n\n\n8\n20+ to 30\n25.00\n\n\n9\n30+ to 40\n35.00\n\n\n10\n40+ to 50\n45.00\n\n\n11\n50+ to 60\n55.00\n\n\n12\n60+ to 70\n65.00\n\n\n13\n70+ to 80\n75.00\n\n\n14\n80+ to 90\n85.00\n\n\n15\n90+ to 100\n95.00\n\n\n\n\n\n\n\nchiang |&gt; \n  ggplot(aes(midpoint, ordinal))+\n  geom_point(size =2)+\n  geom_line()+\n  scale_y_continuous(breaks = c(0:15))+\n  scale_x_continuous(breaks = c(0, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100))+\n  geom_vline(aes(xintercept = 0), linetype = 2)+\n  geom_vline(aes(xintercept = 0.1), linetype = 2)+\n  geom_vline(aes(xintercept = 0.5), linetype = 2)+\n  geom_vline(aes(xintercept = 1), linetype = 2)+\n  geom_vline(aes(xintercept = 2), linetype = 2)+\n  geom_vline(aes(xintercept = 5), linetype = 2)+\n  geom_vline(aes(xintercept = 10), linetype = 2)+\n  geom_vline(aes(xintercept = 20), linetype = 2)+\n  geom_vline(aes(xintercept = 30), linetype = 2)+\n   geom_vline(aes(xintercept = 40), linetype = 2)+\n   geom_vline(aes(xintercept = 50), linetype = 2)+\n   geom_vline(aes(xintercept = 60), linetype = 2)+\n   geom_vline(aes(xintercept = 70), linetype = 2)+\n   geom_vline(aes(xintercept = 80), linetype = 2)+\n   geom_vline(aes(xintercept = 90), linetype = 2)+\n   geom_vline(aes(xintercept = 100), linetype = 2)+\n  labs(x = \"Percent severity\", y = \"Chiang score\")\n\n\n\n\nFigure 3.2: Ordinal scores of the Chiang scale\n\n\n\n\n\n\n3.1.2 Qualitative ordinal\nIn the qualitative ordinal scale, each class provides a description of the symptoms. An example is the ordinal 0-3 scale for rating eyespot of wheat developed by (Scott and Hollins 1974).\n\nOrdinal scale for rating eyespot of wheat (Scott and Hollins 1974)\n\n\n\n\n\n\nClass\nDescription\n\n\n\n\n0\nuninfected\n\n\n1\nslight eyespot (or or more small lesion occupying in total less than half of the circumference of the stem)\n\n\n2\nmoderate eyespot (one or more lesions occupying at least half the circumference of the stem)\n\n\n3\nsevere eyespot (stem completely girdled by lesions; tissue softened so that lodging would really occur)"
  },
  {
    "objectID": "data-ordinal.html#disease-severity-index-dsi",
    "href": "data-ordinal.html#disease-severity-index-dsi",
    "title": "3  Ordinal scales",
    "section": "3.2 Disease severity index (DSI)",
    "text": "3.2 Disease severity index (DSI)\nUsually, when quantitative or qualitative ordinal scales are used, the scores are transformed into an index on a percentage basis, such as the disease severity index (DSI) which is used in data analysis. The DSI is a single number that summarizes a large amount of information on disease severity (Chester 1950). The formula for a DSI (%) can be written as follows:\n\\(DSI = \\frac{∑(class \\ freq. \\ ✕ \\ score \\  of \\ class)} {total \\ n \\ ✕ \\ maximal \\ class} ✕ 100\\)\nThe DSI() and DSI2() are part of the r4pde package. Let’s see how each function works.\nThe DSI() allows to automate the calculation of the disease severity index (DSI) in a series of units (e.g. leaves) that are further classified according to ordinal scores. The function requires three arguments:\n\nunit = the vector of the number of each unit\nclass = the vector of the scores for the units\nmax = the maximum value of the scale\n\nLet’s create a toy data set composed of 12 units where each received an ordinal score. The vectors were arranged as a data frame named scores.\n\nunit &lt;- c(1:12)\nclass &lt;- c(2,3,1,1,3,4,5,0,2,5,2,1)\nratings &lt;- data.frame(unit, class)\nknitr::kable(ratings)\n\n\n\n\nunit\nclass\n\n\n\n\n1\n2\n\n\n2\n3\n\n\n3\n1\n\n\n4\n1\n\n\n5\n3\n\n\n6\n4\n\n\n7\n5\n\n\n8\n0\n\n\n9\n2\n\n\n10\n5\n\n\n11\n2\n\n\n12\n1\n\n\n\n\n\nThe ordinal score used in this example has 6 as the maximum score. The function returns the DSI value.\n\nlibrary(r4pde)\nDSI(ratings$unit, ratings$class, 6)\n\n[1] 40.27778\n\n\nLet’s now deal with a situation of multiple plots (five replicates) where a fixed number of 12 samples were taken and assessed using an ordinal score. Let’s input the data using the tribble() function. Note that the data is in the wide format.\n\nexp &lt;- tibble::tribble(\n  ~rep, ~`1`, ~`2`, ~`3`, ~`4`, ~`5`, ~`6`, ~`7`, ~`8`, ~`9`, ~`10`, ~`11`,~`12`,\n  1, 2, 3, 1, 1, 3, 4, 5, 0, 2, 5, 2, 1,\n  2, 3, 4, 4, 6, 5, 4, 4, 0, 2, 1, 1, 5,\n  3, 5, 6, 6, 5, 4, 2, 0, 0, 0, 0, 2, 0,\n  4, 5, 6, 0, 0, 0, 3, 3, 2, 1, 0, 2, 3, \n  5, 0, 0, 0, 0, 2, 3, 2, 5, 6, 2, 1, 0,\n)\nknitr::kable(exp)\n\n\n\n\nrep\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n\n1\n2\n3\n1\n1\n3\n4\n5\n0\n2\n5\n2\n1\n\n\n2\n3\n4\n4\n6\n5\n4\n4\n0\n2\n1\n1\n5\n\n\n3\n5\n6\n6\n5\n4\n2\n0\n0\n0\n0\n2\n0\n\n\n4\n5\n6\n0\n0\n0\n3\n3\n2\n1\n0\n2\n3\n\n\n5\n0\n0\n0\n0\n2\n3\n2\n5\n6\n2\n1\n0\n\n\n\n\n\nAfter reshaping the data to the long format, we can calculate the DSI for each plot/replicate as follows:\n\nres &lt;- exp |&gt; \n  pivot_longer(2:13, names_to = \"unit\", values_to = \"class\") |&gt;\n  group_by(rep) |&gt; \n  summarise(DSI = DSI(unit, class, 6))\n\nAnd here we have the results of the DSI for each replicate.\n\nknitr::kable(res, align = \"c\")\n\n\n\n\nrep\nDSI\n\n\n\n\n1\n40.27778\n\n\n2\n54.16667\n\n\n3\n41.66667\n\n\n4\n34.72222\n\n\n5\n29.16667\n\n\n\n\n\nNow our data set is organized as the frequency of each class as follows:\n\nratings2 &lt;- ratings |&gt; \n  dplyr::count(class)\n\nratings2\n\n  class n\n1     0 1\n2     1 3\n3     2 3\n4     3 2\n5     4 1\n6     5 2\n\n\nNow we can apply the DSI2() function. The function requires three arguments:\n\nclass = the number of the respective class\nfreq = the frequency of the class\nmax = the maximum value of the scale\n\n\nlibrary(r4pde)\nDSI2(ratings2$class, ratings2$n, 6)\n\n[1] 40.27778\n\n\n\n\n\n\nChester, K. S. 1950. Plant disease losses : Their appraisal and interpretation /. Available at: http://dx.doi.org/10.5962/bhl.title.86198.\n\n\nChiang, K.-S., and Bock, C. H. 2021. Understanding the ramifications of quantitative ordinal scales on accuracy of estimates of disease severity and data analysis in plant pathology. Tropical Plant Pathology. 47:58–73 Available at: http://dx.doi.org/10.1007/s40858-021-00446-0.\n\n\nChiang, K.-S., Liu, S.-C., Bock, C. H., and Gottwald, T. R. 2014. What Interval Characteristics Make a Good Categorical Disease Assessment Scale? Phytopathology®. 104:575–585 Available at: http://dx.doi.org/10.1094/phyto-10-13-0279-r.\n\n\nHebert, T. T. 1982. The rationale for the horsfall-barratt plant disease assessment scale. Phytopathology. 72:1269 Available at: http://dx.doi.org/10.1094/phyto-72-1269.\n\n\nLiu, H. I., Tsai, J. R., Chung, W. H., Bock, C. H., and Chiang, K. S. 2019. Effects of Quantitative Ordinal Scale Design on the Accuracy of Estimates of Mean Disease Severity. Agronomy. 9:565 Available at: http://dx.doi.org/10.3390/agronomy9090565.\n\n\nMadden, L. V., Hughes, G., and van den Bosch, F. 2017. The study of plant disease epidemics. The American Phytopathological Society. Available at: http://dx.doi.org/10.1094/9780890545058.\n\n\nNutter, F. W., and Esker, P. D. 2006. The Role of Psychophysics in Phytopathology: The WeberFechner Law Revisited. European Journal of Plant Pathology. 114:199–213 Available at: http://dx.doi.org/10.1007/s10658-005-4732-9.\n\n\nScott, P. R., and Hollins, T. W. 1974. Effects of eyespot on the yield of winter wheat. Annals of Applied Biology. 78:269–279 Available at: http://dx.doi.org/10.1111/j.1744-7348.1974.tb01506.x."
  },
  {
    "objectID": "data-actual-severity.html#the-actual-severity-measure",
    "href": "data-actual-severity.html#the-actual-severity-measure",
    "title": "4  Image analysis",
    "section": "4.1 The actual severity measure",
    "text": "4.1 The actual severity measure\nAmong the various methods to express plant disease severity, the percent area affected (or symptomatic) by the disease is one of the most common, especially when dealing with diseases that affect leaves. In order to evaluate whether visual estimates of plant disease severity are sufficiently accurate (as discussed in the previous chapter), one requires the actual severity values. These are also essential when creating Standard Area Diagrams (SADs), which are diagrammatic representations of severity values used as a reference either before or during visual assessment to standardize and produce more accurate results across different raters (Del Ponte et al. 2017).\nThe actual severity values are typically approximated using image analysis, wherein the image is segmented, and each pixel is categorized into one of three classes:\n\nDiseased (or symptomatic)\nNon-diseased (or healthy)\nBackground (the non-plant portion of the image)\n\nThe ratio of the diseased area to the total area of the unit (e.g., the entire plant organ or section of the image) yields the proportion of the diseased area, or the percent area affected (when multiplied by 100). Researchers have employed various proprietary or open-source software to determine the actual severity, as documented in a review on Standard Area Diagrams (Del Ponte et al. 2017).\nIn this section, we will utilize the measure_disease() function from the pliman (Plant IMage ANalysis) R package (Olivoto 2022) to measure the percent area affected. The package was compared with other software for determining plant disease severity across five different plant diseases and was shown to produce accurate results in most cases (Olivoto et al. 2022).\nThere are essentially two methods to measure severity. The first is predicated on image palettes that define each class of the image. The second relies on RGB-based indices (Alves et al. 2021). Let’s explore the first method, as well as an interactive approach to setting color palettes."
  },
  {
    "objectID": "data-actual-severity.html#image-palettes",
    "href": "data-actual-severity.html#image-palettes",
    "title": "4  Image analysis",
    "section": "4.2 Image palettes",
    "text": "4.2 Image palettes\nhe most crucial step is the initial one, where the user needs to correctly define the color palettes for each class. In pliman, the palettes are separate images representing each of the three classes: background (b), symptomatic (s), and healthy (h).\nThe reference image palettes can be constructed by manually sampling small areas of the image and creating a composite image. Naturally, the results may vary depending on how these areas are selected. A study that validated pliman for determining disease severity demonstrated the effect of different palettes prepared independently by three researchers (Olivoto et al. 2022). During the calibration of the palettes, examining the processed masks is crucial to create reference palettes that are the most representative of the respective class.\nIn this example, I manually selected and pasted several sections of images representing each class from a few leaves into a Google slide. Once the image palette was ready, I exported each one as a separate PNG image file (JPG also works). These files were named: sbr_b.png, sbr_h.png, and sbr_s.png. They can be found here in this folder for downloading.\n\n\n\nFigure 4.1: Preparation of image palettes by manually sampling fraction of the images that represent background, heatlhy leaf and lesions\n\n\nNow that we have the image palettes, we need to import them into the environment, using image_import() function for further analysis. Let’s create an image object for each palette named h (healthy), s (symptoms) and b (background).\n\nlibrary(pliman)\nh &lt;- image_import(\"imgs/sbr_h.png\")\ns &lt;- image_import(\"imgs/sbr_s.png\")\nb &lt;- image_import(\"imgs/sbr_b.png\")\n\nWe can visualize the imported image palettes using the image_combine() function.\n\nimage_combine(h, s, b, ncol =3)\n\n\n\n\nFigure 4.2: Image palettes created to segment images into background, sypomtoms and healthy area of the image"
  },
  {
    "objectID": "data-actual-severity.html#measuring-severity",
    "href": "data-actual-severity.html#measuring-severity",
    "title": "4  Image analysis",
    "section": "4.3 Measuring severity",
    "text": "4.3 Measuring severity\n\n4.3.1 Single image\nTo determine severity in a single image (e.g. img46.png), the image file needs to be loaded and assigned to an object using the same image_import() function used to load the palettes. We can then visualize the image, again using image_combine().\n\n\n\n\n\n\nTip\n\n\n\nThe collection of images used in this chapter can be found here.\n\n\n\nimg &lt;- image_import(\"imgs/originals/img46.png\")\nimage_combine(img)\n\n\n\n\nFigure 4.3: Imported image for further analysis\n\n\n\n\nNow the engaging part starts with the measure_disease() function. Four arguments are required when using the reference image palettes: the image representing the target image and the three images of the color palettes. As the author of the package states, “pliman will take care of all the details!” The severity is the value displayed under ‘symptomatic’ in the output.\n\nset.seed(123)\nmeasure_disease(\n  img = img,\n  img_healthy = h,\n  img_symptoms = s,\n  img_background = b,\n  show_image = TRUE\n)\n\n\n\n\n$severity\n   healthy symptomatic\n1 92.68302    7.316983\n\n$shape\nNULL\n\n$statistics\nNULL\n\nattr(,\"class\")\n[1] \"plm_disease\"\n\n\n\n\n4.3.2 Multiple images\nMeasuring severity in single images is indeed engaging, but we often deal with multiple images, not just one. Using the above procedure to process each image individually would be time-consuming and potentially tedious.\nTo automate the process, pliman offers a batch processing approach. Instead of using the img argument, one can use the pattern argument and define the prefix of the image names. Moreover, we also need to specify the directory where the original files are located.\nIf the user wants to save the processed masks, they should set the save_image argument to TRUE and also specify the directory where the images will be saved. Here’s an example of how to process 10 images of soybean rust symptoms. The output is a list object with the measures of the percent healthy and percent symptomatic area for each leaf in the severity object.\n\npliman &lt;- measure_disease(\n  pattern = \"img\",\n  dir_original = \"imgs/originals\" ,\n  dir_processed = \"imgs/processed\",\n  save_image = TRUE,\n  img_healthy = h,\n  img_symptoms = s,\n  img_background = b,\n  show_image = FALSE\n)\n\nProcessing image img11 |====                                     | 10% 00:00:00 \n\n\nProcessing image img35 |========                                 | 20% 00:00:02 \n\n\nProcessing image img37 |============                             | 30% 00:00:03 \n\n\nProcessing image img38 |================                         | 40% 00:00:03 \n\n\nProcessing image img46 |====================                     | 50% 00:00:04 \n\n\nProcessing image img5 |=========================                 | 60% 00:00:06 \n\n\nProcessing image img63 |=============================            | 70% 00:00:08 \n\n\nProcessing image img67 |=================================        | 80% 00:00:09 \n\n\nProcessing image img70 |=====================================    | 90% 00:00:11 \n\n\nProcessing image img75 |=========================================| 100% 00:00:12 \n\nseverity &lt;- pliman$severity\nseverity\n\n     img  healthy symptomatic\n1  img11 70.80072  29.1992835\n2  img35 46.96430  53.0357002\n3  img37 60.49390  39.5060986\n4  img38 79.14737  20.8526306\n5  img46 93.15143   6.8485680\n6   img5 20.53977  79.4602312\n7  img63 97.15698   2.8430190\n8  img67 99.83723   0.1627709\n9  img70 35.58683  64.4131683\n10 img75 93.04517   6.9548329\n\n\nWhem the argument save_image is set to TRUE, the images are all saved in the folder with the standard prefix “proc.”\n\n\n\nFigure 4.4: Images created by pliman and exported to a specific folder\n\n\nLet’s have a look at one of the processed images.\n\n\n\nFigure 4.5: Figure created by pliman after batch processing to segment the images and calculate percent area covered by symptoms. The symptomatic area is delinated in the image."
  },
  {
    "objectID": "data-actual-severity.html#how-good-are-these-measurements",
    "href": "data-actual-severity.html#how-good-are-these-measurements",
    "title": "4  Image analysis",
    "section": "4.4 How good are these measurements?",
    "text": "4.4 How good are these measurements?\nThese 10 images were previously processed in QUANT software for measuring severity which is also based on image threshold. Let’s create a tibble for the image code and respective “actual” severity - assuming QUANT measures as reference.\n\nlibrary(tidyverse)\nquant &lt;- tribble(\n  ~img, ~actual,\n   \"img5\",     75,\n  \"img11\",     24,\n  \"img35\",     52,\n  \"img37\",     38,\n  \"img38\",     17,\n  \"img46\",      7,\n  \"img63\",    2.5,\n  \"img67\",   0.25,\n  \"img70\",     67,\n  \"img75\",     10\n  )\n\nWe can now combine the two dataframes and produce a scatter plot relating the two measures.\n\ndat &lt;- left_join(severity, quant)\n\nJoining with `by = join_by(img)`\n\ndat %&gt;%\n  ggplot(aes(actual, symptomatic)) +\n  geom_point(size = 3, shape = 16, color = \"gray20\") +\n  ylim(0, 100) +\n  xlim(0, 100) +\n  geom_abline(slope = 1, intercept = 0) +\n  labs(x = \"Quant\",\n       y = \"pliman\")\n\n\n\n\nFigure 4.6: Scatter plot for the relationship between severity values measured by pliman and Quant software\n\n\n\n\nThe concordance correlation coefficient is a test for agreement between two observers or two methods (see previous chapter). It is an indication of how accurate the pliman measures are compared with a standard. The coefficient is greater than 0.99 (1.0 is perfect concordance), suggesting an excellent agreement!\n\nlibrary(epiR)\nccc &lt;- epi.ccc(dat$actual, dat$symptomatic)\nccc$rho.c\n\n        est     lower     upper\n1 0.9940941 0.9774812 0.9984606\n\n\nIn conclusion, as mentioned earlier, the most critical step is defining the reference image palettes. A few preliminary runs may be necessary for some images to ensure that the segmentation is being carried out correctly, based on visual judgment. This is not different from any other color-threshold based methods, where the choices made by the user impact the final result and contribute to variation among assessors. The drawbacks are the same as those encountered with direct competitors, namely, the need for images to be taken under uniform and controlled conditions, especially with a contrasting background."
  },
  {
    "objectID": "data-actual-severity.html#creating-palettes-interactively",
    "href": "data-actual-severity.html#creating-palettes-interactively",
    "title": "4  Image analysis",
    "section": "4.5 Creating palettes interactively",
    "text": "4.5 Creating palettes interactively\nPliman offers another function measure_disease_iter() which allows the user to pick up samples in the image to create the color palettes for each required clss (background, healthy and symptoms). Check the video below.\n\n\n\n\n\nAlves, K. S., Guimarães, M., Ascari, J. P., Queiroz, M. F., Alfenas, R. F., Mizubuti, E. S. G., et al. 2021. RGB-based phenotyping of foliar disease severity under controlled conditions. Tropical Plant Pathology. 47:105–117 Available at: http://dx.doi.org/10.1007/S40858-021-00448-Y.\n\n\nDel Ponte, E. M., Pethybridge, S. J., Bock, C. H., Michereff, S. J., Machado, F. J., and Spolti, P. 2017. Standard Area Diagrams for Aiding Severity Estimation: Scientometrics, Pathosystems, and Methodological Trends in the Last 25 Years. Phytopathology®. 107:1161–1174 Available at: http://dx.doi.org/10.1094/PHYTO-02-17-0069-FI.\n\n\nOlivoto, T. 2022. Lights, camera, pliman! An R package for plant image analysis. Methods in Ecology and Evolution. 13:789–798 Available at: http://dx.doi.org/10.1111/2041-210X.13803.\n\n\nOlivoto, T., Andrade, S. M. P., and M. Del Ponte, E. 2022. Measuring plant disease severity in R: introducing and evaluating the pliman package. Tropical Plant Pathology. 47:95–104 Available at: http://dx.doi.org/10.1007/s40858-021-00487-5."
  },
  {
    "objectID": "data-accuracy.html",
    "href": "data-accuracy.html",
    "title": "5  Reliability and accuracy",
    "section": "",
    "text": "6 Severity data"
  },
  {
    "objectID": "data-accuracy.html#terminology",
    "href": "data-accuracy.html#terminology",
    "title": "5  Reliability and accuracy",
    "section": "6.1 Terminology",
    "text": "6.1 Terminology\nDisease severity, mainly when expressed in percent area diseased assessed visually, is acknowledged as a more difficult and less time- and cost-effective plant disease variable to obtain. However, errors may occur even when assessing a more objective measure such as incidence. This is the case when an incorrect assignment or confusion of symptoms occur. In either case, the quality of the assessment of any disease variable is very important and should be gauged in the studies. Several terms can be used when evaluating the quality of disease assessments, including reliability, precision, accuracy or agreement.\nReliability: The extent to which the same estimates or measurements of diseased specimens obtained under different conditions yield similar results. There are two types. The inter-rater reliability (or reproducibility) is a measure of consistency of disease assessment across the same specimens between raters or devices. The intra-rater reliability (or repeatability) measures consistency by the same rater or instrument on the same specimens (e.g. two assessments in time by the same rater).\n\n\n\nFigure 6.1: Two types of reliability of estimates or measures of plant disease intensity\n\n\nPrecision: A statistical term to express the measure of variability of the estimates or measurements of disease on the same specimens obtained by different raters (or instruments). However, reliable or precise estimates (or measurements) are not necessarily close to an actual value, but precision is a component of accuracy or agreement.\nAccuracy or agreement: These two terms can be treated as synonymous in plant pathological research. They refer to the closeness (or concordance) of an estimate or measurement to the actual severity value for a specimen on the same scale. Actual values may be obtained using various methods, against which estimates or measurements using an experimental assessment method are compared.\nAn analogy commonly used to explain accuracy and precision is the archer shooting arrows at a target and trying to hit the bull’s eye (center of the target) with each of five arrows. The figure below is used to demonstrate four situations from the combination of two levels (high and low) for precision and accuracy. The figure was produced using the ggplot function of ggplot2 package.\n\n\nCode\nlibrary(ggplot2)\ntarget &lt;- \n  ggplot(data.frame(c(1:10),c(1:10)))+\n  geom_point(aes(x = 5, y = 5), size = 71.5, color = \"black\")+\n  geom_point(aes(x = 5, y = 5), size = 70, color = \"#99cc66\")+\n  geom_point(aes(x = 5, y = 5), size = 60, color = \"white\")+\n  geom_point(aes(x = 5, y = 5), size = 50, color = \"#99cc66\")+\n  geom_point(aes(x = 5, y = 5), size = 40, color = \"white\")+\n  geom_point(aes(x = 5, y = 5), size = 30, color = \"#99cc66\")+\n  geom_point(aes(x = 5, y = 5), size = 20, color = \"white\")+\n  geom_point(aes(x = 5, y = 5), size = 10, color = \"#99cc66\")+\n  geom_point(aes(x = 5, y = 5), size = 4, color = \"white\")+\n  ylim(0,10)+\n  xlim(0,10)+\n  theme_void()\n\nhahp &lt;- target +\n  labs(subtitle = \"High Accuracy High Precision\")+\n  theme(plot.subtitle = element_text(hjust = 0.5))+\n  geom_point(aes(x = 5, y = 5), shape = 4, size =2, color = \"blue\")+\n  geom_point(aes(x = 5, y = 5.2), shape = 4, size =2, color = \"blue\")+\n  geom_point(aes(x = 5, y = 4.8), shape = 4, size =2, color = \"blue\")+\n  geom_point(aes(x = 4.8, y = 5), shape = 4, size =2, color = \"blue\")+\n  geom_point(aes(x = 5.2, y = 5), shape = 4, size =2, color = \"blue\")\n\n\nlahp &lt;- target +\n  labs(subtitle = \"Low Accuracy High Precision\")+\n  theme(plot.subtitle = element_text(hjust = 0.5))+\n  geom_point(aes(x = 6, y = 6), shape = 4, size =2, color = \"blue\")+\n  geom_point(aes(x = 6, y = 6.2), shape = 4, size =2, color = \"blue\")+\n  geom_point(aes(x = 6, y = 5.8), shape = 4, size =2, color = \"blue\")+\n  geom_point(aes(x = 5.8, y = 6), shape = 4, size =2, color = \"blue\")+\n  geom_point(aes(x = 6.2, y = 6), shape = 4, size =2, color = \"blue\")\n\n\nhalp &lt;- target +\n  labs(subtitle = \"High Accuracy Low Precision\")+\n  theme(plot.subtitle = element_text(hjust = 0.5))+\n  geom_point(aes(x = 5, y = 5), shape = 4, size =2, color = \"blue\")+\n  geom_point(aes(x = 5, y = 5.8), shape = 4, size =2, color = \"blue\")+\n  geom_point(aes(x = 5.8, y = 4.4), shape = 4, size =2, color = \"blue\")+\n  geom_point(aes(x = 4.4, y = 5), shape = 4, size =2, color = \"blue\")+\n  geom_point(aes(x = 5.6, y = 5.6), shape = 4, size =2, color = \"blue\")\n\nlalp &lt;- target +\n  labs(subtitle = \"Low Accuracy Low Precision\")+\n  theme(plot.subtitle = element_text(hjust = 0.5))+\n  geom_point(aes(x = 5.5, y = 5.5), shape = 4, size =2, color = \"blue\")+\n  geom_point(aes(x = 4.5, y = 5.4), shape = 4, size =2, color = \"blue\")+\n  geom_point(aes(x = 5.2, y = 6.8), shape = 4, size =2, color = \"blue\")+\n  geom_point(aes(x = 4.8, y = 3.8), shape = 4, size =2, color = \"blue\")+\n  geom_point(aes(x = 5.2, y = 3), shape = 4, size =2, color = \"blue\")\n\n\nlibrary(patchwork)\n(hahp | lahp) /\n(halp | lalp)\n\n\n\n\n\nFigure 6.2: The accuracy and precision of the archer is determined by the location of the group of arrows\n\n\n\n\nAnother way to visualize accuracy and precision is via scatter plots for the relationship between the actual values and the estimates.\n\n\nCode\nlibrary(tidyverse)\ntheme_set(theme_grey())\ndat &lt;- \ntibble::tribble(\n  ~actual,   ~ap,   ~ip,   ~ai,   ~ii,\n        0,     0,    10,     0,    25,\n       10,    10,    20,     5,    10,\n       20,    20,    30,    30,    10,\n       30,    30,    40,    30,    45,\n       40,    40,    50,    30,    35,\n       50,    50,    60,    60,    65,\n       60,    60,    70,    50,    30\n  )\n\nap &lt;- dat |&gt; \n  ggplot(aes(actual, ap))+\n  geom_abline(intercept = 0, slope = 1, \n              linetype = 2, size = 1)+\n    geom_smooth(method = \"lm\")+\n   geom_point(color = \"orange\", size = 3)+\n   ylim(0,70)+\n  xlim(0,70)+\n  labs(x = \"Actual\", y = \"Estimate\",\n       title = \"High Acccuracy High Precision\")\n\nip &lt;- dat |&gt; \n  ggplot(aes(actual, ip))+\n  geom_abline(intercept = 0, slope = 1, \n              linetype = 2, size = 1)+\n  geom_smooth(method = \"lm\", se = F)+\n  geom_point(color = \"orange\", size = 3)+\n  ylim(0,70)+\n  xlim(0,70)+\n  labs(x = \"Actual\", y = \"Estimate\",\n       title = \"Low Acccuracy High Precision\")\n\nai &lt;- dat |&gt; \n  ggplot(aes(actual, ai))+\n  geom_abline(intercept = 0, slope = 1, \n              linetype = 2, size = 1)+\n  geom_smooth(method = \"lm\", se = F)+\n  geom_point(color = \"orange\", size = 3)+\n  ylim(0,70)+\n  xlim(0,70)+\n  labs(x = \"Actual\", y = \"Estimate\",\n       title = \"High Acccuracy Low precision\")\n\nii &lt;- dat |&gt; \n  ggplot(aes(actual, ii))+\n  geom_abline(intercept = 0, slope = 1, \n              linetype = 2, size = 1)+\n  geom_smooth(method = \"lm\", se = F)+\n  geom_point(color = \"orange\", size = 3)+\n  ylim(0,70)+\n  xlim(0,70)+\n  labs(x = \"Actual\", y = \"Estimate\",\n       title = \"Low Acccuracy Low Precision\")\n\nlibrary(patchwork)\n(ap | ip) / (ai | ii)\n\n\n\n\n\nFigure 6.3: Scatter plots for the relationship between actual and estimated values representing situations of low or high precision and accuracy. The dashed line indicates the perfect concordance and the solid blue line represents the fit of the linear regression model"
  },
  {
    "objectID": "data-accuracy.html#statistical-summaries",
    "href": "data-accuracy.html#statistical-summaries",
    "title": "5  Reliability and accuracy",
    "section": "6.2 Statistical summaries",
    "text": "6.2 Statistical summaries\nA formal assessment of the quality of estimates or measures is made using statistical summaries of the data expressed as indices that represent reliability, precision and accuracy. These indices can further be used to test hypothesis such as if one or another method is superior than the other. The indices or the tests vary according to the nature of the variable, whether continuous, binary or categorical.\n\n6.2.1 Inter-rater reliability\nTo calculate measures of inter-rater reliability (or reproducibility) we will work with a fraction of a larger dataset used in a published study. There, the authors tested the effect of standard area diagrams (SADs) on the reliability and accuracy of visual estimates of severity of soybean rust.\nThe selected dataset consists of five columns with 20 rows. The first is the leaf number and the others correspond to assessments of percent soybean rust severity by four raters (R1 to R4). Each row correspond to one symptomatic leaf. Let’s assign the tibble to a dataframe called sbr (an acronym for soybean rust). Note that the variable is continuous.\n\nlibrary(tidyverse)\nsbr &lt;- tribble(\n~leaf, ~R1, ~R2,  ~R3, ~R4,\n1, 0.6, 0.6,  0.7, 0.6,\n2,   2, 0.7,    5,   1,\n3,   5,   5,    8,   5,\n4,   2,   4,    6,   2,\n5,   6,  14,   10,   7,\n6,   5,   6,   10,   5,\n7,  10,  18, 12.5,  12,\n8,  15,  30,   22,  10,\n9,   7,   2,   12,   8,\n10,  6,   9, 11.5,   8,\n11,  7,   7,   20,   9,\n12,  6,  23,   22,  14,\n13, 10,  35, 18.5,  20,\n14, 19,  10,    9,  10,\n15, 15,  20,   19,  20,\n16, 17,  30,   18,  13,\n17, 19,  53,   33,  38,\n18, 17, 6.8,   15,   9,\n19, 15,  20,   18,  16,\n20, 18,  22,   24,  15\n         )\n\nLet’s explore the data using various approaches. First, we can visualize how the individual estimates by the raters differ for a same leaf.\n\n# set the global theme\n\nlibrary(ggthemes)\n\n# transform from wide to long format\nsbr2 &lt;- sbr |&gt; \n  pivot_longer(2:5, names_to = \"rater\",\n               values_to = \"estimate\") \n\n# create the plot\nsbr2 |&gt; \n  ggplot(aes(leaf, estimate, color = rater,\n             group = leaf))+\n  geom_line(color = \"black\")+\n  geom_point(size = 2)+\n  scale_color_colorblind()+\n  labs(y = \"Severity estimate (%)\",\n       x = \"Leaf number\",\n       color = \"Rater\")\n\n\n\n\nFigure 6.4: Visual estimates of soybean rust severity for each leaf by each of four raters\n\n\n\n\nAnother interesting visualization is the correlation matrix of the estimates between all possible pair of raters. The ggpairs function of the GGally package is handy for this task.\n\nlibrary(GGally)\n\n\n# create a new dataframe with only raters\nraters &lt;- sbr |&gt; \n  select(2:5)\n\nggpairs(raters)\n\n\n\n\nFigure 6.5: Correlation plots relating severity estimates for all pairs of raters\n\n\n\n\n\n6.2.1.1 Coefficient of determination\nWe noticed earlier that the correlation coefficients varied across all pairs of rater. Sometimes, the means of squared Pearson’s R values (R2), or the coefficient of determination is used as a measure of inter-rater reliability. We can further examine the pair-wise correlations in more details using the correlation function of the performance package.\n\nlibrary(correlation)\nraters_cor &lt;- correlation(raters)\nlibrary(knitr)\nkable(raters_cor[1:3]) # only first 3 variables\n\n\n\nTable 6.1: Pearson correlation coefficients for all pairs of raters\n\n\nParameter1\nParameter2\nr\n\n\n\n\nR1\nR2\n0.6325037\n\n\nR1\nR3\n0.6825936\n\n\nR1\nR4\n0.6756986\n\n\nR2\nR3\n0.8413333\n\n\nR2\nR4\n0.8922181\n\n\nR3\nR4\n0.8615470\n\n\n\n\n\n\nThe means of coefficient of determination can be easily obtained as follows.\n\n# All pairwise R2\nround(raters_cor$r^2,2)\n\n[1] 0.40 0.47 0.46 0.71 0.80 0.74\n\n# means of R2\nround(mean(raters_cor$r^2), 2)\n\n[1] 0.59\n\n\n\n\n6.2.1.2 Intraclass Correlation Coefficient\nA common statistic to report in reliability studies is the Intraclass Correlation Coefficient (ICC). There are several formulations for the ICC whose choice depend on the particular experimental design. Following the convention of the seminal work by Shrout and Fleiss (1979), there are three main ICCs:\n\nOne-way random effects model, ICC(1,1): in our context, each leaf is rated by different raters who are considered as sampled from a larger pool of raters (random effects)\nTwo-way random effects model, ICC(2,1): both raters and leaves are viewed as random effects\nTwo-way mixed model, ICC(3,1): raters are considered as fixed effects and leaves are considered as random.\n\nAdditionally, the ICC may depend on whether the ratings are an average or not of several ratings. When an average is considered, these are called ICC(1,k), ICC(2,k) and ICC(3,k).\nThe ICC can be computed using the ICC() or the icc() functions of the psych or irr packages, respectively. They both provide the coefficient, F value, and the upper and lower bounds of the 95% confidence interval.\n\nlibrary(psych)\nic &lt;- ICC(raters)\nkable(ic$results[1:2]) # only selected columns\n\n\n\n\n\ntype\nICC\n\n\n\n\nSingle_raters_absolute\nICC1\n0.6405024\n\n\nSingle_random_raters\nICC2\n0.6464122\n\n\nSingle_fixed_raters\nICC3\n0.6919099\n\n\nAverage_raters_absolute\nICC1k\n0.8769479\n\n\nAverage_random_raters\nICC2k\n0.8797008\n\n\nAverage_fixed_raters\nICC3k\n0.8998319\n\n\n\n\n# call ic list for full results\n\nThe output of interest is a dataframe with the results of all distinct ICCs. We note that the ICC1 and ICC2 gave very close results. Now, let’s obtain the various ICCs using the irr package. Differently from the the ICC() function, this one requires further specification of the model to use.\n\nlibrary(irr)\nicc(raters, \"oneway\")\n\n Single Score Intraclass Correlation\n\n   Model: oneway \n   Type : consistency \n\n   Subjects = 20 \n     Raters = 4 \n     ICC(1) = 0.641\n\n F-Test, H0: r0 = 0 ; H1: r0 &gt; 0 \n   F(19,60) = 8.13 , p = 1.8e-10 \n\n 95%-Confidence Interval for ICC Population Values:\n  0.44 &lt; ICC &lt; 0.813\n\n# The one used in the SBR paper\nicc(raters, \"twoway\")\n\n Single Score Intraclass Correlation\n\n   Model: twoway \n   Type : consistency \n\n   Subjects = 20 \n     Raters = 4 \n   ICC(C,1) = 0.692\n\n F-Test, H0: r0 = 0 ; H1: r0 &gt; 0 \n   F(19,57) = 9.98 , p = 6.08e-12 \n\n 95%-Confidence Interval for ICC Population Values:\n  0.503 &lt; ICC &lt; 0.845\n\n\n\n\n6.2.1.3 Overall Concordance Correlation Coefficient\nAnother useful index is the Overall Concordance Correlation Coefficient (OCCC) for evaluating agreement among multiple observers. It was proposed by Barnhart et al. (2002) based on the original index proposed by Lin (1989), earlier defined in the context of two fixed observers. In the paper, the authors introduced the OCCC in terms of the interobserver variability for assessing agreement among multiple fixed observers. As outcome, and similar to the original CCC, the approach addresses the precision and accuracy indices as components of the OCCC. The epi.occc function of the epiR packge does the job but it does compute a confidence interval.\n\nlibrary(epiR)\nepi.occc(raters, na.rm = FALSE, pairs = TRUE)\n\n\nOverall CCC           0.6372\nOverall precision     0.7843\nOverall accuracy      0.8125\n\n\n\n\n\n6.2.2 Intrarater reliability\nAs defined, the intrarater reliability is also known as repeatability, because it measures consistency by the same rater at repeated assessments (e.g. different times) on the same sample. In some studies, we may be interested in testing whether a new method increases repeatability of assessments by a single rater compared with another one. The same indices used for assessing reproducibility (interrater) can be used to assess repeatability, and these are reported at the rater level.\n\n\n6.2.3 Precision\nWhen assessing precision, one measures the variability of the estimates (or measurements) of disease on the same sampling units obtained by different raters (or instruments). A very high precision does not mean that the estimates are closer to the actual value (which is given by measures of bias). However, precision is a component of overall accuracy, or agreement. It is given by the Pearson’s correlation coefficient.\nDifferent from reliability, that requires only the estimates or measures by the raters, now we need a reference (gold standard) value to compare the estimates to. These can be an accurate rater or measures by an instrument. Let’s get back to the soybean rust severity estimation dataset and add a column for the (assumed) actual values of severity on each leaf. In that work, the actual severity values were obtained using image analysis.\n\nsbr &lt;- tibble::tribble(\n~leaf, ~actual, ~R1, ~R2,  ~R3, ~R4,\n1,    0.25, 0.6, 0.6,  0.7, 0.6,\n2,     2.5,   2, 0.7,    5,   1,\n3,    7.24,   5,   5,    8,   5,\n4,    7.31,   2,   4,    6,   2,\n5,    9.07,   6,  14,   10,   7,\n6,    11.6,   5,   6,   10,   5,\n7,   12.46,  10,  18, 12.5,  12,\n8,    13.1,  15,  30,   22,  10,\n9,   14.61,   7,   2,   12,   8,\n10,  16.06,   6,   9, 11.5,   8,\n11,   16.7,   7,   7,   20,   9,\n12,   19.5,   6,  23,   22,  14,\n13,  20.75,  10,  35, 18.5,  20,\n14,  23.56,  19,  10,    9,  10,\n15,  23.77,  15,  20,   19,  20,\n16,  24.45,  17,  30,   18,  13,\n17,  25.78,  19,  53,   33,  38,\n18,  26.03,  17, 6.8,   15,   9,\n19,  26.42,  15,  20,   18,  16,\n20,  28.89,  18,  22,   24,  15\n         )\n\nWe can explore visually via scatter plots the relationships between the actual value and the estimates by each rater (Figure 6.6). To facilitate, we need the data in the long format.\n\nsbr2 &lt;- sbr |&gt; \n  pivot_longer(3:6, names_to = \"rater\",\n               values_to = \"estimate\") \n\nsbr2 |&gt; \n  ggplot(aes(actual, estimate))+\n  geom_point(size = 2, alpha = 0.7)+\n  facet_wrap(~rater)+\n  ylim(0,45)+\n  xlim(0,45)+\n  geom_abline(intercept = 0, slope =1)+\n  theme_gray()+\n  labs(x = \"Actual severity (%)\",\n       y = \"Estimate severity (%)\")\n\n\n\n\nFigure 6.6: Scatterplots for the relationship between estimated and actual severity for each rater\n\n\n\n\nThe Pearson’s r for the relationship, or the precision of the estimates by each rater, can be obtained using the correlation function of the correlation package.\n\nprecision &lt;- sbr2 |&gt; \n  select(-leaf) |&gt; \n  group_by(rater) |&gt; \n  correlation() \n\nkable(precision[1:4])\n\n\n\n\nGroup\nParameter1\nParameter2\nr\n\n\n\n\nR1\nactual\nestimate\n0.8725643\n\n\nR2\nactual\nestimate\n0.5845291\n\n\nR3\nactual\nestimate\n0.7531983\n\n\nR4\nactual\nestimate\n0.7108260\n\n\n\n\n\nThe mean precision can then be obtained.\n\nmean(precision$r)\n\n[1] 0.7302795\n\n\n\n\n6.2.4 Accuracy\n\n6.2.4.1 Absolute errors\nIt is useful to visualize the errors of the estimates which are obtained by subtracting the estimates from the actual severity values. This plot allows to visualize patterns in over or underestimations across a range of actual severity values.\n\nsbr2 |&gt; \n  ggplot(aes(actual, estimate-actual))+\n  geom_point(size = 3, alpha = 0.7)+\n  facet_wrap(~rater)+\n  geom_hline(yintercept = 0)+\n  theme_gray()+\n  labs(x = \"Actual severity (%)\",\n       y = \"Error (Estimate - Actual)\")\n\n\n\n\nFigure 6.7: Error (estimated - actual) of visual severity estimates\n\n\n\n\n\n\n6.2.4.2 Concordance correlation coefficient\nLin’s (1989, 2000) proposed the concordance correlation coefficient (CCC) for agreement on a continuous measure obtained by two methods. The CCC combines measures of both precision and accuracy to determine how far the observed data deviate from the line of perfect concordance. Lin’s CCC increases in value as a function of the nearness of the data reduced major axis to the line of perfect concordance (the accuracy of the data) and of the tightness of the data about its reduced major axis (the precision of the data).\nThe epi.ccc function of the epiR package allows to obtain the Lin’s CCC statistics. Let’s filter only rater 2 and calculate the CCC statistics for this rater.\n\nlibrary(epiR)\n# Only rater 2\nsbr3 &lt;- sbr2 |&gt; filter(rater == \"R2\")\nccc &lt;- epi.ccc(sbr3$actual, sbr3$estimate)\n# Concordance coefficient\nrho &lt;- ccc$rho.c[,1]\n# Bias coefficient\nCb &lt;- ccc$C.b\n# Precision\nr &lt;- ccc$C.b*ccc$rho.c[,1]\n# Scale-shift\nss &lt;- ccc$s.shift\n# Location-shift\nls &lt;- ccc$l.shift\nMetrics &lt;- c(\"Agreement\", \"Bias coefficient\", \"Precision\", \"scale-shift\", \"location-shift\")\nValue &lt;- c(rho, Cb, r, ss, ls)\nres &lt;- data.frame(Metrics, Value)\nkable(res)\n\n\n\nTable 6.2: Statitics of the concordance correlation coefficient summarizing accuracy and precision of visual severity estimates of soybean rust for a single rater\n\n\nMetrics\nValue\n\n\n\n\nAgreement\n0.5230656\n\n\nBias coefficient\n0.8948494\n\n\nPrecision\n0.4680649\n\n\nscale-shift\n1.6091178\n\n\nlocation-shift\n-0.0666069\n\n\n\n\n\n\nNow let’s create a function that will allow us to estimate the CCC for all raters in the data frame in the wide format. The function assumes that the first two columns are the actual and estimates and the rest of the columns are the raters, which is the case for our sbr dataframe . Let’s name this function ccc_byrater.\n\nccc_byrater &lt;- function(data) {\n  long_data &lt;- pivot_longer(data, cols = -c(leaf, actual),\n                            names_to = \"rater\", values_to = \"measurement\")\n  ccc_results &lt;- long_data %&gt;%\n    group_by(rater) %&gt;%\n    summarise(Agreement = as.numeric(epi.ccc(measurement, actual)$rho.c[1]),\n              `Bias coefficient` = epi.ccc(measurement, actual)$C.b,\n              Precision = Agreement * `Bias coefficient`,\n              scale_shift = epi.ccc(measurement, actual)$s.shift,\n              location_shift = epi.ccc(measurement, actual)$l.shift)\n  \n  return(ccc_results)\n}\n\nThen, we use the ccc_byrater function with the original sbr dataset - or any other dataset in the wide format of similar structure. The output is a dataframe with all CCC statistics.\n\nresults &lt;- ccc_byrater(sbr)\nknitr::kable(results)\n\n\n\n\n\n\n\n\n\n\n\n\nrater\nAgreement\nBias coefficient\nPrecision\nscale_shift\nlocation_shift\n\n\n\n\nR1\n0.5968136\n0.6839766\n0.4082065\n1.3652694\n0.9090386\n\n\nR2\n0.5230656\n0.8948494\n0.4680649\n0.6214585\n0.0666069\n\n\nR3\n0.7306948\n0.9701226\n0.7088635\n1.1028813\n0.2280303\n\n\nR4\n0.5861371\n0.8245860\n0.4833205\n1.0044929\n0.6522573"
  },
  {
    "objectID": "data-accuracy.html#accuracy-1",
    "href": "data-accuracy.html#accuracy-1",
    "title": "5  Reliability and accuracy",
    "section": "7.1 Accuracy",
    "text": "7.1 Accuracy\nIncidence data are binary at the individual level; an individual is diseased or not. Here, different from severity that is estimated, the specimen is classified. Let’s create two series of binary data, each being a hypothetical scenario of assignment of 12 plant specimens into two classes: healthy (0) or diseased (1).\n\norder &lt;- c(1:12)\nactual &lt;- c(1,1,1,1,1,1,1,1,0,0,0,0)\nclass &lt;- c(0,0,1,1,1,1,1,1,1,0,0,0)\n\ndat_inc &lt;- data.frame(order, actual, class)\ndat_inc \n\n   order actual class\n1      1      1     0\n2      2      1     0\n3      3      1     1\n4      4      1     1\n5      5      1     1\n6      6      1     1\n7      7      1     1\n8      8      1     1\n9      9      0     1\n10    10      0     0\n11    11      0     0\n12    12      0     0\n\n\nIn the example above, the rater makes 9 accurate classification and misses 3: 2 diseased plants classified as being disease-free (sample 1 and 2), and 1 healthy plant that is wrongly classified as diseased (sample 9).\nNotice that there are four outcomes:\nTP = true positive, a positive sample correctly classified\nTN = true negative, a negative sample correctly classified\nFP = false positive, a negative sample classified as positive\nFN = false negative, a positive sample classified as positive.\nThere are several metrics that can be calculated with the help of a confusion matrix, also known as error matrix. Considering the above outcomes, here is a how a confusion matrix looks like.\nSuppose a 2x2 table with notation\n\n\n\n\nActual value\n\n\n\n\n\nClassification value\nDiseased\nHealthy\n\n\nDiseased\nTP\nFP\n\n\nHealthy\nFN\nTN\n\n\n\nLet’s create this matrix using a function of the caret package.\n\nlibrary(caret)\nattach(dat_inc)\ncm &lt;- confusionMatrix(factor(class), reference = factor(actual))\ncm\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction 0 1\n         0 3 2\n         1 1 6\n                                          \n               Accuracy : 0.75            \n                 95% CI : (0.4281, 0.9451)\n    No Information Rate : 0.6667          \n    P-Value [Acc &gt; NIR] : 0.3931          \n                                          \n                  Kappa : 0.4706          \n                                          \n Mcnemar's Test P-Value : 1.0000          \n                                          \n            Sensitivity : 0.7500          \n            Specificity : 0.7500          \n         Pos Pred Value : 0.6000          \n         Neg Pred Value : 0.8571          \n             Prevalence : 0.3333          \n         Detection Rate : 0.2500          \n   Detection Prevalence : 0.4167          \n      Balanced Accuracy : 0.7500          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nThe function returns the confusion matrix and several statistics such as accuracy = (TP + TN) / (TP + TN + FP + FN). Let’s manually calculate the accuracy and compare the results:\n\nTP = 3\nFP = 2\nFN = 1\nTN = 6\naccuracy = (TP+TN)/(TP+TN+FP+FN)\naccuracy\n\n[1] 0.75\n\n\nTwo other important metrics are sensitivity and specificity.\n\nsensitivity = TP/(TP+FN)\nsensitivity\n\n[1] 0.75\n\nspecificity = TN/(FP+TN)\nspecificity\n\n[1] 0.75\n\n\nWe can calculate some metrics using the MixtureMissing package.\n\nlibrary(MixtureMissing)\nevaluation_metrics(actual, class)\n\n$matr\n       pred_0 pred_1\ntrue_0      3      1\ntrue_1      2      6\n\n$TN\n[1] 3\n\n$FP\n[1] 1\n\n$FN\n[1] 2\n\n$TP\n[1] 6\n\n$TPR\n[1] 0.75\n\n$FPR\n[1] 0.25\n\n$TNR\n[1] 0.75\n\n$FNR\n[1] 0.25\n\n$precision\n[1] 0.8571429\n\n$accuracy\n[1] 0.75\n\n$error_rate\n[1] 0.25\n\n$FDR\n[1] 0.1428571"
  },
  {
    "objectID": "data-accuracy.html#reliability",
    "href": "data-accuracy.html#reliability",
    "title": "5  Reliability and accuracy",
    "section": "7.2 Reliability",
    "text": "7.2 Reliability\n\nlibrary(psych)\ntab &lt;- table(class, actual)\nphi(tab)\n\n[1] 0.48\n\n\n\n\n\n\nBarnhart, H. X., Haber, M., and Song, J. 2002. Overall Concordance Correlation Coefficient for Evaluating Agreement Among Multiple Observers. Biometrics. 58:1020–1027 Available at: http://dx.doi.org/10.1111/j.0006-341x.2002.01020.x.\n\n\nLin, L. I.-K. 1989. A concordance correlation coefficient to evaluate reproducibility. Biometrics. 45:255 Available at: http://dx.doi.org/10.2307/2532051.\n\n\nShrout, P. E., and Fleiss, J. L. 1979. Intraclass correlations: Uses in assessing rater reliability. Psychological Bulletin. 86:420–428 Available at: http://dx.doi.org/10.1037/0033-2909.86.2.420."
  },
  {
    "objectID": "data-sads.html#definitions",
    "href": "data-sads.html#definitions",
    "title": "6  Standard area diagrams",
    "section": "6.1 Definitions",
    "text": "6.1 Definitions\nAccording to a glossary on phytopathometry (Bock et al. 2021), standard area diagram (SAD) can be defined as “a generic term for a pictorial or graphic representation (drawing or true-color photo) of selected disease severities on plants or plant parts (leaves, fruit, flowers, etc.) generally used as an aid for more accurate visual estimation (on the percentage scale) or classification (using an ordinal scale) of severity on a specimen”.\nThe Standard Area Diagrams (SADs), also known as diagrammatic scales, have a long history of use in plant pathology. The concept dates back to the late 1800s when the Cobb scale was developed, featuring five diagrams depicting a range of severity levels of rust pustules on wheat leaves.\nIn the past 20 years, plant pathologists have leveraged advancements in image processing and analysis tools, along with insights from psychophysical and measurement sciences, to develop SADs that are realistic (e.g., true-color photographs), validated, and depict severities that maximize estimation accuracy. SADs have been created in various color formats (black or white, two-color, or true-color) and with varying incremental scales (approximated linear or logarithmic) (Del Ponte et al. 2017).\nSADs have proven beneficial in increasing the accuracy of visual estimates, as estimating percentage areas is generally more challenging than classifying severity into ordinal classes - there are numerous possibilities on the percentage scale, compared to the finite and small number of classes in ordinal scales. A recent quantitative review confirmed that using SADs often results in improved accuracy and precision of visual estimates. However, it also identified factors related to SAD design and structure, disease symptoms, and actual severity that affected the outcomes. In particular, SADs have shown greater utility for raters who are inherently less accurate and for diseases characterized by small and numerous lesions (Del Ponte et al. 2022). Here are examples of SADs in black and white, two-color, and true-color formats:\n\n\n\n\nFigure 6.1: Actual photos of symptoms of loquat scab on fruit (left) and a SADs with eight diagrams (right). Each number represents severity as the percent area affected (González-Domínguez et al. 2014)\n\n\n\n\n\n\nFigure 6.2: SADs for Glomerella leaf spot on apple leaf. Each number represents severity as the percent area affected (Moreira et al. 2018)\n\n\n\n\n\n\nFigure 6.3: SADs for soybean rust. Each number represents severity as the percent area affected (Franceschi et al. 2020)\n\n\nMore SADs can be found in the SADBank, a curated collection of articles on SAD development and validation. Click on the image below to get access to the database.\n\n\n\nFigure 6.4: SADBank, a curated collection of articles"
  },
  {
    "objectID": "data-sads.html#sad-development-and-validation",
    "href": "data-sads.html#sad-development-and-validation",
    "title": "6  Standard area diagrams",
    "section": "6.2 SAD development and validation",
    "text": "6.2 SAD development and validation\nA systematic review of the literature on SADs highlighted the most important aspects related with the development and validation of the tool (Del Ponte et al. 2017). A list of best practices was proposed in the review to guide future research in the area. Follows the most important aspects to be noted:\n\n\n\n\n\n\nBest practices on SADs development\n\n\n\n\nSample a minimum number (e.g., n = 100) of specimens from natural epidemics representing the range of disease severity and typical symptoms observed.\nUse reliable image analysis software to discriminate disease symptoms from healthy areas to calculate percent area affected.\nWhen designing the illustrations for the SAD set, ensure that the individual diagrams are prepared realistically, whether line drawn, actual photos, or computer generated.\nThe number of diagrams should be no less than 6 and no more than 10, distributed approximately linearly, and spaced no more than 15% apart. Additional diagrams (±2) should be included between 0 and 10% severity.\nFor the validation trial, select at least 50 specimens representing the full range of actual severity and symptom patterns.\nWhen selecting raters (a minimum of 15) for validation, make sure they do not have previous experience in using the SAD under evaluation.\nProvide standard instructions on how to recognize the symptoms of the disease and how to assess severity, first without and then with the SAD.\nIdeally repeat the assessment in time, with a 1- or 2-week interval, both without and with the aid, using the same set of raters in order to evaluate the effect of training and experience on gains in accuracy.\nBoth pre- and posttest experiment conditions should be the same to avoid any impact of distraction on accuracy of estimates during the tests."
  },
  {
    "objectID": "data-sads.html#designing-sads-in-r",
    "href": "data-sads.html#designing-sads-in-r",
    "title": "6  Standard area diagrams",
    "section": "6.3 Designing SADs in R",
    "text": "6.3 Designing SADs in R\nThe diagrams used in a set have been developed using various methods and technologies, ranging from hand-drawn diagrams to actual photographs (Del Ponte et al. 2017). There is an increasing trend towards using actual photos that are digitally analyzed using standard image analysis software to determine the percent area affected. With this approach, a large set of images is analyzed, and some images are chosen to represent the severities in the SAD according to the scale structure.\nIn R, the pliman package has a function called sad() which allows the automatic generation of a SADs with a pre-defined number of diagrams. Firstly, as shown in the previous chapter, the set of images to be selected needs to be analysed using the measure_disease() function. Then, a SADs is automatically generated. In the function, the specimens with the smallest and highest severity will be selected for the SAD. The intermediate diagrams are sampled sequentially to achieve the pre-defined number of images after the severity has been ordered from low to high. More details of the function here.\nLet’s use the same set of 10 soybean leaves, as seen in the previous chapter, depicting the rust symptoms and create the sbr object.\n\nlibrary(pliman)\nh &lt;- image_import(\"imgs/sbr_h.png\")\ns &lt;- image_import(\"imgs/sbr_s.png\")\nb &lt;- image_import(\"imgs/sbr_b.png\")\n\nsbr &lt;- measure_disease(\n  pattern = \"img\",\n  dir_original = \"imgs/originals\" ,\n  dir_processed = \"imgs/processed\",\n  save_image = TRUE,\n  img_healthy = h,\n  img_symptoms = s,\n  img_background = b,\n  show_image = FALSE,\n  show_original = FALSE, # set to TRUE for showing the original.\n  col_background = \"white\", \n  verbose = FALSE\n)\n\nWe are ready to run the sad() function to create a SADs with five diagrams side by side. The resulting SADs is in two-color as standard. Set the argument show_original to TRUE for showing the orignal image in the SADs.\n\nsad(sbr, 5, ncol = 5)\n\n\n\n\n    img  healthy symptomatic rank\n8 img67 99.84530   0.1547021    1\n5 img46 92.65801   7.3419891    3\n4 img38 80.48860  19.5114030    5\n3 img37 59.85029  40.1497100    7\n6  img5 21.02512  78.9748781   10"
  },
  {
    "objectID": "data-sads.html#analysis-of-sads-validation-data",
    "href": "data-sads.html#analysis-of-sads-validation-data",
    "title": "6  Standard area diagrams",
    "section": "6.4 Analysis of SADs validation data",
    "text": "6.4 Analysis of SADs validation data\nTo evaluate the effect of SAD on accuracy components, analyze the data, preferably using concordance analysis methods (see chapter), to fully explore which component is affected and to gain insight into the ramification of errors. Linear regression should not be used as the sole method but it could be complementary for comparison with previous literature.\nInferential methods should be used for testing hypotheses related to gain in accuracy. If parametric tests are used (paired t-test for example), make sure to check that the assumptions are not violated. Alternatively, nonparametric tests (Wilcoxon signed rank) or nonparametric bootstrapping should be used when the conditions for parametric tests are not met. More recently, a (parametric) mixed modelling framework has been used to analyse SADs validation data where raters are taken as a random effects in the model (González-Domínguez et al. 2014; Franceschi et al. 2020; Pereira et al. 2020).\n\n6.4.1 Non parametric boostrapping of differences\nBootstrap is a resampling method where large numbers of samples of the same size are repeatedly drawn, with replacement, from a single original sample. It is commonly used when the distribution of a statistic is unknown or complicated and the sample size is too small to draw a valid inference.\nA bootstrap-based equivalence test procedure was first proposed as complementary to parametric (paired t-test) or non-parametric (Wilcoxon) to analyze severity estimation data in a study on the development and validation of a SADs for pecan scab (Yadav et al. 2012). The equivalence test was used to calculate 95% confidence intervals for each statistic by bootstrapping using the percentile method (with an equivalence test, the null hypothesis is the converse of H0, i.e. the null hypothesis is non-equivalence). In that study, the test was used to compare means of the CCC statistics across raters under two conditions: 1) without versus with the SAD; and 2) experienced versus inexperienced raters.\nTo apply the bootstrap-based equivalence test, let’s work with the CCC data for a sample of 20 raters who estimated severity of soybean rust SAD first without and then with the aid. The CCC was calculated as shown here.\n\nlibrary(tidyverse)\n\nsbr &lt;- tibble::tribble(\n  ~rater, ~aided, ~unaided,\n      1,   0.97,     0.85,\n      2,   0.97,     0.85,\n      3,   0.95,     0.82,\n      4,   0.93,     0.69,\n      5,   0.97,     0.84,\n      6,   0.96,     0.86,\n      7,   0.98,     0.78,\n      8,   0.93,     0.72,\n      9,   0.94,     0.67,\n     10,   0.95,     0.53,\n     11,   0.94,     0.78,\n     12,   0.98,     0.89,\n     13,   0.96,      0.8,\n     14,   0.98,     0.87,\n     15,   0.98,      0.9,\n     16,   0.98,     0.87,\n     17,   0.98,     0.84,\n     18,   0.97,     0.86,\n     19,   0.98,     0.89,\n     20,   0.98,     0.78\n  )\n\nLet’s visualize the data using boxplots. Each point in the plot represents a rater.\n\ntheme_set(theme_gray(base_size = 16))\nsbr |&gt; \n  pivot_longer(2:3, names_to = \"condition\", values_to =\"estimate\") |&gt; \n  ggplot(aes(condition, estimate))+\n  geom_boxplot(outlier.colour = NA)+\n  geom_jitter(width = 0.05, size = 2, alpha = 0.5)+\n  ylim(0.4,1)\n\n\n\n\nTo proceed with bootstrapping, we first create a new variable to hold the differences between the means of the estimates (aided minus unaided). If the 95% CI does not include zero, this means that there was a significant improvement in the statistics.\n\n# diff of means\nsbr$diff &lt;- sbr$aided - sbr$unaided\n\nsbr |&gt; \n  ggplot(aes(x= diff))+\n  theme_gray()+\n  geom_histogram(bins = 10, color = \"white\")\n\n\n\n\nUsing the simpleboot and boot packages of R:\n\nlibrary(simpleboot)\nb.mean &lt;- one.boot(sbr$diff, mean, 999)\nboot::boot.ci(b.mean)\n\nWarning in boot::boot.ci(b.mean): bootstrap variances needed for studentized\nintervals\n\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 999 bootstrap replicates\n\nCALL : \nboot::boot.ci(boot.out = b.mean)\n\nIntervals : \nLevel      Normal              Basic         \n95%   ( 0.1255,  0.1946 )   ( 0.1200,  0.1895 )  \n\nLevel     Percentile            BCa          \n95%   ( 0.1295,  0.1990 )   ( 0.1310,  0.2015 )  \nCalculations and Intervals on Original Scale\n\nmean(b.mean$data)\n\n[1] 0.1595\n\nhist(b.mean)\n\n\n\n\nUsing the bootstrap package:\n\nlibrary(bootstrap)\nb &lt;- bootstrap(sbr$diff, 999, mean)\nquantile(b$thetastar, c(.025,.975))\n\n  2.5%  97.5% \n0.1285 0.1940 \n\nmean(b$thetastar)\n\n[1] 0.1592718\n\nsd(b$thetastar)\n\n[1] 0.01694609\n\nse &lt;- function(x) sqrt(var(x)/length(x))\nse(b$thetastar)\n\n[1] 0.0005361504\n\n\nBoth procedures shown above have led to similar results. The 95% CIs of the differences did not include zero, so a significant improvement in accuracy can be inferred.\n\n\n6.4.2 Parametric and non-parametric paired sample tests\nWhen two estimates are gathered from the same rater at different times, these data points are not independent. In such situations, a paired sample t-test can be utilized to test if the mean difference between two sets of observations is zero. This test requires each subject (or leaf, in our context) to be measured or estimated twice, resulting in pairs of observations. However, if the assumptions of the test (such as normality) are violated, a non-parametric equivalent, such as the Wilcoxon signed-rank test, also known as the Wilcoxon test, can be employed. This alternative is particularly useful when the data are not normally distributed.\nTo proceed with these tests, we first need to ascertain whether our data are normally distributed. We should also verify whether the variances are equal. Let’s now apply these two tests to our data and compare the results.\n\n# normality test\nshapiro.test(sbr$aided)\n\n\n    Shapiro-Wilk normality test\n\ndata:  sbr$aided\nW = 0.82529, p-value = 0.002111\n\nshapiro.test(sbr$unaided)\n\n\n    Shapiro-Wilk normality test\n\ndata:  sbr$unaided\nW = 0.83769, p-value = 0.003338\n\n# equal variance test\nvar.test(sbr$aided, sbr$unaided)\n\n\n    F test to compare two variances\n\ndata:  sbr$aided and sbr$unaided\nF = 0.037789, num df = 19, denom df = 19, p-value = 1.53e-09\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.01495720 0.09547109\nsample estimates:\nratio of variances \n        0.03778862 \n\n# paired t-test\nt.test(sbr$aided, sbr$unaided, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  sbr$aided and sbr$unaided\nt = 8.812, df = 19, p-value = 3.873e-08\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 0.1216158 0.1973842\nsample estimates:\nmean of the differences \n                 0.1595 \n\n# Wilcoxon test\nwilcox.test(sbr$aided, sbr$unaided, paired = TRUE)\n\nWarning in wilcox.test.default(sbr$aided, sbr$unaided, paired = TRUE): cannot\ncompute exact p-value with ties\n\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  sbr$aided and sbr$unaided\nV = 210, p-value = 9.449e-05\nalternative hypothesis: true location shift is not equal to 0\n\n\nAs shown above, the two assumptions were violated, so we could rely more confidently on the non-parametric test.\n\n\n6.4.3 Mixed effects modeling\nMixed models, also known as mixed effects models or multilevel models, are an extension of traditional linear models that are used for analyzing hierarchical or clustered data. These models are particularly useful when dealing with data where observations may not be fully independent, or when the assumption of independence is violated. This happens, for instance, when data are collected over time from the same individuals or units, or when individuals are grouped or nested within higher-level units, such as in our case where measurements are taken by different raters (Brown 2021).\nMixed models enable us to model both fixed and random effects. Fixed effects represent the usual regression parameters that we are primarily interested in estimating, while random effects model the random variation that occurs at different levels of hierarchy or clustering. They allow us to account for variability among different levels of data, like inter-rater variability or intra-subject variability in repeated measures designs.\nIn our context, we consider raters as random effects because we view them as a sample drawn from a larger population of potential raters, and our goal is to generalize our findings to this larger population. If we were to sample additional raters, we would expect these new raters to differ from our current ones. However, by considering raters as a random effect in our model, we can account for this inter-rater variability and make more accurate inferences about the overall population.\nThe random effects component in the mixed model allows us to capture and model the additional variance that is not explicitly accounted for by the fixed effects in our model. In other words, random effects help us to capture and quantify the ‘unexplained’ or ‘residual’ variation that exists within and between the clusters or groups in our data. This could include, for instance, variation in disease measurements that are taken repeatedly from the same subjects. In conclusion, mixed models provide a robust and flexible framework for modeling hierarchical or clustered data, allowing us to effectively account for both fixed and random effects and to make more accurate inferences about our data.\nLet’s start reshaping our data to the long format and assign them to a new data frame.\n\nsbr2 &lt;- sbr |&gt; \n  pivot_longer(2:3, names_to = \"condition\", values_to = \"estimate\")\n\nNow we fit the mixed model using the lmer function of the lme4 package. We will fit the model to the logit of the estimate because they should be bounded between zero and one. Preliminary analysis using non-transformed or log-transformed data resulted in lack of normality of residuals and heterocedasticity (not shown).\n\nlibrary(lme4) \nlibrary(car) # for logit function\nmix &lt;- lmer(logit(estimate) ~ condition + (1 | rater), data = sbr2)\n\n# Check model performance\nlibrary(performance)\ncheck_normality(mix)\n\nOK: residuals appear as normally distributed (p = 0.381).\n\ncheck_heteroscedasticity(mix)\n\nOK: Error variance appears to be homoscedastic (p = 0.961).\n\n# Check effect of condition\ncar::Anova(mix)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: logit(estimate)\n           Chisq Df Pr(&gt;Chisq)    \ncondition 458.44  1  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Estimate the means for each group\nlibrary(emmeans)\nem &lt;- emmeans(mix, ~ condition, transform = \"response\")\nem\n\n condition response      SE   df lower.CL upper.CL\n aided        0.968 0.00359 25.5    0.960    0.975\n unaided      0.817 0.01719 25.5    0.781    0.852\n\nDegrees-of-freedom method: inherited from kenward-roger when re-gridding \nConfidence level used: 0.95 \n\n# Contrast the means\npairs(em)\n\n contrast        estimate     SE   df t.ratio p.value\n aided - unaided    0.151 0.0149 25.5  10.141  &lt;.0001\n\nDegrees-of-freedom method: inherited from kenward-roger when re-gridding \n\n# plot the means with 95% CIs\nplot(em) +\n  coord_flip()+\n  xlim(0.7,1)+\n  theme_gray()\n\n\n\n\nAs shown above, we can reject the null hypothesis that the means are the same between the two groups.\nAlternatively, we could fit GLMMs - generalized linear mixed models, which extend the traditional linear mixed models to accommodate response variables that follow different distributions. They are particularly useful when the response variable does not follow a normal distribution and cannot be adequately transformed to meet the parametric assumptions of traditional linear models. The glmmTMB package in R provides a convenient and flexible platform to fit GLMMs using a variety of distributions (Brooks et al. 2017).\nIn our case, considering our response variable bounded between 0 and 1, a Beta distribution might be a suitable choice. Beta distribution is a continuous probability distribution defined on the interval [0, 1], and is commonly used for modelling variables that represent proportions or percentages.\nThe function glmmTMB() from the glmmTMB package can be used to fit a GLMM with a Beta distribution. In this function, we specify the distribution family as beta_family().\n\nlibrary(glmmTMB)\nmix2 &lt;-  glmmTMB(estimate ~ condition + (1| rater), \n                 data = sbr2, \n                 family = beta_family())\n\nBecause the package performance does not handle the glmmTMB output, we will use the DHARMa package in R which can be particularly useful for checking the assumptions of your GLMM fitted with glmmTMB(). The package provides a convenient way to carry out residual diagnostics for models fitted via maximum likelihood estimation, including GLMMs. This package creates standardized residuals from the observed responses and the predicted responses of a fitted model, and then compares these residuals to a simulated set of residuals under a correct model.\n\nlibrary(DHARMa)\n\nplot(simulateResiduals(mix2))\n\n\n\n\nIn this example, simulateResiduals() generates simulated residuals from your fitted model, and the plot creates a plot of these residuals. This showed that the residuals from our model are uniformly distributed, which is an assumption of GLMMs. We can now proceed with the posthoc analysis and noticed that the results are similar to when the response variable was transformed to logit.\n\ncar::Anova(mix2)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: estimate\n           Chisq Df Pr(&gt;Chisq)    \ncondition 400.93  1  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(emmeans)\nem &lt;- emmeans(mix2, ~ condition, transform = \"response\")\nem\n\n condition response     SE df lower.CL upper.CL\n aided        0.967 0.0043 36    0.958    0.976\n unaided      0.814 0.0167 36    0.780    0.848\n\nConfidence level used: 0.95 \n\n# Contrast the means\npairs(em)\n\n contrast        estimate     SE df t.ratio p.value\n aided - unaided    0.153 0.0139 36  11.001  &lt;.0001\n\n\n\n\n\n\nBock, C. H., Pethybridge, S. J., Barbedo, J. G. A., Esker, P. D., Mahlein, A.-K., and Del Ponte, E. M. 2021. A phytopathometry glossary for the twenty-first century: towards consistency and precision in intra- and inter-disciplinary dialogues. Tropical Plant Pathology. 47:14–24 Available at: http://dx.doi.org/10.1007/s40858-021-00454-0.\n\n\nBrooks, M. E., Kristensen, K., van Benthem, K. J., Magnusson, A., Berg, C. W., Nielsen, A., et al. 2017. glmmTMB balances speed and flexibility among packages for zero-inflated generalized linear mixed modeling. The R Journal. 9:378–400.\n\n\nBrown, V. A. 2021. An Introduction to Linear Mixed-Effects Modeling in R. Advances in Methods and Practices in Psychological Science. 4:251524592096035 Available at: http://dx.doi.org/10.1177/2515245920960351.\n\n\nDel Ponte, E. M., Cazón, L. I., Alves, K. S., Pethybridge, S. J., and Bock, C. H. 2022. How much do standard area diagrams improve accuracy of visual estimates of the percentage area diseased? A systematic review and meta-analysis. Tropical Plant Pathology. 47:43–57 Available at: http://dx.doi.org/10.1007/s40858-021-00479-5.\n\n\nDel Ponte, E. M., Pethybridge, S. J., Bock, C. H., Michereff, S. J., Machado, F. J., and Spolti, P. 2017. Standard Area Diagrams for Aiding Severity Estimation: Scientometrics, Pathosystems, and Methodological Trends in the Last 25 Years. Phytopathology®. 107:1161–1174 Available at: http://dx.doi.org/10.1094/PHYTO-02-17-0069-FI.\n\n\nFranceschi, V. T., Alves, K. S., Mazaro, S. M., Godoy, C. V., Duarte, H. S. S., and Del Ponte, E. M. 2020. A new standard area diagram set for assessment of severity of soybean rust improves accuracy of estimates and optimizes resource use. Plant Pathology. 69:495–505 Available at: http://dx.doi.org/10.1111/ppa.13148.\n\n\nGonzález-Domínguez, E., Martins, R. B., Del Ponte, E. M., Michereff, S. J., García-Jiménez, J., and Armengol, J. 2014. Development and validation of a standard area diagram set to aid assessment of severity of loquat scab on fruit. European Journal of Plant Pathology. Available at: http://dx.doi.org/10.1007/s10658-014-0400-2.\n\n\nMoreira, R. R., Silva Silveira Duarte, H. da, and De Mio, L. L. M. 2018. Improving accuracy, precision and reliability of severity estimates of Glomerella leaf spot on apple leaves using a new standard area diagram set. European Journal of Plant Pathology. 153:975–982 Available at: http://dx.doi.org/10.1007/s10658-018-01610-0.\n\n\nPereira, W. E. L., Andrade, S. M. P. de, Del Ponte, E. M., Esteves, M. B., Canale, M. C., Takita, M. A., et al. 2020. Severity assessment in the Nicotiana tabacum-Xylella fastidiosa subsp. pauca pathosystem: design and interlaboratory validation of a standard area diagram set. Tropical Plant Pathology. 45:710–722 Available at: http://dx.doi.org/10.1007/s40858-020-00401-5.\n\n\nYadav, N. V. S., Vos, S. M. de, Bock, C. H., and Wood, B. W. 2012. Development and validation of standard area diagrams to aid assessment of pecan scab symptoms on fruit. Plant Pathology. 62:325–335 Available at: http://dx.doi.org/10.1111/j.1365-3059.2012.02641.x."
  },
  {
    "objectID": "data-training.html#training-sessions",
    "href": "data-training.html#training-sessions",
    "title": "7  Training sessions",
    "section": "7.1 Training sessions",
    "text": "7.1 Training sessions\nIn the same way that Standard Area Diagrams (SADs) can improve the accuracy of visual estimates of disease severity, exposure to a diverse set of diagrams or actual images with known severity values can significantly enhance a rater’s assessment proficiency. The key to this improvement is the frequent exposure to various levels of severity, which enables the rater to better calibrate their judgments over time.\nAs the rater engages with these reference diagrams or images, they develop a mental model of the severity scale. This mental model is continually refined through repeated exposure to a variety of severity values. This iterative learning process allows the rater to adjust their estimations based on the feedback from known values, thus improving their overall accuracy and precision in disease severity estimation.\nSuch a process, often termed ‘training’, is particularly beneficial in scenarios where visual estimation is the primary tool for assessing disease severity. Training raters using sets of reference images is an effective strategy to enhance inter-rater reliability and consistency over time, especially when coupled with other tools like SADs."
  },
  {
    "objectID": "data-training.html#software",
    "href": "data-training.html#software",
    "title": "7  Training sessions",
    "section": "7.2 Software",
    "text": "7.2 Software\nIndeed, the use of computerized training sessions in assessing disease severity has a rich history, dating back to the mid-1980s when personal computers were first introduced. These early applications were developed using operating systems like DOS or Windows and involved software like AREAGRAM, DISTRAIN, DISEASE.PRO, ESTIMATE, SEVERITY.PRO, and COMBRO. These programs utilized computerized images with specific and measured disease severities to train raters, as outlined in the review by Bock et al. (2021).\nThe main advantage of these computerized training sessions is that they allow raters to familiarize themselves with various disease severity levels, thereby enhancing their performance in severity estimation. Such training has been proven to significantly improve the accuracy and consistency of disease severity evaluations.\nHowever, a potential limitation of this approach is the short-lived nature of the benefits derived from such training. The skills and proficiency gained from these computerized training sessions may degrade over time, necessitating regular retraining for raters to maintain their performance level. This could be due to the fact that estimation skills, like many other skills, require regular practice for maintenance. Without ongoing exposure to severity scales and continued practice, the accuracy and precision of a rater’s estimates may decline.\nTo address this challenge, it would be beneficial to implement a structured training regimen that includes regular retraining sessions. This could help ensure the continued proficiency of raters in estimating disease severity, thus maintaining the accuracy and reliability of assessments over time. Furthermore, it would be advantageous to investigate the optimal frequency and structure of these training sessions to maximize their effectiveness and sustainability in the long term.\n\n\n\nFigure 7.1: Selected screenshots from Severity.Pro, the disease assessment training program by Forrest W. Nutter (Madden et al. 2021).\n\n\n\n7.2.1 Online training tools\nIn Brazil, the “Sistema de treinamento de acuidade visual” was initially developed as a web-based system to train raters in assessing citrus canker. The system has evolved over time and now has a current version that is accessible on both iOS and Android platforms. You can find the current version of the system at this link. This platform provides an interactive training experience to enhance the ability of raters in accurately assessing the severity of citrus canker.\nIn Mexico, a specific application called Validar-PER has been developed to train raters in visually assessing the severity of coffee leaf rust. This application utilizes diagrammatic log-based scales as a standardized approach for severity assessment. You can access the Validar-PER application online here. The application aims to improve the proficiency of raters in evaluating the severity of coffee leaf rust using a systematic and standardized methodology.\n\n\n\nFigure 7.2: Screen of Validar-PER, an online training module for assessing coffee leaf rust severity\n\n\n\n\n7.2.2 Training software made with R\n\n7.2.2.1 TraineR\nTraineR, developed by the author of this book, is created using R and Shiny. Its purpose is to train users in assessing disease severity, specifically expressed as the percentage area of an organ (leaf or fruit) affected by lesions.\nTo use the app, users can adjust parameters for organ shape, organ color, as well as lesion shape, lesion color, lesion number, and lesion size. These adjustments will generate a standard area diagram with an ellipsoidal shape.\nTo initiate the training, users should first set the desired number of attempts for the session and click on the “generate new” button. A diagram will then be displayed, and users should input their estimate of the diseased area as a numeric value in percentage. The estimate will be recorded and shown in a table along with the actual value, enabling a comparison between the actual and estimated values.\nUsers can continue generating new diagrams and providing estimates until they reach the defined number of attempts. Once the final attempt is completed, the app will present the accuracy in the form of Lin’s concordance correlation coefficient to the user. Plots depicting the relationship between estimates and actual values, as well as the error of the estimates, will be displayed. Furthermore, comprehensive accuracy statistics are also made available.\nCurrently, the app has certain limitations, including the inability to overlap lesions and a maximum severity representation of approximately 60%. Nonetheless, it remains a valuable educational and demonstration tool.\n\n\n\nFigure 7.3: Screen of TraineR, an online app for training in the assessment of plant disease severity\n\n\n\n\n7.2.2.2 Trainer2\nTrainer2 the second generation of TraineR, takes advantage of actual photographs showcasing disease symptoms. This updated version allows for testing the ability of raters to assess disease severity, particularly by evaluating the percentage area affected based on real symptoms captured in the photographs.\nBy utilizing actual images, Trainer2 offers a more realistic and practical approach to training raters. Raters can now evaluate disease severity by visually inspecting the symptoms depicted in the photographs, enhancing their ability to accurately assess the extent of damage in terms of the affected area.\nThe incorporation of real symptoms in Trainer2 serves as a valuable tool for evaluating and refining the skills of raters in disease severity assessment. It provides a more authentic training experience and helps raters become proficient in identifying and quantifying the extent of disease based on visual cues observed in real-life scenarios.\n\n\n\nFigure 7.4: Screen of traineR2, an online for training in the assessment of plant disease severity based on real symptoms captured in photographs\n\n\n\n\n\n\nBock, C. H., Chiang, K.-S., and Del Ponte, E. M. 2021. Plant disease severity estimated visually: a century of research, best practices, and opportunities for improving methods and practices to maximize accuracy. Tropical Plant Pathology. 47:25–42 Available at: http://dx.doi.org/10.1007/s40858-021-00439-z.\n\n\nMadden, L. V., Esker, P. D., and Pethybridge, S. J. 2021. Forrest W. Nutter, Jr.: a career in phytopathometry. Tropical Plant Pathology. 47:5–13 Available at: http://dx.doi.org/10.1007/s40858-021-00469-7."
  },
  {
    "objectID": "temporal-dpc.html#how-epidemics-occur",
    "href": "temporal-dpc.html#how-epidemics-occur",
    "title": "8  Disease progress curves",
    "section": "8.1 How epidemics occur",
    "text": "8.1 How epidemics occur\nBefore knowing how epidemics develop in time, it is important to understand how an epidemic occur. An epidemic begins when the primary inoculum (a variable number of propagules able to infect the plant) that is surviving somewhere establishes an intimate contact with individuals of the host population - this process is called infection. These inocula are usually surviving externally to the plant host and need to disperse (move), passively or by means of a vector, to reach the plant. It can also be that a growing host encounter a localized (static) source of inoculum.\nOnce the infection is established, the pathogen colonizes the plant tissues and disease symptoms are noticed. When this happens, the incubation period can be measured in time units. A successful colonization will lead to reproduction of the pathogen inside and/or external to the crop, and so the latent period is completed, and can also be measure in time units. Finally, the infectious period takes place and continues until the pathogen is not capable of producing the secondary inoculum on the infected site.\n\n\n\n\n\nflowchart\n  A[Infection] --&gt; B[Colonization]\n  B --&gt; C[Reproduction]\n  C -. New inoculum .-&gt; D[Dispersal]\n  E[Survival] -- Primary inoculum --&gt; D\n  D  --&gt; A\n  D  -.-&gt; A\n  C --&gt; E \n\n\nFigure 8.1: Five main processes of the disease cycle\n\n\n\n\nEpidemiologists are generally interested in determining the length of the incubation, latent, and infectious periods as influenced by factors related to the host, pathogen, or environment. This is relevant because the longer it takes for the completion of the incubation and latent periods, the lower the potential number of repeated cycles. In summary, a single “infection cycle” represents all events that occur from infection to dispersal, and this occurs only once for many diseases, while for others there may be multiple cycles, which are defined as an “infection chain.”\n\n\nCode\nlibrary(tidyverse)\nperiods &lt;- tibble::tribble(\n  ~period, ~length, ~color, ~order,\n  \"Incubation\", 10, 0, 1,\n  \"Latent\" , 15, 0, 2,\n  \"Infectious\", 25, 15, 3\n)\n\np &lt;- periods |&gt; \n  ggplot(aes(reorder(period, order), length, fill = period))+\n  geom_col()+\n  geom_col(aes(period, color), color = \"white\", fill = \"white\")+\n  coord_flip()+\n  theme_void()+\n  theme(legend.position = \"none\")+\n  annotate(geom = \"text\", x = 0.5, y = 15, label = \"----- Time ---&gt;\")+\n  annotate(geom = \"text\", x = 1, y = 5, label = \"Incubation\", color = \"white\")+\n  annotate(geom = \"text\", x = 2, y = 8, label = \"Latent\", color = \"white\")+\n  annotate(geom = \"text\", x = 3, y = 20, label = \"Infectious\", color = \"white\")+\n  annotate(geom = \"text\", x = 1, y = 10.5, label = \"Visible symptoms\", angle = 90, size = 1.7)+\n  annotate(geom = \"text\", x = 2, y = 15.5, label = \"Reproduction starts\", angle = 90, size =1.7)+\n  annotate(geom = \"text\", x = 3, y = 25.5, label = \"Reproduction ends\", angle = 90, size =1.7)+\n  scale_fill_manual(values = c(\"darkgreen\",  \"brown\", \"darkorange\"))+\n  geom_segment(mapping=aes(x=0.6, y=0, xend=0.6, yend=10), arrow=arrow(ends='both'), size=1, color = \"black\")+ \n  geom_segment(mapping=aes(x=1.6, y=0, xend=1.6, yend=15), arrow=arrow(ends='both'), size=1, color = \"black\")  +\n   geom_segment(mapping=aes(x=2.6, y=15, xend=2.6, yend=25), arrow=arrow(ends='both'), size=1, color = \"black\") \n  library(png)\n  library(cowplot)\n  incubation &lt;- readPNG(\"imgs/incubation3.png\", native = TRUE)\n  latent &lt;- readPNG(\"imgs/latent3.png\", native = TRUE)\n  p2 &lt;- p + draw_image(incubation , x = 0.5, y = 13, scale = 5)+\n    draw_image(latent , x = 1.5, y = 20, scale = 5)\n  ggsave(\"imgs/periods.png\", width =6, height =2, bg = \"white\")  \n\n\n\n\n\nFigure 8.2: Three time-related epidemiological periods and their relations with stages of the disease cycle including colonization (symptoms) and reproduction (sporulation in the case of fungi). Drawings of apple scab symptoms and signs adapted from Agrios (2005)"
  },
  {
    "objectID": "temporal-dpc.html#disease-curves",
    "href": "temporal-dpc.html#disease-curves",
    "title": "8  Disease progress curves",
    "section": "8.2 Disease curves",
    "text": "8.2 Disease curves\nA key understanding of the epidemics relates to the knowledge of rates and patterns. Epidemics can be viewed as dynamic systems that change their state as time goes. The first and simplest way to characterize such changes in time is to produce a graphical plot called disease progress curve (DPC). This curve can be obtained as long as the intensity of the disease (y) in the host population is assessed sequentially in time (t).\nA DPC summarizes the interaction of the three main components of the disease triangle occurring during the epidemic. The curves can vary greatly in shape according to variations in each of the components, in particular due to management practices that alter the course of the epidemics and for which the goal is to stop disease increase. We can create a data frame in R for a single DPC and make a plot using ggplot. By convention we use t for time and y for disease intensity, expressed in percentage (0 to 100%).\nFirstly, let’s load the essential R packages and set up the environment.\n\nlibrary(tidyverse) # essential packages \ntheme_set(theme_gray(base_size = 16)) # set global theme\n\nThere are several ways to create a data frame in R. I like to use the tribble function as below. The entered data will be assigned to a dataframe called dpc.\n\ndpc &lt;- \n  tribble(\n   ~t,  ~y, \n   0,  8, \n   7,  13, \n  14,  78, \n  21,  92, \n  28,  99, \n  35, 99.5, \n  42, 99.9, \n  )\n\nNow the plot\n\ndpc1 &lt;- dpc |&gt;\n  ggplot(aes(t, y)) +\n  theme_gray()+\n  geom_line(size = 1)+\n  geom_point(size = 4, shape = 16)+\n  labs(x = \"Assessment time (days)\",\n       y = \"Disease intensity (%)\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\nggsave(\"imgs/dpc1.png\", dpc1)\n\n\n\n\nFigure 8.3: A typical disease progress curve for an epidemic that reaches the maximum value"
  },
  {
    "objectID": "temporal-dpc.html#epidemic-classification",
    "href": "temporal-dpc.html#epidemic-classification",
    "title": "8  Disease progress curves",
    "section": "8.3 Epidemic classification",
    "text": "8.3 Epidemic classification\nVanderplank analysed the shapes of great number of epidemic curves and classified the epidemics into two basic types: monocyclic or polycyclic (Vanderplank 1963). In monocyclic epidemics, inoculum capable of infecting the crop is not produced during the epidemics. These epidemics are initiated and maintained only by the primary inoculum. There is no secondary infection and hence no further spread of newly produced inoculum among the host individuals. Tipically, the progress curves for monocyclic epidemics have a saturation type shape.\nConversely, when the secondary inoculum produced during the epidemics is capable of infecting the host during the same crop cycle, a polycyclic epidemic is established. The number of repeated cycles just depends on how long it takes to complete a single infection cycle. These epidemics most commonly present a sigmoid shape Figure 8.4.\n\n\nCode\nlibrary(tidyverse)\ntheme_set(theme_bw(base_size = 16))\n\nlibrary(epifitter)\npolyc &lt;- sim_logistic(N = 50, dt = 5, \n                      y0 = 0.01, r = 0.2, \n                      K = 0.8, n = 1, \n                      alpha =0)\n\np &lt;- polyc |&gt; \n  ggplot(aes(time, y))+\n  geom_point(aes(time, y), size =19, shape =1)+\n  geom_line()+\n  ylim(0,1)+\n  theme_gray()+\n  labs(x = \"Time\", y = \"Disease intensity\")\n\n\nmonoc &lt;- sim_monomolecular(N = 50, dt = 5, \n                           y0 = 0.01, r = 0.1,\n                           K = 0.8, n = 1, \n                           alpha =0)\nlibrary(ggforce)\nm &lt;- monoc |&gt; \n  ggplot(aes(time, y))+\n  geom_point(aes(x = 25, y = 0.5), size =90, shape = 1)+\n   geom_line()+\n  theme_gray()+\n  ylim(0,1)+\n  labs(x = \"Time\", y = \"Disease intensity\")\n\nlibrary(patchwork)\ncycles &lt;- m | p\nggsave(\"imgs/cycles.png\", bg = \"white\", width = 8, height =4)\n\n\n\n\n\nFigure 8.4: Hypothetical curves for monocyclic (left) and polycyclic (right) epidemics. Each circle represents a single infection cycle."
  },
  {
    "objectID": "temporal-dpc.html#curve-descriptors-and-audpc",
    "href": "temporal-dpc.html#curve-descriptors-and-audpc",
    "title": "8  Disease progress curves",
    "section": "8.4 Curve descriptors and AUDPC",
    "text": "8.4 Curve descriptors and AUDPC\nThe depiction and analysis of disease progress curves can provide useful information for gaining understanding of the underlying epidemic process. The curves are extensively used to evaluate how disease control measures affect epidemics. When characterizing DPCs, a researcher may be interested in describing and comparing epidemics that result from different treatments, or simply in their variations as affected by changes in environment, host or pathogen.\nThe precision and complexity of the analysis of progress curve data depends on the objective of the study. In general, the goal is to synthesize similarities and differences among epidemics based on common descriptors of the disease progress curves. For example, the simple appraisal of the disease intensity at any time during the course of the epidemic should be sufficient for certain situations. Furthermore, a few quantitative and qualitative descriptors can be extracted including:\n\nEpidemic duration\nMaximum disease\nCurve shape\nArea under the area under the disease progress curve (AUDPC).\n\nLet’s visualize the AUDPC in the same plot that we produced above.\n\ndpc2 &lt;- dpc |&gt;\n  ggplot(aes(t, y)) +\n  labs(x = \"Assessment time (days)\",\n       y = \"Disease intensity (%)\")+\n    geom_area(fill = \"darkorange\")+\n    geom_line(size = 1)+\n  theme_gray()+\n  geom_point(size = 3, shape = 16)+\n  scale_x_continuous(breaks = c(0, 7, 14, 21, 28, 35, 42))\nggsave(\"imgs/dpc2.png\")\n\n\n\n\nFigure 8.5: Representation of the area under the disease progress curve\n\n\nThe AUDPC summarizes the “total measure of disease stress” and is largely used to compare epidemics (Jeger and Viljanen-Rollinson 2001). The most common approach to calculate AUDPC is the trapezoidal method, which splits the disease progress curves into a series of rectangles, calculating the area of each of them and then summing the areas. Let’s extend the plot code to show those rectangles using the annotate function.\n\n\nCode\ndpc3 &lt;- dpc |&gt;\n  ggplot(aes(t, y)) +\n  theme_gray()+\n  labs(x = \"Assessment time (days)\",\n       y = \"Disease intensity (%)\")+\n  annotate(\"rect\", xmin = dpc$t[1], xmax = dpc$t[2], \n           ymin = 0, ymax = (dpc$y[1]+ dpc$y[2])/2, \n           color = \"darkgreen\", fill = \"darkorange\")+\n   annotate(\"rect\", xmin = dpc$t[2], xmax = dpc$t[3], \n            ymin = 0, ymax = (dpc$y[2]+ dpc$y[3])/2, \n            color = \"darkgreen\", fill = \"darkorange\")+\n   annotate(\"rect\", xmin = dpc$t[3], xmax = dpc$t[4], \n            ymin = 0, ymax = (dpc$y[3]+ dpc$y[4])/2,\n            color = \"darkgreen\", fill = \"darkorange\")+\n   annotate(\"rect\", xmin = dpc$t[4], xmax = dpc$t[5], \n            ymin = 0, ymax = (dpc$y[4]+ dpc$y[5])/2, \n            color = \"darkgreen\", fill = \"darkorange\")+\n   annotate(\"rect\", xmin = dpc$t[5], xmax = dpc$t[6], \n            ymin = 0, ymax = (dpc$y[5]+ dpc$y[6])/2, \n            color = \"darkgreen\",fill = \"darkorange\")+\n   annotate(\"rect\", xmin = dpc$t[6], xmax = dpc$t[7], \n            ymin = 0, ymax = (dpc$y[6]+ dpc$y[7])/2, \n            color = \"darkgreen\", fill = \"darkorange\")+\n  geom_line(size = 1)+\n  geom_point(size = 3, shape = 16)+\n  annotate(geom = \"text\", x = 26.5, y = 50,\n           label = \"AUDPC = 3048.5\", size = 6)+\n  scale_x_continuous(breaks = c(0, 7, 14, 21, 28, 35, 42))\nggsave(\"imgs/dpc3.png\")\n\n\n\n\n\nFigure 8.6: Representation of the area under the disease progress curve calculated using the trapezoidal method\n\n\nIn R, we can obtain the AUDPC for the DPC we created earlier using the AUDPC function offered by the epifitter package. Because we are using the percent data, we need to set the argument y_proportion = FALSE. The function returns the absolute AUDPC. If one is interested in relative AUDPC, the argument type should be set to \"relative\". There is also the alternative to AUDPC, the area under the disease progress stairs (AUDPS) (Simko and Piepho 2012).\n\nlibrary(epifitter)\nAUDPC(dpc$t, dpc$y, \n      y_proportion = FALSE)\n\n[1] 3048.15\n\n# The relative AUDPC \nAUDPC(dpc$t, dpc$y, \n      y_proportion = FALSE, \n      type = \"relative\")\n\n[1] 0.72575\n\n# To calculate AUDPS, the alternative to AUDPC\nAUDPS(dpc$t, dpc$y, \n      y_proportion = FALSE)\n\n[1] 3425.8\n\n\n\n\n\n\nJeger, M. J., and Viljanen-Rollinson, S. L. H. 2001. The use of the area under the disease-progress curve (AUDPC) to assess quantitative disease resistance in crop cultivars. Theoretical and Applied Genetics. 102:32–40 Available at: http://dx.doi.org/10.1007/s001220051615.\n\n\nSimko, I., and Piepho, H.-P. 2012. The Area Under the Disease Progress Stairs: Calculation, Advantage, and Application. Phytopathology®. 102:381–389 Available at: http://dx.doi.org/10.1094/phyto-07-11-0216.\n\n\nVanderplank, J. 1963. Plant disease epidemics and control. Elsevier. Available at: http://dx.doi.org/10.1016/C2013-0-11642-X."
  },
  {
    "objectID": "temporal-models.html#non-flexible-models",
    "href": "temporal-models.html#non-flexible-models",
    "title": "9  Population models",
    "section": "9.1 Non-flexible models",
    "text": "9.1 Non-flexible models\nThese population dynamics models require at least two parameters, hence they are known as non-flexible, as opposed to the flexible ones for which there are at least one additional (third) parameter.\nFollowing the convention proposed by (Madden et al. 2017) in their book “The study of plant disease epidemics”:\n\ntime is represented by \\(t\\)\ndisease intensity by \\(y\\)\nthe rate of change in \\(y\\) between two time units is represented by \\(\\frac{dy}{dt}\\)\n\nNow we can proceed and learn which non-flexible models exist and for which situation they are more appropriate.\n\n9.1.1 Exponential\nThe differential equation for the exponential model is given by\n\\(\\frac{dy}{dt} = r_E.y\\),\nwhere \\(r_E\\) is the apparent infection rate (subscript E for this model) (sensu Vanderplank) and \\(y\\) is the disease intensity. Biologically, this formulation suggests that diseased plants, or \\(y\\), and \\(r_E\\) at each time contribute to disease increase. The value of \\(\\frac{dy}{dt}\\) is minimal when \\(y = 0\\) and increases exponentially with the increase in \\(y\\).\nThe integral for the exponential model is given by\n\\(y = y_0 e^{r_Et}\\),\nwhere \\(y0\\) is and \\(r\\) are obtained via estimation. Let’s simulate two curves by varying \\(r\\) while fixing \\(y0\\) and varying the latter while fixing \\(r_E\\). We produce the two plots in ggplot and add the predicted curve using the `stat_function`. But first, we need to define values for the two model parameters. Further modifications to these values will be handled directly in the simulation (e.g. doubling infection rate, reducing initial inoculum by half, etc.).\n\nlibrary(tidyverse) # essential packages \ntheme_set(theme_gray(base_size = 16)) # set global theme\n\n\ny0 &lt;- 0.001 \nr &lt;- 0.06 \ntmax &lt;- 60 # maximum duration t of the epidemics\ndat &lt;- data.frame(t = seq(1:tmax), y = seq(0:1)) # define the axes\n\nIn the plot below, note that the infection rate in one curve was doubled (\\(r\\) = 0.12)\n\ndat |&gt;\n  ggplot(aes(t, y)) +\n  stat_function(fun = function(t) y0 * exp(r * t), linetype = 1) +\n  stat_function(fun = function(t) y0 * exp(r * 2 * t), linetype = 2) +\n  ylim(0, 1) +\n  theme_gray()+\n  labs(x = \"Time\")\n\n\n\n\nFigure 9.1: Exponential curves with two rates of infection (0.06 and 0.12) and the same initial inoculum (0.001)\n\n\n\n\nNow the inoculum was increased five times while using the same doubled rate.\n\ndat |&gt;\n  ggplot(aes(t, y)) +\n  stat_function(fun = function(t) y0 * exp(r * 2 * t), linetype = 1) +\n  stat_function(fun = function(t) y0 * 5 * exp(r * 2 * t), linetype = 2) +\n  ylim(0, 1) +\n  theme_gray()+\n  labs(x = \"Time\")\n\n\n\n\nFigure 9.2: Exponential curves with the same rate of infection (0.12) and single and five times the initial inoculum (0.001)\n\n\n\n\n\n\n9.1.2 Monomolecular\nThe differential of the monomolecular model is given by\n\\(\\frac{dy}{dt} = r_M (1-y)\\)\nwhere now the \\(r_M\\) is the rate parameter of the monomolecular model and \\((1-y)\\) is the proportion of non-infected (healthy) individuals or host tissue. Note that \\(\\frac{dy}{dt}\\) is maximum when \\(y = 0\\) and decreases when \\(y\\) approaches 1. Its decline is due to decrease in the proportion of individuals or healthy sites with the increase in \\(y\\). Any inoculum capable of infecting the host will more likely land on infected individuals or sites.\nThe integral of the monomolecular model is given by\n\\(\\frac{dy}{dt} = 1 - (1-y)e^{-r_Mt}\\)\nThis model commonly describes the temporal patterns of the monocyclic epidemics. In those, the inoculum produced during the course of the epidemics do not contribute new infections. Therefore, different from the exponential model, disease intensity \\(y\\) does not affect the epidemics and so the absolute rate is proportional to \\((1-y)\\).\nLet’s simulate two monomolecular curve with different rate parameters where one is one third of the other.\n\ndat |&gt;\n  ggplot(aes(t, y)) +\n  stat_function(fun = function(t) 1 - ((1 - y0) * exp(-r * t))) +\n  stat_function(fun = function(t) 1 - ((1 - y0) * exp(-(r / 3) * t))) +\n  labs(x = \"Time\") +\n  theme_gray(base_size = 16)+\n  annotate(geom = \"text\", x = 35, y = 0.77, label = \"r = 0.06\") +\n  annotate(geom = \"text\", x = 50, y = 0.55, label = \"r = 0.02\")\n\n\n\n\nFigure 9.3: Monomolecular curves with two rates of infection (0.06 and 0.02) and the same initial inoculum (0.001)\n\n\n\n\nNow inoculum was increased 100 times with the reduced rate.\n\ndat |&gt;\n  ggplot(aes(t, y)) +\n  stat_function(fun = function(t) 1 - ((1 - y0) * exp(-r / 2 * t))) +\n  stat_function(fun = function(t) 1 - ((1 - (y0 * 100)) * exp(-r / 2 * t))) +\n  theme_gray(base_size = 16)+\n  labs(x = \"Time\") +\n  annotate(geom = \"text\", x = 35, y = 0.77, label = \"y0 = 0.1\") +\n  annotate(geom = \"text\", x = 45, y = 0.65, label = \"y0 = 0.001\")\n\n\n\n\nFigure 9.4: Monomolecular curves with one rate (0.06) and the initial inoculum increased 100 times\n\n\n\n\n\n\n9.1.3 Logistic\nThe logistic model is a more elaborated version of the two previous models as it incorporates the features of them both. Its differential is given by\n\\(\\frac{dy}{dt} = r_L. y . (1 - y)\\),\nwhere \\(r_L\\) is the infection rate of the logistic model, \\(y\\) is the proportion of diseased individuals or host tissue and \\((1-y)\\) is the proportion of non-affected individuals or host area.\nBiologically, \\(y\\) in its differential equation implies that \\(\\frac{dy}{dt}\\) increases with the increase in \\(y\\) (as in the exponential) because more disease means more inoculum. However, \\((1-y)\\) leads to a decrease in \\(\\frac{dy}{dt}\\) when \\(y\\) approaches the maximum \\(y=1\\), because the proportion of healthy individuals or host area decreases (as in the monomolecular). Therefore, \\(\\frac{dy}{dt}\\) is minimal at the onset of the epidemics, reaches a maximum when \\(y/2\\) and declines until \\(y=1\\).\nThe integral is given by\n\\(y = \\frac{1}{1 + (1-y_0).e^{-r.t}}\\),\nwhere \\(r_L\\) is the apparent infection rate of the logistic model and \\(y0\\) is the disease intensity at \\(t=0\\). This model provides a good fit to polycyclic epidemics.\nLet’s check two curves where in one the infection rate is double while keeping the same initial inoculum.\n\ndat |&gt;\n  ggplot(aes(t, y)) +\n  stat_function(\n    linetype = 2,\n    fun = function(t) 1 / (1 + ((1 - y0) / y0) * exp(-r * 2 * t))\n  ) +\n  stat_function(fun = function(t) 1 / (1 + ((1 - y0) / y0) * exp(-r * 4 * t))) +\n  labs(x = \"Time\") +\n  theme_gray()+\n  annotate(geom = \"text\", x = 41, y = 0.77, label = \"r = 0.18\") +\n  annotate(geom = \"text\", x = 50, y = 0.10, label = \"r = 0.024\")\n\n\n\n\nFigure 9.5: Logistic curves with two rates of infection (0.18 and 0.024) and the same initial inoculum (0.001)\n\n\n\n\nNow the inoculum is reduced 10 times for a same infection rate.\n\ndat |&gt;\n  ggplot(aes(t, y)) +\n  stat_function(\n    linetype = 2,\n    fun = function(t) 1 / (1 + ((1 - (y0 / 10)) / (y0 / 10)) * exp(-r * 3 * t))\n  ) +\n  stat_function(fun = function(t) 1 / (1 + ((1 - y0) / y0) * exp(-r * 3 * t))) +\n  labs(x = \"Time\") +\n  theme_gray()+\n  annotate(geom = \"text\", x = 35, y = 0.77, label = \"y0 = 0.001\") +\n  annotate(geom = \"text\", x = 50, y = 0.10, label = \"y0 = 0.0001\")\n\n\n\n\nFigure 9.6: Logistic curves with a single rate of infection (0.24) and two initial inoculum (0.001 and 0.0001)\n\n\n\n\n\n\n9.1.4 Gompertz\nThe Gompertz model is similar to the logistic and also provides a very good fit to several polycyclic diseases. The differential equation is given by\n\\(\\frac{dy}{dt} = r_G.[ln(1) - ln(y)]\\)\nDifferently from the logistic, the variable representing the non-infected individuals or host area is \\(-ln(y)\\). The integral equation is given by\n\\(y = e^{(ln(y0)).{e^{-r_G.t)}}}\\),\nwhere \\(r_G\\) is the apparent infection rate for the Gompertz models and \\(y_0\\) is the disease intensity at \\(t = 0\\).\nLet’s check curves for two rates.\n\ndat |&gt;\n  ggplot(aes(t, y)) +\n  stat_function(\n    linetype = 2,\n    fun = function(t) exp(log(y0) * exp(-r/2 * t))\n  ) +\n  stat_function(fun = function(t) exp(log(y0) * exp(-r*2 * t))) +\n  labs(x = \"Time\") +\n  theme_gray()+\n  annotate(geom = \"text\", x = 41, y = 0.77, label = \"r = 0.12\") +\n  annotate(geom = \"text\", x = 50, y = 0.10, label = \"r = 0.03\")\n\n\n\n\nFigure 9.7: Gompertz curves with two rates of infection (0.12 and 0.03) and the same initial inoculum (0.001)\n\n\n\n\nAnd those when inoculum was reduced one thousand times.\n\ndat |&gt;\n  ggplot(aes(t, y)) +\n  stat_function(\n    linetype = 2,\n    fun = function(t) exp(log(y0) * exp(-r*2 * t))\n  ) +\n  stat_function(fun = function(t) exp(log(y0/1000) * exp(-r*2 * t))) +\n  labs(x = \"Time\") +\n  theme_gray()+\n  annotate(geom = \"text\", x = 15, y = 0.77, label = \"y0 = 0.001\") +\n  annotate(geom = \"text\", x = 25, y = 0.10, label = \"y0 = 0.00001\")\n\n\n\n\nFigure 9.8: Gompertz curves with a single rate of infection (0.12) and two levels of initial inoculum (0.001 and 0.00001)"
  },
  {
    "objectID": "temporal-models.html#interactive-application",
    "href": "temporal-models.html#interactive-application",
    "title": "9  Population models",
    "section": "9.2 Interactive application",
    "text": "9.2 Interactive application\nA shiny app was developed to demonstrate these four models interactively. Click on the image below to get access to the app.\n\n\n\nFigure 9.9: Screenshot of the application to visualize the population dynamics models by varying the model's parameters\n\n\n\n\n\n\nMadden, L. V., Hughes, G., and van den Bosch, F. 2017. Temporal analysis i: Quantifying and comparing epidemics. In The American Phytopathological Society, p. 63–116. Available at: http://dx.doi.org/10.1094/9780890545058.004."
  },
  {
    "objectID": "temporal-fitting.html#non-replicated-epidemics",
    "href": "temporal-fitting.html#non-replicated-epidemics",
    "title": "10  Model fitting",
    "section": "10.1 Non-replicated epidemics",
    "text": "10.1 Non-replicated epidemics\nWe will compare three DPCs of the incidence of tobacco etch, a virus disease, in peppers. Evaluations of incidence were evaluated at a 7-day interval up to 49 days. The data are available in chapter 4 (page 93) (Madden et al. 2017). Let’s input the data manually and create a data frame. First column is the assessment time and the other columns correspond to the treatments, called groups in the book, from 1 to 3."
  },
  {
    "objectID": "temporal-fitting.html#entering-data",
    "href": "temporal-fitting.html#entering-data",
    "title": "10  Model fitting",
    "section": "10.2 Entering data",
    "text": "10.2 Entering data\n\nlibrary(tidyverse) # essential packages \ntheme_set(theme_bw(base_size = 16)) # set global theme\n\n\npepper &lt;- \n  tribble(\n   ~t,  ~`1`,  ~`2`,  ~`3`,\n   0,  0.08, 0.001, 0.001,\n   7,  0.13,  0.01, 0.001,\n  14,  0.78,  0.09,  0.01,\n  21,  0.92,  0.25,  0.05,\n  28,  0.99,   0.8,  0.18,\n  35, 0.995,  0.98,  0.34,\n  42, 0.999,  0.99,  0.48,\n  49, 0.999, 0.999,  0.74\n  )"
  },
  {
    "objectID": "temporal-fitting.html#visualize-the-dpcs",
    "href": "temporal-fitting.html#visualize-the-dpcs",
    "title": "10  Model fitting",
    "section": "10.3 Visualize the DPCs",
    "text": "10.3 Visualize the DPCs\nBefore proceeding with model selection and fitting, let’s visualize the three epidemics. The code below reproduces quite exactly the top plot of Fig. 4.15 (Madden et al. (2017) page 94). The appraisal of the curves might give us a hint on which models are the best candidates.\nBecause the data was entered in the wide format (each DPC is in a different column) we need to reshape it to the long format. The pivot_longer() function will do the job of reshaping from wide to long format so we can finally use the ggplot() function to produce the plot.\n\npepper |&gt; \n  pivot_longer(2:4, names_to =\"treat\", values_to = \"inc\") |&gt; \n  ggplot (aes(t, inc, \n              linetype = treat, \n              shape = treat, \n              group = treat))+\n  geom_line(size = 1)+\n  geom_point(size =3, shape = 16)+\n  annotate(geom = \"text\", x = 15, y = 0.84, label = \"1\")+\n  annotate(geom = \"text\", x = 23, y = 0.6, label = \"2\")+\n  annotate(geom = \"text\", x = 32, y = 0.33, label = \"3\")+\n  labs(y = \"Disease incidence (y)\",\n       x = \"Time (days)\")+\n  theme(legend.position = \"none\")\n\n\n\n\nFigure 10.1: Disease progress curves for three tobacco etch epidemics in pepper. Reproduced from Madden et al. (2017) page 94\n\n\n\n\nMost of the three curves show a sigmoid shape with the exception of group 3 that resembles an exponential growth, not reaching the maximum value, and thus suggesting an incomplete epidemic. We can easily eliminate the monomolecular and exponential models and decide on the other two non-flexible models: logistic or Gompertz. To do that, let’s proceed to model fitting and evaluate the statistics for supporting a final decision. There are two modeling approaches for model fitting in epifitter: the linear or nonlinear parameter-estimation methods."
  },
  {
    "objectID": "temporal-fitting.html#fitting-single-epidemics",
    "href": "temporal-fitting.html#fitting-single-epidemics",
    "title": "10  Model fitting",
    "section": "10.4 Fitting: single epidemics",
    "text": "10.4 Fitting: single epidemics\nAmong the several options offered by epifitter we start with the simplest one, which is fit a model to a single epidemics using the linear regression approach. For such, the fit_lin() requires two arguments: time (time) and disease intensity (y) each one as a vector stored or not in a dataframe.\nSince we have three epidemics, fit_lin() will be use three times. The function produces a list object with six elements. Let’s first look at the Stats dataframe of each of the three lists named epi1 to epi3.\n\nlibrary(epifitter)\nepi1 &lt;- fit_lin(time = pepper$t,  \n                y = pepper$`1` )\nepi1$Stats\n\n                 CCC r_squared    RSE\nGompertz      0.9848    0.9700 0.5911\nMonomolecular 0.9838    0.9681 0.5432\nLogistic      0.9782    0.9572 0.8236\nExponential   0.7839    0.6447 0.6705\n\n\n\nepi2 &lt;- fit_lin(time = pepper$t,  \n  y = pepper$`2` )\nepi2$Stats\n\n                 CCC r_squared    RSE\nLogistic      0.9962    0.9924 0.4524\nGompertz      0.9707    0.9431 0.8408\nMonomolecular 0.9248    0.8601 1.0684\nExponential   0.8971    0.8134 1.2016\n\n\n\nepi3 &lt;- fit_lin(time = pepper$t,  \n  y = pepper$`3` )\nepi3$Stats\n\n                 CCC r_squared    RSE\nLogistic      0.9829    0.9665 0.6045\nGompertz      0.9825    0.9656 0.2263\nExponential   0.9636    0.9297 0.7706\nMonomolecular 0.8592    0.7531 0.2534\n\n\nThe statistics of the model fit confirms our initial guess that the predictions by the logistic or the Gompertz are closer to the observations than predictions by the other models. There is no much difference between them based on these statistics. However, to pick one of the models, it is important to inspect the curves with the observed and predicted values to check which model is best for all curves."
  },
  {
    "objectID": "temporal-fitting.html#fitting-multiple-epidemics",
    "href": "temporal-fitting.html#fitting-multiple-epidemics",
    "title": "10  Model fitting",
    "section": "10.5 Fitting: multiple epidemics",
    "text": "10.5 Fitting: multiple epidemics\nBefore looking at the prediction, let’s use another handy function that allows us to simultaneously fit the models to multiple DPC data. Different from fit_lin(), fit_multi() requires the data to be structured in the long format where there is a column specifying each of the epidemics.\nLet’s then create a new data set called pepper2 using the data transposing functions of the tidyr package.\n\npepper2 &lt;- pepper |&gt; \n  pivot_longer(2:4, names_to =\"treat\", values_to = \"inc\")\n\nNow we fit the models to all DPCs. Note that the name of the variable indicating the DPC code needs to be informed in strata_cols argument.\n\nepi_all &lt;- fit_multi(\n  time_col = \"t\",\n  intensity_col = \"inc\",\n  data = pepper2,\n  strata_cols = \"treat\",\n  nlin = FALSE\n)\n\nNow let’s select the statistics of model fitting. Again, Epifitter ranks the models based on the CCC (the higher the better) but it is important to check the RSE as well - the lower the better. In fact, the RSE is more important when the goal is prediction.\n\nepi_all$Parameters |&gt; \n  select(treat, model, best_model, RSE, CCC)\n\n   treat         model best_model       RSE       CCC\n1      1      Gompertz          1 0.5911056 0.9847857\n2      1 Monomolecular          2 0.5431977 0.9838044\n3      1      Logistic          3 0.8235798 0.9781534\n4      1   Exponential          4 0.6705085 0.7839381\n5      2      Logistic          1 0.4523616 0.9961683\n6      2      Gompertz          2 0.8407922 0.9707204\n7      2 Monomolecular          3 1.0683633 0.9247793\n8      2   Exponential          4 1.2015809 0.8971003\n9      3      Logistic          1 0.6045243 0.9829434\n10     3      Gompertz          2 0.2262550 0.9824935\n11     3   Exponential          3 0.7705736 0.9635747\n12     3 Monomolecular          4 0.2533763 0.8591837\n\n\nTo be more certain about our decision, let’s advance to the final step which is to produce the plots with the observed and predicted values for each assessment time by calling the Data dataframe of the `epi_all list.\n\nepi_all$Data |&gt;\n filter(model %in% c(\"Gompertz\", \"Logistic\")) |&gt; \n  ggplot(aes(time, predicted, shape = treat)) +\n  geom_point(aes(time, y)) +\n  geom_line() +\n  facet_wrap(~ model) +\n coord_cartesian(ylim = c(0, 1)) + # set the max to 0.6\n  labs(\n    y = \"Disease incidence\",\n    x = \"Time (days after emergence)\"\n  )\n\n\n\n\nFigure 10.2: Observed (dots) and fitted (line) values for three tobacco etch epidemics in pepper\n\n\n\n\nOverall, the logistic model seems a better fit for all the curves. Let’s produce a plot with the prediction error versus time.\n\nepi_all$Data |&gt;\n filter(model %in% c(\"Gompertz\", \"Logistic\")) |&gt; \n  ggplot(aes(time, predicted -y, shape = treat)) +\n  geom_point() +\n  geom_line() +\n  geom_hline(yintercept = 0, linetype =2)+\n  facet_wrap(~ model) +\n coord_cartesian(ylim = c(-0.4, 0.4)) + # set the max to 0.6\n  labs(\n    y = \"Prediction error\",\n    x = \"Time (days after emergence)\"\n  )\n\n\n\n\nFigure 10.3: Prediction error (dotted lines) by two models fitted to the progress curves of three tobacco etch epidemics in pepper\n\n\n\n\nThe plots above confirms the logistic model as good fit overall because the errors for all epidemics combined are more scattered around the non-error line.\n\n  epi_all$Parameters |&gt;\n    filter(model == \"Logistic\") |&gt;\n    select(treat, y0, y0_ci_lwr, y0_ci_upr, r, r_ci_lwr, r_ci_upr \n)\n\n  treat           y0    y0_ci_lwr   y0_ci_upr         r  r_ci_lwr  r_ci_upr\n1     1 0.0935037690 0.0273207272 0.274728744 0.2104047 0.1659824 0.2548270\n2     2 0.0013727579 0.0006723537 0.002800742 0.2784814 0.2540818 0.3028809\n3     3 0.0008132926 0.0003131745 0.002110379 0.1752146 0.1426077 0.2078215\n\n\nWe can produce a plot for visual inference on the differences in the parameters.\n\np1 &lt;- epi_all$Parameters |&gt;\n  filter(model == \"Logistic\") |&gt;\n  ggplot(aes(treat, r)) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = r_ci_lwr, ymax = r_ci_upr),\n    width = 0,\n    size = 1\n  ) +\n  labs(\n    x = \"Epidemic\",\n    y = \"r\"\n  )\n\np2 &lt;- epi_all$Parameters |&gt;\n  filter(model == \"Logistic\") |&gt;\n  ggplot(aes(treat, 1 - exp(-y0))) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = y0_ci_lwr, ymax = y0_ci_upr),\n    width = 0,\n    size = 1\n  ) +\n  labs(\n    x = \"Epidemic\",\n    y = \"y0\"\n  )\n\nlibrary(patchwork)\np1 | p2\n\n\n\n\nFigure 10.4: Estimated infection rates (left) and initial inoculum (right) by a logistic model fitted to the progress curves of three epidemics of tobacco etch on pepper"
  },
  {
    "objectID": "temporal-fitting.html#designed-experiments",
    "href": "temporal-fitting.html#designed-experiments",
    "title": "10  Model fitting",
    "section": "10.6 Designed experiments",
    "text": "10.6 Designed experiments\nIn this next section, we will work with disease data collected over time in the same plot unit (also called repeated measures) from a designed experiment for evaluating and comparing treatment effects.\nAgain, we will use a dataset of progress curves shown in page 98 (Madden et al. 2017). The curves represent the incidence of soybean plants symptomatic for bud blight caused by tobacco streak virus. Four treatments (different planting dates) were evaluated in randomized complete block design with four replicates. There are four assessment in time for each curve. The data was stored as a csv file and will be loaded using read_csv() function and stored as dataframe called budblight.\n\n10.6.1 Loading data\n\nbudblight &lt;- read_csv(\"https://raw.githubusercontent.com/emdelponte/epidemiology-R/main/data/bud-blight-soybean.csv\")\n\nLet’s have a look at the first six rows of the dataset and check the data type for each column. There is an additional column representing the replicates, called block.\n\nbudblight\n\n# A tibble: 64 × 4\n   treat  time block     y\n   &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 PD1      30     1  0.1 \n 2 PD1      30     2  0.3 \n 3 PD1      30     3  0.1 \n 4 PD1      30     4  0.1 \n 5 PD1      40     1  0.3 \n 6 PD1      40     2  0.38\n 7 PD1      40     3  0.36\n 8 PD1      40     4  0.37\n 9 PD1      50     1  0.57\n10 PD1      50     2  0.52\n# … with 54 more rows\n\n\n\n\n10.6.2 Visualizing the DPCs\nLet’s have a look at the curves and produce a combo plot figure similar to Fig. 4.17 of the book, but without the line of the predicted values.\n\np3 &lt;- budblight |&gt;\n  ggplot(aes(\n    time, y,\n    group = block,\n    shape = factor(block)\n  )) +\n  geom_point(size = 1.5) +\n  ylim(0, 0.6) +\n  theme(legend.position = \"none\")+\n  facet_wrap(~treat, ncol =1)+\n  labs(y = \"Disease incidence\",\n       x = \"Time (days after emergence)\")\n\np4 &lt;- budblight |&gt;\n  ggplot(aes(\n    time, log(1 / (1 - y)),\n    group = block,\n    shape = factor(block)\n  )) +\n  geom_point(size = 2) +\n  facet_wrap(~treat, ncol = 1) +\n  theme(legend.position = \"none\")+\n  labs(y = \"Transformed incidence\", x = \"Time (days after emergence)\")\n\np3 | p4\n\n\n\n\nFigure 10.5: Disease progress curves for the incidence of budblight of soybean in Brazil for four planting dates\n\n\n\n\n\n\n10.6.3 Model fitting\nRemember that the first step in model selection is the visual appraisal of the curve data linearized with the model transformation. In the case the curves represent complete epidemics (close to 100%) appraisal of the absolute rate (difference in y between two times) over time is also helpful.\nFor the treatments above, it looks like the curves are typical of a monocyclic disease (the case of soybean bud blight), for which the monomolecular is usually a good fit, but other models are also possible as well. For this exercise, we will use both the linear and the nonlinear estimation method.\n\n10.6.3.1 Linear regression\nFor convenience, we use the fit_multi() to handle multiple epidemics. The function returns a list object where a series of statistics are provided to aid in model selection and parameter estimation. We need to provide the names of columns (arguments): assessment time (time_col), disease incidence (intensity_col), and treatment (strata_cols).\n\nlin1 &lt;- fit_multi(\n  time_col = \"time\",\n  intensity_col = \"y\",\n  data = budblight,\n  strata_cols = \"treat\",\n  nlin = FALSE\n)\n\nLet’s look at how well the four models fitted the data. Epifitter suggests the best fitted model (1 to 4, where 1 is best) for each treatment. Let’s have a look at the statistics of model fitting.\n\nlin1$Parameters |&gt; \nselect(treat, best_model, model, CCC, RSE)\n\n   treat best_model         model       CCC        RSE\n1    PD1          1 Monomolecular 0.9348429 0.09805661\n2    PD1          2      Gompertz 0.9040182 0.22226189\n3    PD1          3      Logistic 0.8711178 0.44751963\n4    PD1          4   Exponential 0.8278055 0.36124036\n5    PD2          1 Monomolecular 0.9547434 0.07003116\n6    PD2          2      Gompertz 0.9307192 0.17938711\n7    PD2          3      Logistic 0.9062012 0.38773023\n8    PD2          4   Exponential 0.8796705 0.32676216\n9    PD3          1 Monomolecular 0.9393356 0.06832499\n10   PD3          2      Gompertz 0.9288436 0.17156394\n11   PD3          3      Logistic 0.9085414 0.39051075\n12   PD3          4   Exponential 0.8896173 0.33884790\n13   PD4          1      Gompertz 0.9234736 0.17474422\n14   PD4          2 Monomolecular 0.8945962 0.06486949\n15   PD4          3      Logistic 0.8911344 0.52412586\n16   PD4          4   Exponential 0.8739618 0.49769642\n\n\nAnd now we extract values for each parameter estimated from the fit of the monomolecular model.\n\nlin1$Parameters |&gt;\nfilter(model == \"Monomolecular\") |&gt;\nselect(treat, y0, r)\n\n  treat         y0          r\n1   PD1 -0.5727700 0.02197351\n2   PD2 -0.5220593 0.01902952\n3   PD3 -0.4491365 0.01590586\n4   PD4 -0.3619898 0.01118047\n\n\nNow we visualize the fit of the monomolecular model (using filter function - see below) to the data together with the observed data and then reproduce the right plots in Fig. 4.17 from the book.\n\nlin1$Data |&gt;\n  filter(model == \"Monomolecular\") |&gt;\n  ggplot(aes(time, predicted)) +\n  geom_point(aes(time, y)) +\n  geom_line(size = 0.5) +\n  facet_wrap(~treat) +\n  coord_cartesian(ylim = c(0, 0.6)) + # set the max to 0.6\n  labs(\n    y = \"Disease incidence\",\n    x = \"Time (days after emergence)\"\n  )\n\n\n\n\nFigure 10.6: Observed (dot) and fitted values by a monomolecular model (line) to the data on the incidence of budblight of soybean in Brazil for four planting dates\n\n\n\n\nNow we can plot the means and respective 95% confidence interval of the apparent infection rate (\\(r\\)) and initial inoculum (\\(y_0\\)) for visual inference.\n\np5 &lt;- lin1$Parameters |&gt;\n  filter(model == \"Monomolecular\") |&gt;\n  ggplot(aes(treat, r)) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = r_ci_lwr, ymax = r_ci_upr),\n    width = 0,\n    size = 1\n  ) +\n  labs(\n    x = \"Epidemic\",\n    y = \"Infection rate (r)\"\n  )\n\np6 &lt;- lin1$Parameters |&gt;\n  filter(model == \"Monomolecular\") |&gt;\n  ggplot(aes(treat, 1 - exp(-y0))) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = y0_ci_lwr, ymax = y0_ci_upr),\n    width = 0,\n    size = 1\n  ) +\n  labs(\n    x = \"Time\",\n    y = \"Initial inoculum (y0)\"\n  )\np5 | p6\n\n\n\n\nFigure 10.7: Estimates of the infection rate (left) and initial inoculum (right) from the fit of a monomolecular model to the data on the incidence of budblight of soybean in Brazil for four planting dates\n\n\n\n\n\n\n10.6.3.2 Non-linear regression\nTo estimate the parameters using the non-linear approach, we repeat the same arguments in the fit_multi function, but include an additional argument nlin set to TRUE.\n\nnlin1 &lt;- fit_multi(\n  time_col = \"time\",\n  intensity_col = \"y\",\n  data = budblight,\n  strata_cols = \"treat\",\n  nlin = TRUE\n)\n\nLet’s check statistics of model fit.\n\nnlin1$Parameters |&gt;\nselect(treat, model, CCC, RSE, best_model)\n\n   treat         model       CCC        RSE best_model\n1    PD1 Monomolecular 0.9382991 0.06133704          1\n2    PD1      Gompertz 0.9172407 0.06986307          2\n3    PD1      Logistic 0.8957351 0.07700720          3\n4    PD1   Exponential 0.8544194 0.08799512          4\n5    PD2 Monomolecular 0.9667886 0.04209339          1\n6    PD2      Gompertz 0.9348370 0.05726761          2\n7    PD2      Logistic 0.9077857 0.06657793          3\n8    PD2   Exponential 0.8702365 0.07667322          4\n9    PD3 Monomolecular 0.9570853 0.04269129          1\n10   PD3      Gompertz 0.9261609 0.05443852          2\n11   PD3      Logistic 0.8997106 0.06203037          3\n12   PD3   Exponential 0.8703443 0.06891021          4\n13   PD4 Monomolecular 0.9178226 0.04595409          1\n14   PD4      Gompertz 0.9085579 0.04791331          2\n15   PD4      Logistic 0.8940731 0.05083336          3\n16   PD4   Exponential 0.8842437 0.05267415          4\n\n\nAnd now we obtain the two parameters of interest. Note that the values are not the sames as those estimated using linear regression, but they are similar and highly correlated.\n\nnlin1$Parameters |&gt;\nfilter(model == \"Monomolecular\") |&gt;\nselect(treat, y0, r)\n\n  treat         y0          r\n1   PD1 -0.7072562 0.02381573\n2   PD2 -0.6335713 0.02064629\n3   PD3 -0.5048763 0.01674209\n4   PD4 -0.3501234 0.01094368\n\n\n\np7 &lt;- nlin1$Parameters |&gt;\n  filter(model == \"Monomolecular\") |&gt;\n  ggplot(aes(treat, r)) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = r_ci_lwr, ymax = r_ci_upr),\n    width = 0,\n    size = 1\n  ) +\n  labs(\n    x = \"Epidemic\",\n    y = \"Infection rate (r)\"\n  )\n\np8 &lt;- nlin1$Parameters |&gt;\n  filter(model == \"Monomolecular\") |&gt;\n  ggplot(aes(treat, y0)) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = y0_ci_lwr, ymax = y0_ci_upr),\n    width = 0,\n    size = 1\n  ) +\n  labs(\n    x = \"Epidemic\",\n    y = \"Initial inoculum (y0)\"\n  )\n\np7 | p8\n\n\n\n\nFigure 10.8: Estimates of the infection rate (left) and initial inoculum (right) from the fit of a monomolecular model to the data on the incidence of budblight of soybean in Brazil for four planting dates\n\n\n\n\n\n\n\n\nMadden, L. V., Hughes, G., and van den Bosch, F. 2017. Temporal analysis i: Quantifying and comparing epidemics. In The American Phytopathological Society, p. 63–116. Available at: http://dx.doi.org/10.1094/9780890545058.004."
  },
  {
    "objectID": "spatial-gradients.html#introduction",
    "href": "spatial-gradients.html#introduction",
    "title": "11  Spatial gradients",
    "section": "11.1 Introduction",
    "text": "11.1 Introduction\nThe assessment of disease in terms of its spatial distribution, particularly considering changes in its intensity as it spreads over distance, is defined as the “disease gradient.” It’s the dispersal, or migration, of the pathogen through various means—such as wind, vectors, rain, movement of infected material, or even human mediation—that encourages the spread of plant diseases within a field or across continents, thereby creating these disease gradients.\nThere exist two distinct types of gradients: the inoculum gradient, in which the availability of a host is not necessarily a prerequisite, and the disease gradient, where all three elements of the disease triangle are essential.\nIn the ensuing chapters, we shall explore examples of actual disease gradients measured in the field, each exhibiting its own unique pattern.\nOur first example, from Mundt’s 1999 study (Mundt et al. 1999), sought to measure the dispersal potential of the pathogenic bacteria, Xanthomonas oryzae pv. oryzae, which is responsible for leaf blight in rice. This study was conducted using experimental plots in the Philippines during the wet seasons of 1994 and 1995.\nThe data were made available in this tutorial. We enter the data manually and then produce two plots, one for each year.\n\nlibrary(tidyverse)\ntheme_set(theme_bw(base_size = 16))\n\nxo &lt;- \ntibble::tribble(\n    ~d,   ~y4,   ~y5,\n     0, 3.083, 7.185,\n  0.22, 0.521,  0.38,\n  0.44, 0.083, 0.157,\n  0.66, 0.021, 0.028\n  )\n\ng1 &lt;- xo |&gt; \n  ggplot(aes(d, y4))+\n  geom_point()+\n  geom_line()+\n  ylim(0,8)+\n  labs(y = \"Number of new lesions\",\n       x = \"Distance (m)\",\n       title = \"1994 wet season\")\n\ng2 &lt;- xo |&gt; \n  ggplot(aes(d, y5))+\n  geom_point()+\n  geom_line()+\n  ylim(0,8)+\n  labs(y = \"Number of new lesions\",\n       x = \"Distance (m)\",\n       title = \"1995 wet season\")\n\nlibrary(patchwork)\n(g1 | g2) +  plot_annotation(\n    caption = \"Source: Mundt et al. (1999)\")\n\n\n\n\nFigure 11.1: Primary gradients of bacerial blight of rice in two wet seasons in the Philippines\n\n\n\n\nThe second example of a disease gradient pertains to stripe rust, caused by Puccinia striiformis f. sp. tritici, on wheat. This data was collected during a field experiment conducted at Hermiston in 2002, as reported in Sackett’s 2005 study (Sackett and Mundt 2005). Later, the data was made publicly available in 2015, courtesy of Mikaberidze (Mikaberidze et al. 2015). For our discussion, we’ll manually input the data in a tibble format.\nThis tibble contains five columns. The first and second columns represent distances from the source of infection, denoted in feet and meters, respectively. The remaining three columns consist of measures of stripe rust severity, each from a separate replicated plot. These measurements offer us a quantifiable view of the disease gradient of stripe rust in the field, thereby shedding light on the infection’s spatial distribution and intensity.\n\nhermiston &lt;- \n  tibble::tribble(\n  ~dist_f, ~dist_m,  ~`1`,  ~`2`,  ~`3`,\n  0,        0,    65,    65,    39,\n  5,      1.5,    35,    44,   7.5,\n  10,       3,  21.5,  14.5,  1.75,\n  20,     6.1,     8,  0.75,   0.2,\n  40,    12.2,     1,  0.08, 0.025,\n  60,    18.3,  0.25, 0.026, 0.015,\n  80,    24.4, 0.035, 0.015, 0.009,\n  100,   30.5,  0.01, 0.003, 0.008,\n  120,   36.6, 0.008, 0.016,  0.01,\n  140,   42.7, 0.003, 0.003,  0.01,\n  160,   48.8, 0.001, 0.006, 0.006,\n  180,   54.9, 0.001, 0.002, 0.002,\n  200,     61, 0.001, 0.003, 0.004,\n  220,   67.1, 0.001, 0.003, 0.002,\n  240,   73.2, 0.001, 0.001,     0,\n  260,   79.2, 0.001, 0.002,     0,\n  280,   85.3, 0.001, 0.001,     0,\n  300,   91.4, 0.001, 0.001, 0.001\n  )\n\n\nlibrary(tidyverse)\nlibrary(ggthemes)\n\nhermiston |&gt; \n  pivot_longer(3:5, names_to = \"replicate\", values_to = \"severity\") |&gt; \n  ggplot(aes(dist_m, severity, color = replicate))+\n  geom_point(size = 2)+\n  geom_line(size = 1)+\n  scale_color_colorblind()+\n  labs(x = \"Distance from the source (m)\",\n       y = \"Stripe rust severity (%)\",\n       color = \"Replicate\",\n       caption = \"source: Sackett et al. (2005)\")\n\n\n\n\nFigure 11.2: Primary gradients of stripe rust of wheat on a replicated experiment\n\n\n\n\nAs evidenced by the examples presented above, disease gradients, assuming a single source of inoculum, typically display a pattern wherein the disease’s intensity diminishes more steeply within shorter proximities to the source. Conversely, the decrease is less steep at greater distances, eventually reaching a point of either zero or a low background level with only occasional diseased plants.\nThe unique shapes of these gradients are largely influenced by mechanisms associated with the dispersal of the inoculum, which are contingent not only on the pathogen’s biological characteristics but also heavily upon environmental factors that can impact the pathogen’s dispersion.\nFrom this, we can categorize the resulting gradients into two types: primary and secondary. The primary gradient is generated solely from the initial source of the infection. On the other hand, the secondary gradient arises from the movement of inoculum that has been produced by plants previously infected due to the primary gradient. These secondary infections then spread to other plants situated at increasing distances from the initial source.\nAs the disease proliferates over time, it’s expected that a combination of both primary and secondary gradients will manifest. This interplay between the two gradient types contributes to the overall spread and severity of the disease within a given population and environment.\nAs an example of primary and secondary gradients, let’s visualize the gradients of Septoria leaf spot, caused by Septoria lycopersici, on tomato (Parker et al. 1997). The gradients were measured during two times, thus enabling a comparison of primary and secondary dispersal/disease gradients. More details of the study and experimental approach were provided in this tutorial. The data is entered below as a tribble and the plot produced using ggplot2.\n\nseptoria &lt;- \ntibble::tribble(\n ~d, ~date1, ~date4,\n 60,     75,    87,\n 120,    40,    78,\n 180,    30,    68,\n 240,    20,    62,\n 300,    15,    50,\n 360,    12,    27,\n 420,    10,    32,\n 480,    12,    12,\n 540,     8,    13,\n 600,     5,     5,\n 660,     4,     4\n                )\n\nseptoria |&gt; \n  pivot_longer(2:3, names_to = \"date\", \n               values_to = \"defoliation\") |&gt; \n  ggplot(aes(d, defoliation, color = date))+\n  geom_point()+\n  geom_line()+\n  scale_color_colorblind()+\n  annotate(geom = \"text\", x = 200, y = 12, \n           label = \"Primary gradient\", hjust = \"left\")+\n  annotate(geom = \"text\", x = 200, y = 72, \n           label = \"Secondary gradient\", hjust = \"left\")+\n  labs(x = \"Distance from focus (m)\",\n       y = \"Percent defoliation\",\n       color = \"Date\",\n       caption = \"Parker et al. (1997)\")\n\n\n\n\nFigure 11.3: Primary and secondary gradients of defoliation due to Septoria leaf spot on tomato\n\n\n\n\nWhen studying disease gradients, researchers need to make sure that there is a well-defined single source of inoculum. In gradients, this is called a focus (where foci are deemed the plural), from where the inoculum originates. Three types of foci can be defined: point, line or area sources. While the point source can be a plant or group of plants at any position in the plot or field (center or corner), line and area sources are usually defined as one or more rows of diseased plants at one side of the plot or field.\n\n\nCode\nlibrary(ggplot2)\n\nline &lt;- ggplot(data.frame(c(1:10),c(1:10)))+\n  annotate(\"rect\", xmin = 0, xmax = 10, ymin = 0, ymax = 10, fill = \"gray92\")+\n  annotate(\"rect\", xmin = 0, xmax = 10, ymin = 9.7, ymax = 10, color = \"black\", fill = \"orange\")+\n  annotate(\"segment\", size = 2, x = 1, xend = 1, y = 9.5, yend = 2, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 3, xend = 3, y = 9.5, yend = 2, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 5, xend = 5, y = 9.5, yend = 2, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 7, xend = 7, y = 9.5, yend = 2, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 9, xend = 9, y = 9.5, yend = 2, arrow = arrow())+\n  ylim(0,10)+\n  xlim(0,10)+\n  coord_fixed()+\n  theme_void()+\n  labs(title = \"      Side line\")\n\narea &lt;- ggplot(data.frame(c(1:10),c(1:10)))+\n  annotate(\"rect\", xmin = 0, xmax = 10, ymin = 0, ymax = 10, fill = \"gray92\")+\n  annotate(\"rect\", xmin = 0, xmax = 10, ymin = 8.2, ymax = 10, color = \"black\", fill = \"orange\")+\n  annotate(\"segment\", size = 2, x = 1, xend = 1, y = 8, yend = 2, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 3, xend = 3, y = 8, yend = 2, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 5, xend = 5, y = 8, yend = 2, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 7, xend = 7, y = 8, yend = 2, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 9, xend = 9, y = 8, yend = 2, arrow = arrow())+\n  ylim(0,10)+\n  xlim(0,10)+\n  coord_fixed()+\n  theme_void()+\n  labs(title = \"      Side area\")\n\npoint_central &lt;- ggplot(data.frame(c(1:10),c(1:10)))+\n  annotate(\"rect\", xmin = 0, xmax = 10, ymin = 0, ymax = 10, fill = \"gray92\")+\n  annotate(\"segment\", size = 2, x = 5, xend = 10, y = 5, yend = 10, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 5, xend = 10, y = 5, yend = 5, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 5, xend = 10, y = 5, yend = 0, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 5, xend = 0, y = 5, yend = 0, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 5, xend = 0, y = 5, yend = 5, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 5, xend = 0, y = 5, yend = 10, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 5, xend = 5, y = 5, yend = 10, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 5, xend = 5, y = 5, yend = 0, arrow = arrow())+\n   annotate(\"rect\", xmin = 5.5, xmax = 4.5, ymin = 4.5, ymax = 5.5, color = \"black\", fill = \"orange\" )+\n  ylim(0,10)+\n  xlim(0,10)+\n  coord_fixed()+\n  theme_void()+\n  labs(title = \"    Central point/area\")\n\npoint_corner &lt;- ggplot(data.frame(c(1:10),c(1:10)))+\n  annotate(\"rect\", xmin = 0, xmax = 10, ymin = 0, ymax = 10, fill = \"gray92\")+\n  annotate(\"segment\", size = 2, x = 0, xend = 10, y = 10, yend = 0, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 0, xend = 6.6, y = 10, yend = 0, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 0, xend = 3.3, y = 10, yend = 0, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 0, xend = 0, y = 10, yend = 0, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 0, xend = 10, y = 10, yend = 3.3, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 0, xend = 10, y = 10, yend = 6.6, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 0, xend = 10, y = 10, yend = 10, arrow = arrow())+\n  annotate(\"rect\", xmin = 0, xmax = 1, ymin = 9, ymax = 10, color = \"black\", fill = \"orange\")+\n  ylim(0,10)+\n  xlim(0,10)+\n  coord_fixed()+\n  theme_void()+\n  labs(title = \"    Corner point/area\")\n\nlibrary(patchwork)\np_gradients &lt;- (line | area)/\n(point_central | point_corner)\n\nggsave(\"imgs/gradients.png\", width =9, height =9, bg = \"white\")\n\n\n\n\n\nFigure 11.4: Example of location and size of inoculum sources for the study of disease gradients\n\n\n\n\n\n\nMikaberidze, A., Mundt, C. C., and Bonhoeffer, S. 2015. Data from: Invasiveness of plant pathogens depends on the spatial scale of host distribution. Available at: http://datadryad.org/stash/dataset/doi:10.5061/dryad.f2j8s.\n\n\nMundt, C. C., Ahmed, H. U., Finckh, M. R., Nieva, L. P., and Alfonso, R. F. 1999. Primary Disease Gradients of Bacterial Blight of Rice. Phytopathology®. 89:64–67 Available at: http://dx.doi.org/10.1094/phyto.1999.89.1.64.\n\n\nParker, S. K., Nutter, F. W., and Gleason, M. L. 1997. Directional Spread of Septoria Leaf Spot in Tomato Rows. Plant Disease. 81:272–276 Available at: http://dx.doi.org/10.1094/pdis.1997.81.3.272.\n\n\nSackett, K. E., and Mundt, C. C. 2005. Primary Disease Gradients of Wheat Stripe Rust in Large Field Plots. Phytopathology®. 95:983–991 Available at: http://dx.doi.org/10.1094/PHYTO-95-0983."
  },
  {
    "objectID": "spatial-models.html#exponential-model",
    "href": "spatial-models.html#exponential-model",
    "title": "12  Gradient models",
    "section": "12.1 Exponential model",
    "text": "12.1 Exponential model\nThe exponential model is also known as Kiyosawa & Shiyomi model. The differential of the exponential model is given by\n\\(\\frac{dy}{dx}\\) = \\(-b_{E}.y\\) ,\nwhere \\(b_{E}\\) is the exponential form of the rate of decline and \\(y\\) is the disease intensity. This model suggests that \\(y\\) (any disease intensity) is greater close to the source of inoculum, or at the distance zero. The integral form of the model is given by\n\\(y = a . e^{-b.x}\\) ,\nwhere \\(a\\) is the disease intensity at the distance zero and \\(b\\) is the rate of decline, in this case negative because disease intensity decreases with the increase of the distance from inoculum source. Let’s make a plot for two disease gradients of varying parameters for this model.\nFirst we need to load essential packages for programming, customizing the outputs and defining a global ggplot theme.\n\nlibrary(tidyverse)\ntheme_set(theme_bw(base_size = 16)) # set global theme\n\nSet the parameters for the exponential model with two rates and the same inoculum level at the source:\n\na1 &lt;- 0.2 # y at distance zero for gradient 1\na2 &lt;- 0.2 # y at distance zero for gradient 2\nb1 &lt;- 0.1 # decline rate for gradient 1\nb2 &lt;- 0.05 # decline rate for gradient 2\nmax1 &lt;- 80 # maximum distance for gradient 1\nmax2 &lt;- 80 # maximum distance for gradient 2\ndat &lt;- data.frame(x = seq(1:max1), y = seq(0:a1))\n\nThe following code allows to visualize the model predictions.\n\ndat |&gt;\n  ggplot(aes(x, y)) +\n  stat_function(fun = function(x) a1 * exp(-b1 * x), linetype = 1) +\n  stat_function(fun = function(x) a2 * exp(-b2 * x), linetype = 2) +\n  ylim(0, a1) +\n  annotate(\"text\", x = 20, y = 0.04, label = \"b = 0.1\") +\n  annotate(\"text\", x = 20, y = 0.10, label = \"b = 0.05\") +\n  labs(x = \"Distance (m)\", y = \"Disease incidence (proportion)\"\n  )\n\n\n\n\nFigure 12.1: Exponential curves describing plant disease gradients"
  },
  {
    "objectID": "spatial-models.html#power-law-model",
    "href": "spatial-models.html#power-law-model",
    "title": "12  Gradient models",
    "section": "12.2 Power law model",
    "text": "12.2 Power law model\nAlso known as the modified Gregory’s model (Gregory was a pioneer in the use this model to describe plant disease gradients). In the power law model, \\(Y\\) is proportional to the power of the distance, and is given by:\n\\(Y = a_{P}.x - b_{P}\\)\nwhere \\(a_{P}\\) and \\(b_{P}\\) are the two parameters of the power law model. They differ from the exponential because as closer to \\(x\\) is to zero, \\(Y\\) is indefinitely large (not meaningful biologically). However, the model can still be useful because it produces realistic values at any distance \\(x\\) away from the source. The values of the \\(a_{P}\\) parameter should be interpreted in accord to the scale of \\(x\\), whether in centimeters or meters. If the distance between the source and the first measure away from the source is 0.5m, it is so more appropriate to record the distance in cm than in m or km.\nOnce \\(y\\) at the distance zero from the source is undefined when using the power law model, this is usually modified by the addition of a positive constant \\(C\\) in \\(x\\):\n\\(Y = a_{P}.(x + C) - b_{P}\\)\nFor this reason, the model is named as the modified power law. Here, the constant \\(C\\) is of the same unit of \\(x\\). At the distance zero, the positive constant is a term that express the size of the inoculum source. In other words, the \\(a\\) parameter is a theoretical value of \\(Y\\) at the distance \\(1-C\\) from the center of the inoculum source.\nLet’s plot two gradients with two rate parameters for the modified power law model:\n\nC &lt;- 0.5\na1 &lt;- 0.2 # y at zero distance for gradient 1\na2 &lt;- 0.2 # y at zero distance for gradient 2\nb1 &lt;- 0.5 # decline rate for gradient 1\nb2 &lt;- 0.7 # decline rate for gradient 2\nmax1 &lt;- 80 # maximum distance for gradient 1\nmax2 &lt;- 80 # maximum distance for gradient 2\ndat2 &lt;- data.frame(x = seq(1:max1), y = seq(0:a1))\n\n\ndat2 |&gt;\n  ggplot(aes(x, y)) +\n  stat_function(fun = function(x) a1 * ((x + C)^-b1), linetype = 1) +\n  stat_function(fun = function(x) a2 * ((x + C)^-b2), linetype = 2) +\n  ylim(0, a1 - 0.02) +\n  annotate(\"text\", x = 20, y = 0.03, label = \"b = 0.1\") +\n  annotate(\"text\", x = 20, y = 0.06, label = \"b = 0.05\") +\n  labs(x = \"Distance (m)\", y = \"Disease incidence\")\n\n\n\n\nFigure 12.2: Power law (modified) curves describing plant disease gradients\n\n\n\n\nThe differential equation of the power law model is given by:\n\\(\\frac{dy}{dx}\\) = \\(\\frac{-b_{P}.Y}{x - C}\\)\nSimilar to the exponential model, \\(\\frac{dy}{dx}\\) is proportional to \\(Y\\), meaning that the gradient is steeper (more negative) at the highest disease intensity value, usually closer to the source."
  },
  {
    "objectID": "spatial-models.html#linearization-of-the-models",
    "href": "spatial-models.html#linearization-of-the-models",
    "title": "12  Gradient models",
    "section": "12.3 Linearization of the models",
    "text": "12.3 Linearization of the models\n\n12.3.1 Transformations of y\nThe gradient models, again similar to the temporal disease models, are non linear in their parameters. The model is intrinsically linear if transformations are applied (according to the model) in both sides of the equations. The linear model in its generic state is given by\n\\(y* = a* + bx\\) ,\nwhere the asterisk in \\(a\\) indicated that one of the transformations was applied in \\(y\\) that produced the linear model. Note that \\(a*\\) is the transformed version of the initial disease intensity, which needs to be returned to the original scale according to the respective back-transformation. Follows the linearized form of the two most common gradient models.\n\\(ln(y) = ln(a_{E}) - b_{E}. x\\)\n\\(ln(y) = ln(a_{P}) - b_{E}. ln(x+C)\\)\n\n\n12.3.2 Plot for the linearized form of models\nLet’s visualize the linearization of the exponential model with two different slopes (gradient 1 and 2). Note that the transformation used was \\(ln(y)\\).\n\nC &lt;- 0.5\na1 &lt;- 0.2 # y at zero distance for gradient 1\na2 &lt;- 0.2 # y at zero distance for gradient 2\nb1 &lt;- 0.5 # decline rate for gradient 1\nb2 &lt;- 0.7 # decline rate for gradient 2\nmax1 &lt;- 80 # maximum distance for gradient 1\nmax2 &lt;- 80 # maximum distance for gradient 2\ndat2 &lt;- data.frame(x = seq(1:max1), y = seq(0:a1))\n\ndat2 |&gt;\n  ggplot(aes(x, y)) +\n  stat_function(fun = function(x) log(a1) - (b1 * x), linetype = 1) +\n  stat_function(fun = function(x) log(a2) - (b2 * x), linetype = 2) +\n  labs(x = \"log of distance (m)\", y = \"log of disease incidence\"\n  )\n\n\n\n\nFigure 12.3: Linearization of the exponential model describing plant disease gradients\n\n\n\n\nFollows the linearization of the modified power law model. Note that the transformation used was \\(ln(y)\\) and \\(ln(x+C)\\) .\n\nC &lt;- 0.5\na1 &lt;- 0.2 # y at zero distance for gradient 1\na2 &lt;- 0.2 # y at zero distance for gradient 2\nb1 &lt;- 0.5 # decline rate for gradient 1\nb2 &lt;- 0.7 # decline rate for gradient 2\nmax1 &lt;- log(80) # maximum distance for gradient 1\nmax2 &lt;- log(80) # maximum distance for gradient 2\ndat2 &lt;- data.frame(x = seq(1:max1), y = seq(0:a1))\n\ndat2 |&gt;\n  ggplot(aes(x, y)) +\n  stat_function(fun = function(x) log(a1) - (b1 * log(x + C)), linetype = 1) +\n  stat_function(fun = function(x) log(a2) - (b2 * log(x + C)), linetype = 2) +\n  labs(\n    title = \"Modified Power Law\",\n    subtitle = \"\",\n    x = \"log of distance (m)\",\n    y = \"log of disease incidence\"\n  )\n\n\n\n\nFigure 12.4: Linearization of the modified power law curves describing plant disease gradients"
  },
  {
    "objectID": "spatial-fitting.html#dataset",
    "href": "spatial-fitting.html#dataset",
    "title": "13  Fitting gradient models",
    "section": "13.1 Dataset",
    "text": "13.1 Dataset\nThe hypothetical data below shows a gradient for the number of lesions counted at varying distances in meters from the source. Let’s create two vectors, one for the distances \\(x\\) and the other for the lesion count \\(Y\\), and then a data frame by combining the two vectors.\n\n# create the two vectors\nx &lt;- c(0.8, 1.6, 2.4, 3.2, 4, 7.2, 12, 15.2, 21.6, 28.8)\nY &lt;- c(184.9, 113.3, 113.3, 64.1, 25, 8, 4.3, 2.5, 1, 0.8)\ngrad1 &lt;- data.frame(x, Y) # create the dataframe\ngrad1 # show the gradient\n\n      x     Y\n1   0.8 184.9\n2   1.6 113.3\n3   2.4 113.3\n4   3.2  64.1\n5   4.0  25.0\n6   7.2   8.0\n7  12.0   4.3\n8  15.2   2.5\n9  21.6   1.0\n10 28.8   0.8"
  },
  {
    "objectID": "spatial-fitting.html#visualize-the-gradient",
    "href": "spatial-fitting.html#visualize-the-gradient",
    "title": "13  Fitting gradient models",
    "section": "13.2 Visualize the gradient",
    "text": "13.2 Visualize the gradient\n\ngrad1 |&gt; \n  ggplot(aes(x, Y))+\n  geom_point()+\n  geom_line()+\n  labs(y = \"Lesion count\",\n       x = \"Distance (m)\")\n\n\n\n\nFigure 13.1: Hypothetical gradient of lesion count over distances from the inoculum source"
  },
  {
    "objectID": "spatial-fitting.html#linear-regression",
    "href": "spatial-fitting.html#linear-regression",
    "title": "13  Fitting gradient models",
    "section": "13.3 Linear regression",
    "text": "13.3 Linear regression\nA linear regression model is fitted to the transformed variables according to the model. The higher the coefficient of determination, the better is the fit of the model to the data.\n\n13.3.1 Exponential model\n\nreg_exp &lt;- lm(log(Y) ~ x, data = grad1)\nsummary(reg_exp)$r.squared\n\n[1] 0.8776612\n\n\n\ngrad1 |&gt; \n  ggplot(aes(x, log(Y)))+\n  geom_point()+\n  geom_line()+\n  geom_abline(slope = coef(reg_exp)[[2]], intercept = coef(reg_exp)[[1]])+\n labs(y = \"Log of Lesion count\",\n       x = \"Distance (m)\")\n\n\n\n\nFigure 13.2: Fit of the exponential model to the log of lesion count over distances from the inoculum source\n\n\n\n\n\n\n13.3.2 Power law model\n\nreg_p &lt;- lm(log(Y) ~ log(x), data = grad1)\nsummary(reg_p)$r.squared\n\n[1] 0.962132\n\n\n\ngrad1 |&gt; \n  ggplot(aes(log(x), log(Y)))+\n  geom_point()+\n  geom_line()+\n  geom_abline(slope = coef(reg_p)[[2]], intercept = coef(reg_p)[[1]])+\n labs(y = \"Log of Lesion count\",\n       x = \"Log of distance\")\n\n\n\n\nFigure 13.3: Fit of the power law model to the log of lesion count over log of the distance from the inoculum source\n\n\n\n\n\n\n13.3.3 Modified power law model\n\nreg_pm &lt;- lm(log(Y) ~ log(x + 0.4), data = grad1)\nsummary(reg_pm)$r.squared\n\n[1] 0.9742072\n\n\n\ngrad1 |&gt; \n  ggplot(aes(log(x+0.4), log(Y)))+\n  geom_point()+\n  geom_line()+\n  geom_abline(slope = coef(reg_pm)[[2]], intercept = coef(reg_pm)[[1]])+\n labs(y = \"Log of Lesion count\",\n       x = \"Log of distance + 0.4 (m)\")\n\n\n\n\nFigure 13.4: Fit of the modified power law model to the log of lesion count over log + 0.4 of the distances from the inoculum source\n\n\n\n\nBased on the (highest) coefficient of determination, the modified power law provided the best fit. The graphs for the fitted models confirm this conclusion."
  },
  {
    "objectID": "spatial-patterns.html#definitions",
    "href": "spatial-patterns.html#definitions",
    "title": "14  Spatial patterns",
    "section": "14.1 Definitions",
    "text": "14.1 Definitions\nA spatial disease pattern can be defined as the arrangement of diseased entities relative to each other and to the architecture of the host crop (Madden et al. 2017). Such arrangement is the realization of the underlying dispersal of the pathogen, from one or several sources within and/or outside the area of interest, under the influence of physical, biological and environmental factors.\nThe study of spatial patterns is conducted at a specific time or multiple times during the epidemic. When assessed multiple times, both spatial and temporal processes can be characterized. Because epidemics change over time, it is expected that spatial patterns are not constant but change over time as well. Usually, plant pathologists are interested in determining spatial patterns at one or various spatial scales, depending on the objective of the study. The scale of interest may be a leaf or root, plant, field, municipality, state, country or even intercontinental area. The diseased units observed may vary from lesions on a single leaf to diseased fields in a large production region.\nThe patterns can be classified into two main types that occur naturally: random or aggregated. The random pattern originates because the chances for the units (leaf, plant, crop) to be infected are equal and low, and are largely independent from each other. In aggregated spatial patterns, such chances are unequal and there is dependency among the units. For example, a healthy unit close to a diseased unit is at higher risk than more distant units.\nLet’s simulate in R two vectors (x,y) for the positions of diseased units that follow a random or an aggregated pattern. For the random pattern, we use runif, a function which generates random deviates from the uniform distribution.\n\nset.seed(123)          # for reproducibility\nx &lt;- runif(50, 0, 30)  # x vector\ny &lt;- runif(50, 0, 30)  # y vector\ndat &lt;- data.frame(x,y) # dataframe for plotting\n\nNow, the plot to visualize the random pattern.\n\nlibrary(tidyverse) \nlibrary(ggthemes)\ntheme_set(theme_few())\n\npr &lt;- dat |&gt; # R base pipe operator\n  ggplot(aes(x, y))+\n  geom_point(size =3, \n             color = \"darkred\")+\n  ylim(0,30)+\n  xlim(0,30)+\n  coord_fixed()+\n  labs(x = \"Distance x\", y = \"Distance y\", \n       title = \"Random\")\npr\n\n\n\n\nFigure 14.1: Random pattern of a plant disease epidemic\n\n\n\n\nNow, we can generate new x and y vectors using rnbinom function which allows generating values for the negative binomial distribution (which should give rise to aggregated patterns) with parameters size and prob. Let’s simulate 50 values with mean 12 and size 20 as dispersal parameter.\n\nx &lt;- rnbinom(n = 50, mu = 12, size = 20)\ny &lt;- rnbinom(n = 50, mu = 5, size = 20)\ndat2 &lt;- data.frame(x, y)\n\nThis should give us an aggregated pattern.\n\npag &lt;- dat2 |&gt;\n  ggplot(aes(x, y))+\n  geom_point(size = 3, color = \"darkred\")+\n  ylim(0,30)+\n  xlim(0,30)+\n  coord_fixed()+\n  labs(x = \"Distance x\", y = \"Distance y\", \n       title = \"Aggregated\")\npag\n\n\n\n\nFigure 14.2: Aggregated pattern of a plant disease epidemic\n\n\n\n\nA rare pattern found in nature is the regular pattern, but it may be generated artificially by the man when conducting experimentation. Follows a code to produce the regular pattern.\n\nx &lt;- rep(c(0,5,10,15,20, 25, 30, 35, 40, 45), 5) \ny &lt;- rep(c(0, 5, 10, 15, 20, 25, 30, 35, 40, 45), each = 10)\ndat3 &lt;- data.frame(x, y)\n\npreg &lt;- dat3 |&gt;\n  ggplot(aes(x, y))+\n  geom_point(size = 3, color = \"darkred\")+\n  ylim(0,30)+\n  xlim(0,30)+\n  coord_fixed()+\n  labs(x = \"Distance x\", y = \"Distance y\", \n       title = \"Regular\")\npreg\n\nWarning: Removed 51 rows containing missing values (geom_point).\n\n\n\n\n\nFigure 14.3: Regular pattern of a plant disease epidemic\n\n\n\n\n\nlibrary(patchwork)\npreg + pr + pag\n\n\n\nggsave(\"imgs/spatial.png\", width = 10, height = 4)"
  },
  {
    "objectID": "spatial-patterns.html#spatiotemporal",
    "href": "spatial-patterns.html#spatiotemporal",
    "title": "14  Spatial patterns",
    "section": "14.2 Spatiotemporal",
    "text": "14.2 Spatiotemporal\nThe location of diseased plants can be assessed over time and so we can appraise both the progress and pattern of the epidemics. Let’s visualize spatial data collected from actual epidemics monitored (plant is diseased or not diseased) during six times during the epidemics. The data is available in the epiphy R package. Let’s use only one variety and one irrigation type.\n\nlibrary(epiphy)\ntswv_1928 &lt;- tomato_tswv$field_1928\n\ntswv_1928 |&gt;\n  filter(variety == \"Burwood-Prize\"&\n         irrigation == \"trenches\") |&gt; \n  ggplot(aes(x, y, color = factor(i)))+\n  geom_point(aes(group = seq_along(factor(t))), size =2)+\n  coord_fixed()+\n  scale_color_manual(values = c(\"grey70\", \"darkred\"))+\n  labs(color = \"Status\", title = \"\")+\n  theme_void()+\n  theme(legend.position = \"bottom\")+\n  facet_wrap(~ t, nrow =1)\n\n\n\n\nFigure 14.4: Spatial patterns of tomato spotted wilt virus at six assessment times"
  },
  {
    "objectID": "spatial-patterns.html#simulating-spatial-patterns",
    "href": "spatial-patterns.html#simulating-spatial-patterns",
    "title": "14  Spatial patterns",
    "section": "14.3 Simulating spatial patterns",
    "text": "14.3 Simulating spatial patterns\nTwo Shiny apps have been developed to allow simulating various spatial disease patterns. The first generates a disease- or pathogen-only data where the units are located in a scatter plot where the user can define the number of cells of the grid as well as the number of points to be plotted and the realized pattern: random or aggregated.\n\n\n\nFigure 14.5: Screenshot of a Shiny app to simulate disease-only data in a grid\n\n\nThe second app generates an artificial plantation with presence-absence data in a 2D map. The user can define the number of rows and number of plants per row and the realized pattern: random or aggregated. The latter pattern can start from the center or border of the plantation. The app calculates the number of foci and the final incidence (proportion of diseased plants).\n\n\n\nFigure 14.6: Screenshot of a Shiny app to simulate a presence-absence data in a 2D map\n\n\n\n\n\n\nMadden, L. V., Hughes, G., and van den Bosch, F. 2017. Spatial aspects of epidemicsIII: Patterns of plant disease. In The American Phytopathological Society, p. 235–278. Available at: http://dx.doi.org/10.1094/9780890545058.009."
  },
  {
    "objectID": "spatial-tests.html#intensively-mapped",
    "href": "spatial-tests.html#intensively-mapped",
    "title": "15  Tests for patterns",
    "section": "15.1 Intensively mapped",
    "text": "15.1 Intensively mapped\n\n15.1.1 Binary data\nIn this situation the individual plants are mapped, meaning that their relative positions to one another are known. It is the case when a census is used to map presence/absence data. The status of each unit (usually a plant) is noted as a binary variable. The plant is either diseased (D or 1) or non-diseased or healthy (H or 0). Several statistical tests can be used to detect a deviation from randomness. The most commonly used tests are runs, doublets and join count.\n\n15.1.1.1 Runs test\nA run is defined as a succession of one or more diseased (D) or healthy (H) plants, which are followed and preceded by a plant of the other disease status or no plant at all. In the example below, we can count 13 runs.\n\n\n\nFigure 15.2: Example for the computation of the number of ordinary runs in a sequence of binary data\n\n\nThere would be few runs if there is an aggregation of diseased or healthy plants and a large number of runs for a random mixing of diseased and healthy plants.\nLet’s create a vector of binary (0 = non-diseased; 1 = diseased) data representing a crop row with 20 plants and assign it to y. For plotting purposes, we make a dataframe for more complete information.\n\nlibrary(tidyverse) \ntheme_set(theme_bw(base_size = 16))\n\n\ny1 &lt;- c(1,1,1,0,0,0,0,0,1,0,0,0,0,1,1,0,0,0,1,1)\nx1 &lt;- c(1:20) # position of each plant\nz1 &lt;- 1\nrow1 &lt;- data.frame(x1, y1, z1) # create a dataframe\n\nWe can then visualize the series using ggplot and count the number of runs as 7, aided by the color used to identify a run.\n\nrow1 |&gt;\n  ggplot(aes(x1, z1, label = x1, color = factor(y1))) +\n  geom_point(shape = 15, size = 7) +\n  theme_void() +\n  scale_x_continuous(breaks = max(z1)) +\n  scale_color_manual(values = c(\"gray70\", \"darkred\")) +\n  geom_text(vjust = 0, nudge_y = 0.5) +\n  coord_fixed() +\n  ylim(0, 2.5) +\n  theme(legend.position = \"top\") +\n  labs(color = \"Status\")\n\n\n\n\nFigure 15.3: Sequence of diseased (1) or non-diseased (0) units (plants). The numbers represent the position of the unit\n\n\n\n\nWe can obtain the number of runs and related statistics using the oruns.test() function of the r4pde package.\n\nlibrary(r4pde)\noruns.test(row1$y1)\n\n$U\n[1] 7\n\n$EU\n[1] 10.6\n\n$pvalue\n[1] 0.08416615\n\n$result\n[1] \"clustering\"\n\n\n\n\n15.1.1.2 Doublets\nDoublet analysis is used to compare the observed number or adjacent diseased plants, a doublet (DD or 11), to the number expected if the disease were randomly distributed in the field. If the observed number is greater than the expected number, contagion within the field is suspected.\n\n\n\nFigure 15.4: Example for the computation of the number of doublets (DD) in a sequence of binary data\n\n\nThe doublets.test() function of the r4pde package calculates the doublets and associated statistics.\n\ndoublets.test(row1$y1)\n\n$Db\n[1] 4\n\n$EDb\n[1] 2.8\n\n$pvalue\n[1] 0.4496918\n\n$result\n[1] \"randomness\"\n\n\n\n\n15.1.1.3 Foci analysis\nThe Analysis of Foci Structure and Dynamics (AFSD), introduced by (Nelson 1996) and further expanded by (Laranjeira et al. 1998), was used in several studies on citrus diseases in Brazil. In this analysis, the data come from incidence maps where both the diseased and no-diseased trees are mapped in the 2D plane (Jesus Junior and Bassanezi 2004; Laranjeira et al. 2004).\nHere is an example of an incidence map with four foci (adapted from (Laranjeira et al. 1998)). The data is organized in the wide format where the first column x is the index for the row and each column is the position of the plant within the row. The 0 and 1 represent the non-diseased and diseased plant, respectively.\n\nfoci &lt;- tibble::tribble(\n           ~x, ~`1`, ~`2`, ~`3`, ~`4`, ~`5`, ~`6`, ~`7`, ~`8`, ~`9`,\n           1,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           2,   1,   1,   1,   0,   0,   0,   0,   1,   0,\n           3,   1,   1,   1,   0,   0,   0,   1,   1,   1,\n           4,   0,   1,   1,   0,   0,   0,   0,   1,   0,\n           5,   0,   1,   1,   0,   0,   0,   0,   0,   0,\n           6,   0,   0,   0,   1,   0,   0,   0,   0,   0,\n           7,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           8,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           9,   0,   0,   0,   0,   0,   1,   0,   1,   0,\n          10,   0,   0,   0,   0,   0,   0,   1,   0,   0,\n          11,   0,   1,   0,   0,   0,   1,   0,   1,   0,\n          12,   0,   0,   0,   0,   0,   0,   0,   0,   0\n          )\n\nSince the data frame is in the wide format, we need to reshape it to the long format using pivot_longer function of the tidyr package before plotting using ggplot2 package.\n\nlibrary(tidyr)\n\nfoci2 &lt;- foci |&gt; \n  pivot_longer(2:10, names_to = \"y\", values_to = \"i\")\nfoci2\n\n# A tibble: 108 × 3\n       x y         i\n   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;\n 1     1 1         0\n 2     1 2         0\n 3     1 3         0\n 4     1 4         0\n 5     1 5         0\n 6     1 6         0\n 7     1 7         0\n 8     1 8         0\n 9     1 9         0\n10     2 1         1\n# ℹ 98 more rows\n\n\nNow we can make the plot.\n\nlibrary(ggplot2)\nfoci2 |&gt; \n  ggplot(aes(x, y, fill = factor(i)))+\n  geom_tile(color = \"black\")+\n  scale_fill_manual(values = c(\"grey96\", \"grey20\"))+\n  theme_void()+\n  coord_fixed()+\n  theme(legend.position = \"none\")\n\n\n\n\nFigure 15.5: Examples of foci of plant diseases - see text for description\n\n\n\n\nIn the above plot, the upper left focus is composed of four diseased plants with a pattern of vertical and horizontal proximity to the central unit (or the Rook’s case). The upper right focus, also with four diseased plants denotes a pattern of longitudinal proximity to the central unit (or the Bishop’s case). The lower left focus is composed of 11 diseased plants with 4 rows and 6 columns occupied by the focus; the shape index of the focus (SIF) is 1.25 and the compactness index of the focus (CIF) is 0.55. The lower right is a single-unit focus.\nIn this analysis, several statistics can be summarized, both at the single focus and averaging across all foci in the area, including:\n\nNumber of foci (NF) and number of single focus (NSF)\nTo compare maps with different number of plants, NF and NSF can be normalized to 1000 plants as NF1000 and NSF1000\nNumber of plants in each focus i (NPFi)\nMaximum number of rows of the focus i (rfi) and maximum number of columns of the focus i (cfi)\nMean shape index of foci (meanSIF = [∑(fri / cfi)]/NF), where SIF values equal to 1.0 indicate isodiametrical foci; values greater than 1.0 indicate foci with greater length in the direction between the planting rows and values less than 1 indicate foci with greater length in the direction of the planting row.\nMean compactness index of foci (meanCIF = [∑(NPFi/rfi*cfi)]/NF), where CIF values close to 1.0 indicate a more compact foci, that is, greater aggregation and proximity among all the plants belonging to the focus\n\nWe can obtain the above-mentioned foci statistics using the AFSD function of the r4pde package. Let’s calculate for the foci2 dataset already loaded, but first we need to check whether all variables are numeric or integer.\n\nstr(foci2) # y was not numeric\n\ntibble [108 × 3] (S3: tbl_df/tbl/data.frame)\n $ x: num [1:108] 1 1 1 1 1 1 1 1 1 2 ...\n $ y: chr [1:108] \"1\" \"2\" \"3\" \"4\" ...\n $ i: num [1:108] 0 0 0 0 0 0 0 0 0 1 ...\n\nfoci2$y &lt;- as.integer(foci2$y) # transform to numeric\n\nlibrary(r4pde)\nresult_foci &lt;- AFSD(foci2)\n\nThe AFSD function returns a list of three data frames. The first is a summary statistics of this analysis, together with the disease incidence (DIS_INC), for the data frame in analysis.\n\nknitr::kable(result_foci[[1]])\n\n\n\n\nstats\nvalue\n\n\n\n\nNF\n4.0000000\n\n\nNF1000\n37.0370370\n\n\nNSF\n1.0000000\n\n\nNSF1000\n9.2592593\n\n\nDIS_INC\n0.2037037\n\n\nmean_SIF\n1.0625000\n\n\nmean_CIF\n0.6652778\n\n\n\n\n\nThe second object in the list is a data frame with statistics at the focus level, including the number of rows and columns occupied by each focus as well as the two indices for each focus: shape and compactness.\n\nknitr::kable(result_foci[[2]])\n\n\n\n\nfocus_id\nsize\nrows\ncols\nSIF\nCIF\n\n\n\n\n1\n11\n4\n5\n0.8\n0.5500000\n\n\n2\n5\n3\n3\n1.0\n0.5555556\n\n\n3\n5\n3\n3\n1.0\n0.5555556\n\n\n4\n1\n1\n1\n1.0\n1.0000000\n\n\n\n\n\nThe third object is the original data frame amended with the id for each focus which can be plotted and labelled (the focus ID) using the plot_AFSD() function.\n\nfoci_data &lt;- result_foci[[3]]\nDT::datatable(foci_data)\n\n\n\n\n\n\nThe plot shows the ID for each focus.\n\nplot_AFSD(foci_data)+\n  theme_bw()\n\n\n\n\nWe will now analyse an actual data set from the epiphy package. The data describe the incidence of tomato spotted wilt virus (TSWV) disease in field trials. There are two years in the dataset. We will work with the data from 1928 when 6 assessments were made in time. We will first work with time 1 by using filter() function of the dplyr package.\n\nlibrary(epiphy)\ntswv_1928 &lt;- tomato_tswv$field_1928\ndf1 &lt;- tswv_1928 |&gt;\n  filter(t == 1) |&gt; # filter time 1\n  select(x, y, i) # select only three variables\n\nFollows the incidence map of the area at time 1.\n\ndf1 |&gt; \n  ggplot(aes(x, y, fill = factor(i)))+\n  geom_tile(color = \"black\")+\n  theme_void()+\n  scale_fill_grey(start = 0.8, end = 0.2)+\n  coord_fixed()+\n  theme(legend.position = \"none\")\n\n\n\n\nNow we can run the AFSD function and obtain the statistics.\n\nresult_df1 &lt;- AFSD(df1)\n\nknitr::kable(result_df1[[1]])\n\n\n\n\nstats\nvalue\n\n\n\n\nNF\n33.0000000\n\n\nNF1000\n17.8571429\n\n\nNSF\n8.0000000\n\n\nNSF1000\n4.3290043\n\n\nDIS_INC\n0.0784632\n\n\nmean_SIF\n1.1482323\n\n\nmean_CIF\n0.7977633\n\n\n\n\n\nThis analysis is usually applied to multiple maps and the statistics are visually related to the incidence in the area in a scatter plot. Let’s calculate the statistics for all five times of the data frame where we will keep now the time variable in the dataframe and split it by time before applying the function. We can do it using the map function of the purrr package.\n\nlibrary(purrr)\n\ndf_all &lt;- tomato_tswv$field_1928\n\n# Split the dataframe by 'time'\ndf_split &lt;- split(df_all, df_all$t)\n\n# Apply the AFSD function to each split dataframe\nresults &lt;- map(df_split, AFSD)\n\nWe can check the summary results for time 2 and time 3.\n\ntime2 &lt;- data.frame(results[[2]][1])\nknitr::kable(time2)\n\n\n\n\nstats\nvalue\n\n\n\n\nNF\n2.0000000\n\n\nNF1000\n1.0822511\n\n\nNSF\n0.0000000\n\n\nNSF1000\n0.0000000\n\n\nDIS_INC\n0.2364719\n\n\nmean_SIF\n1.7121212\n\n\nmean_CIF\n1.1352814\n\n\n\n\ntime3 &lt;- data.frame(results[[3]][1])\nknitr::kable(time3)\n\n\n\n\nstats\nvalue\n\n\n\n\nNF\n1.0000000\n\n\nNF1000\n0.5411255\n\n\nNSF\n0.0000000\n\n\nNSF1000\n0.0000000\n\n\nDIS_INC\n0.4085498\n\n\nmean_SIF\n0.4242424\n\n\nmean_CIF\n1.6341991\n\n\n\n\n# Plot the results to see the two foci in time 1\nplot_AFSD(results[[1]][[3]])+\n  theme_void()+\n  coord_fixed()\n\n\n\n# Plot time 2\nplot_AFSD(results[[2]][[3]])+\n  theme_void()+\n  coord_fixed()\n\n\n\n\n\n\n15.1.1.4 Join count\nIn this analysis, two adjacent plants may be classified by the type of join that links them: D-D, H-H or H-D. The orientation(s) of interest (along rows, across rows, diagonally, or a a combination o these) should be specified in the test. The number of joins of the specified type in the orientation(s) of interest is then counted. The question is whether the observed join-count is large (or small) relative to that expected for a random pattern. The join-count statistics provides a basic measure of spatial autocorrelation.\nIn R, we can use the join.count() function of the spdep package to perform a joint count test. First, we need to create the series of binary data from top to bottom and left to right. The data are shown in Fig. 9.13 in page 260 of the book chapter on spatial analysis (Madden et al. 2017a). In the example, there are 5 rows and 5 columns. This will be informed later to run the test.\n\nS2 &lt;- c(1,0,1,1,0,\n       1,1,0,0,0,\n       1,0,1,0,0,\n       1,0,0,1,0,\n       0,1,0,1,1)\n\nVisualize the two-dimensional array:\n\n# Convert to raster \nmapS2 &lt;- terra::rast(matrix(S2, 5 , 5))\n# Convert to data frame\nmapS3 &lt;- terra::as.data.frame(mapS2, xy = TRUE)\nmapS3 |&gt;\n  ggplot(aes(x, y, label = lyr.1, fill = factor(lyr.1))) +\n  geom_tile(color = \"white\", size = 0.5) +\n  theme_void() +\n  labs(fill = \"Status\") +\n  scale_fill_manual(values = c(\"gray70\", \"darkred\"))+\n  theme(legend.position = \"top\")\n\n\n\n\nFigure 15.6: Visualization of a matrix of presence or absence data representing a disease spatial pattern\n\n\n\n\nAfter loading the library, we need to generate a list of neighbors (nb) for a grid of cells. This is performed with the cell2nb() function by informing the number of rows and columns. The argument rook means shared edge, but it could be the queen, for shared edge or vertex. We can use the default.\n\nlibrary(spdep)\nnb &lt;- cell2nb(nrow = 5,\n              ncol = 5,\n              type = \"rook\")\n\nThe joincount.test() function runs the BB join count test for spatial autocorrelation. The method uses a spatial weights matrix in weights list form for testing whether same-status joins occur more frequently than would be expected if the zones were labelled in a spatially random way. We need to inform the sequence as factor and the nb object we created previously.\n\njoincount.test(factor(S2), \n                nb2listw(nb))\n\n\n    Join count test under nonfree sampling\n\ndata:  factor(S2) \nweights: nb2listw(nb) \n\nStd. deviate for 0 = -0.58266, p-value = 0.7199\nalternative hypothesis: greater\nsample estimates:\nSame colour statistic           Expectation              Variance \n            2.9583333             3.2500000             0.2505797 \n\n\n    Join count test under nonfree sampling\n\ndata:  factor(S2) \nweights: nb2listw(nb) \n\nStd. deviate for 1 = -0.66841, p-value = 0.7481\nalternative hypothesis: greater\nsample estimates:\nSame colour statistic           Expectation              Variance \n            2.4166667             2.7500000             0.2486957 \n\n\nThe function returns a list with a class for each of the status (in this case 0 and 1) with several components. We should look at the P-value. The alternative hypothesis (greater) is that the same status joins occur more frequently than expected if they were labelled in a spatial random way. In this case, we do not reject the null hypothesis of randomness.\nWe can run the ordinary runs and doublets tests, which only considers the adjacent neighbor, for the same series and compare the results.\n\noruns.test(S2)\n\n$U\n[1] 17\n\n$EU\n[1] 13.48\n\n$pvalue\n[1] 0.1496727\n\n$result\n[1] \"clustering\"\n\ndoublets.test(S2)\n\n$Db\n[1] 3\n\n$EDb\n[1] 5.28\n\n$pvalue\n[1] 0.3009097\n\n$result\n[1] \"randomness\"\n\n\nLet’s repeat the procedure using the second array of data shown in the book chapter, for which the result is different. In this case, there is evidence to reject the null hypothesis, indicating aggregation of plants.\n\nS3 &lt;- c(1,1,1,0,0,\n       1,1,1,0,0,\n       1,1,1,0,0,\n       1,1,1,0,0,\n       0,0,0,0,0)\n\njoincount.test(factor(S3), \n                nb2listw(nb))\n\n\n    Join count test under nonfree sampling\n\ndata:  factor(S3) \nweights: nb2listw(nb) \n\nStd. deviate for 0 = 4.2451, p-value = 1.093e-05\nalternative hypothesis: greater\nsample estimates:\nSame colour statistic           Expectation              Variance \n            5.3750000             3.2500000             0.2505797 \n\n\n    Join count test under nonfree sampling\n\ndata:  factor(S3) \nweights: nb2listw(nb) \n\nStd. deviate for 1 = 4.5953, p-value = 2.16e-06\nalternative hypothesis: greater\nsample estimates:\nSame colour statistic           Expectation              Variance \n            5.0416667             2.7500000             0.2486957 \n\noruns.test(S3)\n\n$U\n[1] 8\n\n$EU\n[1] 13.48\n\n$pvalue\n[1] 0.02490392\n\n$result\n[1] \"clustering\"\n\n\nWe can apply these tests for a real example epidemic data provided by the epiphy R package (Gigot 2018). Let’s work with part of the intensively mapped data on the incidence of tomato spotted wilt virus (TSWV) disease in field trials reported by Cochran (1936) and Bald (1937). First, we need to load the library and then assign one dataframe (the dataset has two dataframes) of the dataset tomato_tswv to a new dataframe called tswv_1929.\n\nlibrary(epiphy)\ntswv_1929 &lt;- tomato_tswv$field_1929\ntswv_1929 |&gt;  head(10) \n\n   x  y t i n\n1  1  1 1 0 1\n2  1  2 1 1 1\n3  1  3 1 0 1\n4  1  4 1 1 1\n5  1  5 1 0 1\n6  1  6 1 0 1\n7  1  7 1 0 1\n8  1  8 1 0 1\n9  1  9 1 1 1\n10 1 10 1 0 1\n\n\nThe inspection of the first 10 rows of the dataframe shows five variables where x and y are spatial grid coordinates, t is assessment time, i is the status of the plant (0 = healthy, 1 = diseased) and n is the sampling unit size (here all one). Let’s visualize these data for each sampling time.\n\ntswv_1929 |&gt;\n  ggplot(aes(x, y, fill = factor(i))) +\n  geom_tile() +\n  coord_fixed() +\n  scale_fill_manual(values = c(\"gray70\", \"darkred\")) +\n  facet_wrap( ~ t) +\n  labs(fill = \"Status\")+\n  theme(legend.position = \"top\")\n\n\n\n\nFigure 15.7: Incidence maps for for tomato spotted wilt virus (TSWV) disease in field trials reported by Cochran (1936) and Bald (1937)\n\n\n\n\nCheck the number of rows (y) and columns (x) for further preparing the neighbor object for the join count statistics.\n\ntswv_1929 |&gt; \n  dplyr::select(x, y) |&gt; \n  summary()\n\n       x               y        \n Min.   : 1.00   Min.   : 1.00  \n 1st Qu.: 6.75   1st Qu.:15.75  \n Median :12.50   Median :30.50  \n Mean   :12.50   Mean   :30.50  \n 3rd Qu.:18.25   3rd Qu.:45.25  \n Max.   :24.00   Max.   :60.00  \n\n\nThere are 60 rows and 24 columns.\n\n# Neighbor grid\nnb1 &lt;- cell2nb(nrow = 60,\n               ncol = 24,\n               type = \"rook\")\n\n# Pull the binary sequence of time 1\nS1 &lt;- tswv_1929 |&gt;\n  filter(t == \"1\") |&gt;\n  pull(i)\n\njoincount.test(factor(S1),\n               nb2listw(nb1))\n\n\n    Join count test under nonfree sampling\n\ndata:  factor(S1) \nweights: nb2listw(nb1) \n\nStd. deviate for 0 = -0.28351, p-value = 0.6116\nalternative hypothesis: greater\nsample estimates:\nSame colour statistic           Expectation              Variance \n           482.000000            482.578874              4.169132 \n\n\n    Join count test under nonfree sampling\n\ndata:  factor(S1) \nweights: nb2listw(nb1) \n\nStd. deviate for 1 = -0.059497, p-value = 0.5237\nalternative hypothesis: greater\nsample estimates:\nSame colour statistic           Expectation              Variance \n            23.458333             23.578874              4.104614 \n\n\nWe can apply the join count test for time 2 and time 3. Results show that the pattern changes from random to aggregate over time.\n\n# Pull the binary sequence of time 1\nS2 &lt;- tswv_1929 |&gt;\n  filter(t == \"2\") |&gt;\n  pull(i)\n\njoincount.test(factor(S2),\n               nb2listw(nb1))\n\n\n    Join count test under nonfree sampling\n\ndata:  factor(S2) \nweights: nb2listw(nb1) \n\nStd. deviate for 0 = 0.35872, p-value = 0.3599\nalternative hypothesis: greater\nsample estimates:\nSame colour statistic           Expectation              Variance \n           317.000000            315.900625              9.392312 \n\n\n    Join count test under nonfree sampling\n\ndata:  factor(S2) \nweights: nb2listw(nb1) \n\nStd. deviate for 1 = 0.34604, p-value = 0.3647\nalternative hypothesis: greater\nsample estimates:\nSame colour statistic           Expectation              Variance \n            82.958333             81.900625              9.342754 \n\n# Pull the binary sequence of time 1\nS3 &lt;- tswv_1929 |&gt;\n  filter(t == \"3\") |&gt;\n  pull(i)\n\njoincount.test(factor(S3), \n                nb2listw(nb1))\n\n\n    Join count test under nonfree sampling\n\ndata:  factor(S3) \nweights: nb2listw(nb1) \n\nStd. deviate for 0 = 1.8541, p-value = 0.03186\nalternative hypothesis: greater\nsample estimates:\nSame colour statistic           Expectation              Variance \n            136.12500             129.92773              11.17243 \n\n\n    Join count test under nonfree sampling\n\ndata:  factor(S3) \nweights: nb2listw(nb1) \n\nStd. deviate for 1 = 1.7275, p-value = 0.04204\nalternative hypothesis: greater\nsample estimates:\nSame colour statistic           Expectation              Variance \n            243.70833             237.92773              11.19743 \n\n\n\n\n\n15.1.2 Point pattern analysis\nPoint pattern analysis involves the study of the spatial arrangement of points in a two-dimensional space. In its simplest form, one can visualize this as a scatterplot on a map, where each point represents an event, object, or entity in space. For example, the points might represent the locations of diseased plants in a population.\nThe easiest way to visualize a 2-D point pattern is to produce a map of the locations, which is simply a scatterplot but with the provision that the axes are equally scaled. However, while the visualization can provide a basic understanding of the spatial distribution, the real power of point pattern analysis lies in the quantitative methods that allow one to analyze the distribution in a more detailed and systematic way. These methods help to identify whether the points are randomly distributed, clustered (points are closer together than expected by chance), or regularly spaced (points are more evenly spaced than expected by chance). This analysis can provide insights into underlying processes that might explain the observed patterns.\nLet’s work with two simulated datasets that were originally generated to produced a random or an aggregated (clustered) pattern.\n\nlibrary(r4pde)\nrand &lt;- SpatialRandom\naggr &lt;- SpatialAggregated\n\nIn order to create a polygon with the most extreme points, we can use the chull() function to find the convex hull, which will give us the indices of the points that form the smallest convex polygon that contains all the points in our dataset.\n\nhull_indices_rand &lt;- chull(rand)\n# Add these indices as a new column to the data frame\nrand$hull &lt;- FALSE\nrand$hull[hull_indices_rand] &lt;- TRUE\n\nhull_indices_aggr &lt;- chull(aggr)\n# Add these indices as a new column to the data frame\naggr$hull &lt;- FALSE\naggr$hull[hull_indices_aggr] &lt;- TRUE\n\nThe two dataframes has two variables each. Let’s produce 2-D map.\n\nprand &lt;- rand |&gt; \n  ggplot(aes(x, y))+\n  geom_polygon(data = rand[hull_indices_rand, ], aes(x, y), fill = NA, color = 'black') +\n  geom_point()+\n  scale_color_manual(values = c(\"black\", NA))+\n  coord_fixed()+\n  coord_flip()+\n  theme_void()+\n  theme(legend.position = \"none\")+\n  labs (title = \"Random spatial pattern\", \n        x = \"Latitude\",\n        y = \"Longitude\",\n        caption = \"Source: r4pd R package\")\n\npaggr &lt;- aggr |&gt; \n  ggplot(aes(x, y))+\n  geom_polygon(data = aggr[hull_indices_aggr, ], aes(x, y), fill = NA, color = 'black') +\n  geom_point()+\n  scale_color_manual(values = c(\"black\", NA))+\n  coord_fixed()+\n  coord_flip()+\n  theme_void()+\n  theme(legend.position = \"none\")+\n  labs (title = \"Aggregated spatial pattern\", \n        x = \"Latitude\",\n        y = \"Longitude\",\n        caption = \"Source: r4pd R package\")\n\nlibrary(patchwork)\nprand | paggr\n\n\n\n\n\n15.1.2.1 Quadrat based\nQuadrat count analysis for random data\n\nlibrary(spatstat)\n### Create window \nwindow_rand &lt;- ripras(rand$x, rand$y)\n\n# create the point pattern object\nppp_rand &lt;- ppp(rand$x, rand$y, window_rand)\nplot(ppp_rand)\n\n\n\n## Quadrat count 10 x 10\nqq &lt;- quadratcount(ppp_rand,8,8, keepempty=TRUE) \n\n# plot the quadrat count\nplot(qq)\n\n\n\n# Quadrat test\nqt &lt;- quadrat.test(qq, alternative=\"clustered\", method=\"M\")\nqt\n\n\n    Conditional Monte Carlo test of CSR using quadrat counts\n    Test statistic: Pearson X2 statistic\n\ndata:  \nX2 = 48.441, p-value = 0.9035\nalternative hypothesis: clustered\n\nQuadrats: 64 tiles (irregular windows)\n\n\nQuadrat count analysis for aggregated data\n\n### Create window \nwindow_aggr &lt;- ripras(aggr$x, aggr$y)\n\n# create the point pattern object\nppp_aggr &lt;- ppp(aggr$x, aggr$y, window_aggr)\nplot(ppp_aggr)\n\n\n\n## Quadrat count 10 x 10\nqq_aggr &lt;- quadratcount(ppp_aggr,8,8, keepempty=TRUE) \n\n# plot the quadrat count\nplot(qq_aggr)\n\n\n\n# Quadrat test\nqt_aggr &lt;- quadrat.test(qq, alternative=\"clustered\", method=\"M\")\nqt_aggr\n\n\n    Conditional Monte Carlo test of CSR using quadrat counts\n    Test statistic: Pearson X2 statistic\n\ndata:  \nX2 = 48.441, p-value = 0.912\nalternative hypothesis: clustered\n\nQuadrats: 64 tiles (irregular windows)\n\n\n\n\n15.1.2.2 Spatial KS test\nPerforms a test of goodness-of-fit test of the uniform Poisson point process (Complete Spatial Randomness, CSR) for the data set. The test is performed by comparing the observed distribution of the values of a spatial covariate at the data points, and the predicted distribution of the same covariate under the model, using a classical goodness-of-fit test Baddeley et al. (2005). Thus, we must nominate a spatial covariate for this test. In the case below we nominate x, y or x and y as covariate.\nLet’s test for the aggregated data.\n\n# y as covariate\nks_y &lt;- cdf.test(ppp_aggr, test=\"ks\", \"y\", jitter=FALSE)\nks_y\n\n\n    Spatial Kolmogorov-Smirnov test of CSR in two dimensions\n\ndata:  covariate 'y' evaluated at points of 'ppp_aggr' \n     and transformed to uniform distribution under CSR\nD = 0.075883, p-value = 0.1821\nalternative hypothesis: two-sided\n\nplot(ks_y)\n\n\n\n# x as covariate\nks_x &lt;- cdf.test(ppp_aggr, test=\"ks\", \"x\", jitter=FALSE)\nks_x\n\n\n    Spatial Kolmogorov-Smirnov test of CSR in two dimensions\n\ndata:  covariate 'x' evaluated at points of 'ppp_aggr' \n     and transformed to uniform distribution under CSR\nD = 0.09506, p-value = 0.04661\nalternative hypothesis: two-sided\n\nplot(ks_x)\n\n\n\n# x and y as covariates\nfun &lt;- function(x,y){2* x + y}\nks_xy &lt;- cdf.test(ppp_aggr, test=\"ks\", fun, jitter=FALSE)\nks_xy\n\n\n    Spatial Kolmogorov-Smirnov test of CSR in two dimensions\n\ndata:  covariate 'fun' evaluated at points of 'ppp_aggr' \n     and transformed to uniform distribution under CSR\nD = 0.12026, p-value = 0.004875\nalternative hypothesis: two-sided\n\nplot(ks_xy)\n\n\n\n\nAs shown above, we have sufficient evidence to reject the null hypothesis of complete spatial randomness.\n\n\n15.1.2.3 Distance based\nA spatial point process is a set of irregularly distributed locations within a defined region which are assumed to have been generated by some form of stochastic mechanism.\nThe K function, a.k.a. Ripley’s K-function, is a statistical measure used in spatial analysis to examine the spatial distribution of a single type of point in a given area. Named after its developer, the British statistician B.D. Ripley, the K-function measures the expected number of points within a given distance of an arbitrary point, assuming homogeneous intensity (a constant probability of a point occurring in a particular place).\nTo describe it simply: imagine you have a map of diseased trees in a forest, and you select a tree at random. The K-function helps you answer the question: “How many other diseased trees do I expect to find within a certain distance from the diseased tree I’ve chosen?”\nThe K-function is often used to identify and analyze patterns within spatial data, such as clustering, randomness, or regularity (dispersion). It is particularly useful because it looks at the distribution at all scales (distances) simultaneously. To interpret the results of Ripley’s K-function:\n\nRandom distribution: If the points (like trees in our example) are randomly distributed, the plot of the K-function will be a straight line at a 45-degree angle.\nClustered distribution: If the points are clustered (grouped closer together than you’d expect by chance), the plot will be above the 45-degree line of the random expectation.\nRegular or dispersed distribution: If the points are regularly spaced or dispersed (further apart than you’d expect by chance), the plot will be below the 45-degree line.\n\nRipley’s K checks the density of diseased units in each area by the variance as a function of radial distances (r) from the diseased unit, hence K(r). If the spatial localization of a diseased unit is independent, the process is random in space.\nLet’s use the Kest function of the spatstat package to obtain K(r).\n\nk_rand &lt;- Kest(ppp_rand)\nplot(k_rand)\n\n\n\nk_aggr &lt;- Kest(ppp_aggr)\nplot(k_aggr)\n\n\n\n\nThe envelope function performs simulations and computes envelopes of a summary statistic based on the simulations. The envelope can be used to assess the goodness-of-fit of a point process model to point pattern data (Baddeley et al. 2014). Let’s simulate the envelope and plot the values using ggplot. Because observed K(r) (solid line) lied outside the simulation envelope, aggregation was detected.\n\nke &lt;- envelope(ppp_aggr, fun = Kest)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98,  99.\n\nDone.\n\ndata.frame(ke) |&gt; \n  ggplot(aes(r, theo))+\n  geom_line(linetype =2)+\n  geom_line(aes(r, obs))+\n  geom_ribbon(aes(ymin = lo, ymax = hi),\n              fill = \"steelblue\", alpha = 0.5)+\n  labs(y = \"K(r)\", x = \"r\")+\n  theme_bw(base_size = 16)\n\n\n\n\nmad.test performs the ‘global’ or ‘Maximum Absolute Deviation’ test described by Ripley (1977, 1981). See (Baddeley et al. 2014). This performs hypothesis tests for goodness-of-fit of a point pattern data set to a point process model, based on Monte Carlo simulation from the model.\n\n# Maximum absolute deviation test\nmad.test(ppp_aggr, Kest)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98,  99.\n\nDone.\n\n\n\n    Maximum absolute deviation test of CSR\n    Monte Carlo test based on 99 simulations\n    Summary function: K(r)\n    Reference function: theoretical\n    Alternative: two.sided\n    Interval of distance values: [0, 50.8401070056579]\n    Test statistic: Maximum absolute deviation\n    Deviation = observed minus theoretical\n\ndata:  ppp_aggr\nmad = 1765.1, rank = 1, p-value = 0.01\n\nmad.test(ppp_rand, Kest)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98,  99.\n\nDone.\n\n\n\n    Maximum absolute deviation test of CSR\n    Monte Carlo test based on 99 simulations\n    Summary function: K(r)\n    Reference function: theoretical\n    Alternative: two.sided\n    Interval of distance values: [0, 45.9916850622588]\n    Test statistic: Maximum absolute deviation\n    Deviation = observed minus theoretical\n\ndata:  ppp_rand\nmad = 122.15, rank = 84, p-value = 0.84\n\n\nAnother statistics that can be used is the O-ring statitics which are used in spatial analysis to quantify and test the degree of interaction between two types of spatial points (Wiegand and A. Moloney 2004). The name derives from the method of placing a series of concentric circles (O-rings) around each point of type 1 and counting how many points of type 2 fall within each ring. The plot generated by O-ring statistics is called an O-ring plot or an O-function plot. It plots the radius of the rings on the x-axis and the estimated intensity of points of type 2 around points of type 1 on the y-axis.\nInterpreting the plot is as follows:\n\nRandom pattern: If points of type 2 are randomly distributed around points of type 1, the O-ring plot will be a flat line. This means that the intensity of points of type 2 does not change with the distance to points of type 1.\nAggregation or clustering: If points of type 2 are aggregated around points of type 1, the O-ring plot will be an upward-sloping curve. This indicates that the intensity of points of type 2 increases with proximity to points of type 1.\nDispersion: If points of type 2 are dispersed away from points of type 1, the O-ring plot will be a downward-sloping curve. This shows that the intensity of points of type 2 decreases as you get closer to points of type 1.\n\nThe O-ring plot often includes a confidence envelope. If the O-ring statistic falls within this envelope, it suggests that the observed pattern could be the result of random spatial processes. If it falls outside the envelope, it suggests that the pattern is not random. Therefore, to decide whether a pattern is aggregated or random using O-ring statistics:\n\nLook at the shape of the O-ring plot.\nCompare the O-ring statistic to the confidence envelope.\n\nAn aggregated pattern will show an increasing curve that lies outside the confidence envelope, indicating that the density of type 2 points is higher close to type 1 points. On the other hand, a random pattern will show a flat line that lies within the confidence envelope, indicating no significant difference in the density of type 2 points around type 1 points at varying distances.\nIn R, we can use the estimate_o_ring() function of the onpoint package. We will use the point pattern object ppp_fw used in the previous examples\n\nlibrary(onpoint)\nplot(estimate_o_ring(ppp_rand))\n\n\n\nplot(estimate_o_ring(ppp_aggr))\n\n\n\n\nThe function can be used in combination with spatstat’s envelope() function.\n\noring_envelope &lt;- envelope(ppp_aggr, fun = estimate_o_ring, nsim = 199, verbose = FALSE)\nplot(oring_envelope)\n\n\n\n\nTo plot simulation envelopes using quantum plots (Esser et al. 2014), just pass an envelope object as input to plot_quantums().\n\nplot_quantums(oring_envelope, ylab = \"O-ring\")\n\n\n\n\n\n\n\n15.1.3 Grouped data\nIf the data are intensively mapped, meaning that the spatial locations of the sampling units are known, we are not limited to analyse presence/absence (incidence) only data at the unit level. The sampling units may be quadrats where the total number of plants and the number of disease plants (or number of pathogen propagules) are known. Alternatively, it could be a continuous measure of severity. The question here, similar to the previous section, is whether a plant being diseased makes it more (or less) likely that neighboring plants will be diseased. If that is the case, diseased plants are exhibiting spatial autocorrelation. The most common methods are autocorrelation (known as Moran’s I), semivariance and SADIE (an alternative approach to autocorrelation.)\n\n15.1.3.1 Autocorrelation\nSpatial autocorrelation analysis provides a quantitative assessment of whether a large value of disease intensity in a sampling unit makes it more (positive autocorrelation) or less (negative auto- correlation) likely that neighboring sampling units tend to have a large value of disease intensity (Madden et al. 2017a).\nWe will illustrate the method by reproducing the example provided in page 264 of the chapter on spatial analysis (Madden et al. 2017a), which was extracted from table 11.3 of Campbell and Madden. L. (1990). The data represent a single transect with the number of Macrophomia phaseolina propagules per 10 g air-dry soil recorded in 16 contiguous quadrats across a field.\n\nmp &lt;- data.frame(\n  i = c(1:16),\n  y = c(41, 60, 81, 22, 8, 20, 28, 2, 0, 2, 2, 8, 0, 43, 61, 50)\n)\nmp\n\n    i  y\n1   1 41\n2   2 60\n3   3 81\n4   4 22\n5   5  8\n6   6 20\n7   7 28\n8   8  2\n9   9  0\n10 10  2\n11 11  2\n12 12  8\n13 13  0\n14 14 43\n15 15 61\n16 16 50\n\n\nWe can produce a plot to visualize the number of propagules across the transect.\n\nmp |&gt;\n  ggplot(aes(i, y)) +\n  geom_col(fill = \"darkred\") +\n  labs(\n    x = \"Relative position within a transect\",\n    y = \"Number of propagules\",\n    caption = \"Source: Campbell and Madden (1990)\"\n  )\n\n\n\n\nFigure 15.8: Number of propagules of Macrophomina phaseolina in the soil at various positions within a transect\n\n\n\n\nTo calculate the autocorrelation coefficient in R, we can use the ac() function of the tseries package.\n\nlibrary(tseries)\nac_mp &lt;- acf(mp$y, lag = 5, pl = FALSE)\nac_mp\n\n\nAutocorrelations of series 'mp$y', by lag\n\n     0      1      2      3      4      5 \n 1.000  0.586  0.126 -0.033 -0.017 -0.181 \n\n\nLet’s store the results in a data frame to facilitate visualization.\n\nac_mp_dat &lt;- data.frame(index = ac_mp$lag, ac_mp$acf)\nac_mp_dat\n\n  index   ac_mp.acf\n1     0  1.00000000\n2     1  0.58579374\n3     2  0.12636306\n4     3 -0.03307249\n5     4 -0.01701392\n6     5 -0.18092810\n\n\nAnd now the plot known as autocorrelogram.\n\nac_mp_dat |&gt;\n  ggplot(aes(index, ac_mp.acf, label = round(ac_mp.acf, 3))) +\n  geom_col(fill = \"darkred\") +\n  geom_text(vjust = 0, nudge_y = 0.05) +\n  scale_x_continuous(n.breaks = 6) +\n  geom_hline(yintercept = 0) +\n  labs(x = \"Distance lag\", y = \"Autocorrelation coefficient\")\n\n\n\n\nFigure 15.9: Autocorrelogram for the spatial distribution of Macrophomina phaseolina in soil\n\n\n\n\nThe values we obtained here are not the same but quite close to the values reported in Madden et al. (2017b). For the transect data, the calculated coefficients in the book example for lags 1, 2 and 3 are 0.625, 0.144, and - 0.041. The conclusion is the same, the smaller the distance between sampling units, the stronger is the correlation between the count values.\nThe method above is usually referred to Moran’s I (Moran 1950). Let’s use another example dataset from the book to calculate the Moran’s I in R. The data is shown in page 269 of the book. The data represent the number of diseased plants per quadrat (out of a total of 100 plants in each) in 144 quadrats. It was based on an epidemic generated using the stochastic simulator of Xu and Madden (2004). The data is stored in a CSV file.\n\nepi &lt;- read_csv(\"https://raw.githubusercontent.com/emdelponte/epidemiology-R/main/data/xu-madden-simulated.csv\")\nepi1 &lt;- epi |&gt;\n  pivot_longer(2:13,\n               names_to = \"y\",\n               values_to = \"n\") |&gt;\n  pull(n)\n\nUsing moran() function of the spdep R package.\n\nset.seed(100)\nlibrary(spdep)\n\nThe cell2nb() function creates the neighbor list with 12 rows and 12 columns, which is how the 144 quadrats are arranged.\n\nnb &lt;- cell2nb(12, 12, type = \"queen\", torus = FALSE)\n\nThe nb2listw() function supplements a neighbors list with spatial weights for the chosen coding scheme. We use the default W, which is the row standardized (sums over all links to n). We then create the col.W neighbor list.\n\ncol.W &lt;- nb2listw(nb, style = \"W\")\n\nThe Moran’s I statistic is given by the moran() function\n\nmoran(x = epi1, # numeric vector\n      listw = col.W, # the nb list\n      n = 12, # number of zones\n      S0 = Szero(col.W)) # global sum of weights\n\n$I\n[1] 0.05818595\n\n$K\n[1] 2.878088\n\n\nThe Moran’s test for spatial autocorrelation uses spatial weights matrix in weights list form.\n\nmoran.test(x = epi1, \n           listw = col.W)\n\n\n    Moran I test under randomisation\n\ndata:  epi1  \nweights: col.W    \n\nMoran I statistic standard deviate = 15.919, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.698231416      -0.006993007       0.001962596 \n\n\n\ncorrel_I &lt;- sp.correlogram(nb, epi1, \n                           order = 10,\n                           method = \"I\",  \n                           zero.policy = TRUE)\n\nWe can generate a correlogram using the output of the sp.correlogram() function. Note that the figure below is very similar to the one shown in Figure 91.5 in page 269 of the book chapter (Madden et al. 2017a). Let’s store the results in a dataframe.\n\ndf_correl &lt;- data.frame(correl_I$res) |&gt; \n  mutate(lag = c(1:10))\n\n# Show the spatial autocorrelation for 10 distance lags\nround(df_correl$X1,3)\n\n [1]  0.698  0.340  0.086 -0.002 -0.009 -0.024 -0.090 -0.180 -0.217 -0.124\n\n\nThen, we can generate the plot using ggplot.\n\ndf_correl |&gt;\n  ggplot(aes(lag, X1)) +\n  geom_col(fill = \"darkred\") +\n  scale_x_continuous(n.breaks = 10) +\n  labs(x = \"Distance lag\", y = \"Spatial autocorrelation\")\n\n\n\n\nFigure 15.10: Autocorrelogram for the spatial distribution of simulated epidemics\n\n\n\n\n\n\n15.1.3.2 Semivariance\nSemi-variance is a key quantity in geostatistics. This differs from spatial autocorrelation because distances are usually measured in discrete spatial lags. The semi-variance can be defined as half the variance of the differences between all possible points spaced a constant distance apart.\nThe semi-variance at a distance d = 0 will be zero, because there are no differences between points that are compared to themselves. However, as points are compared to increasingly distant points, the semi-variance increases. At some distance, called the Range, the semi-variance will become approximately equal to the variance of the whole surface itself. This is the greatest distance over which the value at a point on the surface is related to the value at another point. In fact, when the distance between two sampling units is small, the sampling units are close together and, usually, variability is low. As the distance increases, so (usually) does the variability.\nResults of semi-variance analysis are normally presented as a graphical plot of semi-variance against distance, which is referred to as a semi-variogram. The main characteristics of the semi-variogram of interest are the nugget, the range and the sill, and their estimations are usually based on an appropriate (non-linear) model fitted to the data points representing the semi-variogram.\nFor the semi-variance, we will use the variog() function of the geoR package. We need the data in the long format (x, y and z). Let’s reshape the data to the long format and store it in epi2 dataframe.\n\nepi2 &lt;- epi |&gt;\n  pivot_longer(2:13,\n               names_to = \"y\",\n               values_to = \"n\") |&gt;\n  mutate(y = as.numeric(y))\n\nhead(epi2)\n\n# A tibble: 6 × 3\n      x     y     n\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1     1     2\n2     1     2     2\n3     1     3     3\n4     1     4    33\n5     1     5     4\n6     1     6     0\n\n\n\nlibrary(geoR)\n# the coordinates are x and y and the data is the n\nv1 &lt;- variog(coords = epi2[,1:2], data = epi2[,3])\n\nvariog: computing omnidirectional variogram\n\n\n\nv2 &lt;- variofit(v1, ini.cov.pars = c(1200, 12), \n               cov.model = \"exponential\", \n               fix.nugget = F)\n\nvariofit: covariance model used is exponential \nvariofit: weights used: npairs \nvariofit: minimisation function used: optim \n\n# Plotting \nplot(v1, xlim = c(0,15))\nlines(v2, lty = 1, lwd = 2)\n\n\n\n\nFigure 15.11: Semivariance plot for the spatial distribution simulated epidemic\n\n\n\n\n\n\n15.1.3.3 SADIE\nSADIE (spatial analysis by distance indices) is an alternative to autocorrelation and semi-variance methods described previously, which has found use in plant pathology (Madden et al. 2017a; Xu and Madden 2004; Li et al. 2011). Similar to those methods, the spatial coordinates for the disease intensity (count of diseased individuals) or pathogen propagules values should be provided.\nSADIE quantifies spatial pattern by calculating the minimum total distance to regularity. That is, the distance that individuals must be moved from the starting point defined by the observed counts to the end point at which there is the same number of individuals in each sampling unit. Therefore, if the data are highly aggregated, the distance to regularity will be large, but if the data are close to regular to start with, the distance to regularity will be smaller.\nThe null hypothesis to test is that the observed pattern is random. SADIE calculates an index of aggregation (Ia). When this is equal to 1, the pattern is random. If this is greater than 1, the pattern is aggregated. Hypothesis testing is based on the randomization procedure. The null hypothesis of randomness, with an alternative hypothesis of aggregation.\nAn extension was made to quantify the contribution of each sampling unit count to the observed pattern. Regions with large counts are defined as patches and regions with small counts are defined as gaps. For each sampling unit, a clustering index is calculated and can be mapped.\nIn R, we can use the sadie() function of the epiphy package (Gigot 2018). The function computes the different indices and probabilities based on the distance to regularity for the observed spatial pattern and a specified number of random permutations of this pattern. To run the analysis, the dataframe should have only three columns: the first two must be the x and y coordinates and the third one the observations. Let’s continue working with the simulated epidemic dataset named epi2. We can map the original data as follows:\n\nepi2 |&gt;\n  ggplot(aes(x, y, label = n, fill = n)) +\n  geom_tile() +\n  geom_text(size = 5, color = \"white\") +\n  theme_void() +\n  coord_fixed() +\n  scale_fill_gradient(low = \"gray70\", high = \"darkred\")\n\n\n\n\nFigure 15.12: Spatial map for the number of diseased plants per quadrat (n = 144) in simulated epidemic\n\n\n\n\n\nlibrary(epiphy)\nsadie_epi2 &lt;- sadie(epi2)\n\nComputation of Perry's indices:\n\nsadie_epi2\n\nSpatial Analysis by Distance IndicEs (sadie)\n\nCall:\nsadie.data.frame(data = epi2)\n\nIa: 2.4622 (Pa = &lt; 2.22e-16)\n\n\nThe simple output shows the Ia value and associated P-value. As suggested by the low value of the P-value, the pattern is highly aggregated. The summary() function provides a more complete information such as the overall inflow and outflow measures. A dataframe with the clustering index for each sampling unit is also provided using the summary() function.\n\nsummary(sadie_epi2)\n\n\nCall:\nsadie.data.frame(data = epi2)\n\nFirst 6 rows of clustering indices:\n  x y  i cost_flows      idx_P idx_LMX prob\n1 1 1  2 -11.382725 -7.2242617      NA   NA\n2 1 2  2  -9.461212 -6.2258877      NA   NA\n3 1 3  3  -7.299482 -5.3390880      NA   NA\n4 1 4 33   1.000000  0.8708407      NA   NA\n5 1 5  4  -5.830952 -3.6534511      NA   NA\n6 1 6  0  -5.301329 -2.9627172      NA   NA\n\nSummary indices:\n                      overall    inflow  outflow\nPerry's index        2.495346 -2.811023 2.393399\nLi-Madden-Xu's index       NA        NA       NA\n\nMain outputs:\nIa: 2.4622 (Pa = &lt; 2.22e-16)\n\n'Total cost': 201.6062\nNumber of permutations: 100\n\n\nThe plot() function allows to map the clustering indices and so to identify regions of patches (red, outflow) and gaps (blue, inflow).\n\nplot(sadie_epi2)\n\n\n\n\nFigure 15.13: Map of the SADIE clustering indices where red identifiy patches (outflow) and blue identify gaps (inflow)\n\n\n\n\nA isocline plot can be obtained by setting the isocline argument as TRUE.\n\nplot(sadie_epi2, isoclines = TRUE)\n\n\n\n\nFigure 15.14: Map of the SADIE clustering indices"
  },
  {
    "objectID": "spatial-tests.html#sparsely-sampled-data",
    "href": "spatial-tests.html#sparsely-sampled-data",
    "title": "15  Tests for patterns",
    "section": "15.2 Sparsely sampled data",
    "text": "15.2 Sparsely sampled data\nDifferent from intensively mapped data, sparsely sampled data do not contain information about the spatial location of the units, and so it is not taken into account in the analysis. The analysis of sparsely sampled data usually involves characterizing the extent of variability in the mean level of disease intensity per sampling unit (Madden et al. 2017a). There are two types of approaches to analyse these data in the context of spatial patterns of plant disease epidemics: 1) testing the goodness of fit to statistical probability distributions and 2) calculating indices of aggregation. These will be discussed further separated depending on the nature of the data, whether count or incidence (proportion), for which specific distributions are assumed to describe the data.\n\n15.2.1 Count data\n\n15.2.1.1 Fit to distributions\nTwo statistical distributions can be adopted as reference for the description of random or aggregated patterns of disease data in the form of counts of infection within sampling units. Take the count of lesions on a leaf, or the count of diseased plants on a quadrat, as an example. If the presence of a lesion/diseased plant does not increase or decrease the chance that other lesions/diseased plants will occur, the Poisson distribution describes the distribution of lesions on the leaf. Otherwise, the negative binomial provides a better description.\nLet’s work with the previous simulation data of 144 quadrats with a variable count of diseased plants per quadrat (in a maximum of 100). Notice that we won’t consider the location of each quadrat as in the previous analyses of intensively mapped data. We only need the vector with the number of infected units per sampling unit.\nThe epiphy package provides a function called fit_two_distr(), which allows fitting these two distribution for count data. In this case, either randomness assumption (Poisson distributions) or aggregation assumption (negative binomial) are made, and then, a goodness-of-fit comparison of both distributions is performed using a log-likelihood ratio test. The function requires a dataframe created using the count() function where the number of infection units is designated as i. It won’t work with a single vector of numbers. We create the dataframe using:\n\ndata_count &lt;- epi2 |&gt; \n  mutate(i = n) |&gt;  # create i vector\n  epiphy::count()   # create the map object of count class\n\nWe can now run the function that will look fo the the vector i. The function returns a list of four components including the outputs of the fitting process for both distribution and the result of the log-likelihood ratio test, the llr.\n\nfit_data_count &lt;- fit_two_distr(data_count)\nsummary(fit_data_count)\n\nFitting of two distributions by maximum likelihood\nfor 'count' data.\nParameter estimates:\n\n(1) Poisson (random):\n       Estimate  Std.Err Z value    Pr(&gt;z)    \nlambda 27.85417  0.43981  63.333 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(2) Negative binomial (aggregated):\n       Estimate    Std.Err Z value    Pr(&gt;z)    \nk     0.6327452  0.0707846  8.9390 &lt; 2.2e-16 ***\nmu   27.8541667  2.9510198  9.4388 &lt; 2.2e-16 ***\nprob  0.0222118  0.0033463  6.6378 3.184e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nfit_data_count$llr\n\nLikelihood ratio test\n\n               LogLik Df  Chisq Pr(&gt;Chisq)    \nrandom :     -2654.71                         \naggregated :  -616.51  1 4076.4  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe very low value of the P-value of the LLR test suggest that the negative binomial provides a better fit to the data. The plot() function allows for visualizing the expected random and aggregated frequencies together with the observed frequencies. The number of breaks can be adjusted as indicated.\n\nplot(fit_data_count, breaks = 5) \n\n\n\n\nFigure 15.15: Frequencies of the observed and expected aggregated and random distributions\n\n\n\n\nSee below another way to plot by extracting the frequency data (and pivoting from wide to long format) from the generated list and using ggplot. Clearly, the negative binomial is a better description for the observed count data.\n\ndf &lt;- fit_data_count$freq |&gt;\n  pivot_longer(2:4, names_to = \"pattern\", values_to = \"value\")\n\ndf |&gt;\n  ggplot(aes(category, value, fill = pattern)) +\n  geom_col(position = \"dodge\", width = 2) +\n  scale_fill_manual(values = c(\"gray70\", \"darkred\", \"steelblue\")) +\n  theme(legend.position = \"top\")\n\n\n\n\nFigure 15.16: Frequencies of the observed and expected aggregated and random distributions\n\n\n\n\n\n\n15.2.1.2 Aggregation indices\n\nidx &lt;- agg_index(data_count, method = \"fisher\")\nidx\n\nFisher's index of dispersion:\n(Version for count data)\n34.25\n\nchisq.test(idx)\n\n\n    Chi-squared test for (N - 1)*index following a chi-squared\n    distribution (df = N - 1)\n\ndata:  idx\nX-squared = 4897.2, df = 143, p-value &lt; 2.2e-16\n\nz.test(idx)\n\n\n    One-sample z-test\n\ndata:  idx\nz = 82.085, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n# Lloyd index\n\nidx_lloyd &lt;- agg_index(data_count, method = \"lloyd\")\nidx_lloyd\n\nLloyd's index of patchiness:\n2.194\n\nidx_mori &lt;- agg_index(data_count, method = \"morisita\")\nidx_mori\n\nMorisita's coefficient of dispersion:\n(Version for count data)\n2.186\n\n# Using the vegan package\nlibrary(vegan)\nz &lt;- data_count$data$i\nmor &lt;- dispindmorisita(z)\nmor\n\n      imor     mclu      muni      imst pchisq\n1 2.185591 1.008728 0.9922162 0.5041152      0\n\n\n\n\n15.2.1.3 Power law\nWhen we have a collection of count data sets at the sampling unit scale the Taylor’s power law (TPL) can be used to assess the overall degree of heterogeneity.\n\n\n\n15.2.2 Incidence data\n\n15.2.2.1 Fit to distributions\n\ntas &lt;-\n  read.csv(\n    \"https://www.apsnet.org/edcenter/disimpactmngmnt/topc/EcologyAndEpidemiologyInR/SpatialAnalysis/Documents/tasmania_test_1.txt\",\n    sep = \"\"\n  )\nhead(tas,10)\n\n   quad group_size count\n1     1          6     4\n2     2          6     6\n3     3          6     6\n4     4          6     6\n5     5          6     6\n6     6          6     6\n7     7          6     6\n8     8          6     6\n9     9          6     4\n10   10          6     6\n\n# Create incidence object for epiphy\ndat_tas &lt;- tas |&gt;\n  mutate(n = group_size, i = count) |&gt;\n  epiphy::incidence()\n\n## Fit to two distributions\nfit_tas &lt;- fit_two_distr(dat_tas)\nsummary(fit_tas)\n\nFitting of two distributions by maximum likelihood\nfor 'incidence' data.\nParameter estimates:\n\n(1) Binomial (random):\n     Estimate Std.Err Z value    Pr(&gt;z)    \nprob  0.90860 0.01494  60.819 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(2) Beta-binomial (aggregated):\n      Estimate  Std.Err Z value    Pr(&gt;z)    \nalpha 1.923479 0.869621  2.2119  0.026976 *  \nbeta  0.181337 0.075641  2.3973  0.016514 *  \nprob  0.913847 0.023139 39.4943 &lt; 2.2e-16 ***\nrho   0.322080 0.096414  3.3406  0.000836 ***\ntheta 0.475101 0.209789  2.2647  0.023534 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nfit_tas$llr\n\nLikelihood ratio test\n\n              LogLik Df  Chisq Pr(&gt;Chisq)    \nrandom :     -75.061                         \naggregated : -57.430  1 35.263   2.88e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nplot(fit_tas)\n\n\n\n\n\n\n15.2.2.2 Aggregation indices\nglm model\n\nbinom.tas = glm(cbind(count, group_size - count) ~ 1,\n                family = binomial,\n                data = tas)\nsummary(binom.tas)\n\n\nCall:\nglm(formula = cbind(count, group_size - count) ~ 1, family = binomial, \n    data = tas)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-3.447   1.073   1.073   1.073   1.073  \n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   2.2967     0.1799   12.77   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 117.76  on 61  degrees of freedom\nResidual deviance: 117.76  on 61  degrees of freedom\nAIC: 152.12\n\nNumber of Fisher Scoring iterations: 5\n\nlibrary(performance)\ncheck_overdispersion(binom.tas)\n\n# Overdispersion test\n\n       dispersion ratio =   2.348\n  Pearson's Chi-Squared = 143.206\n                p-value = &lt; 0.001\n\n\nepiphy(c-alpha test)\n\nlibrary(epiphy)\ntas2 &lt;- tas |&gt;\n  mutate(i = count,\n         n = group_size) |&gt;  # create i vector\n  epiphy::incidence()\n\nt &lt;- agg_index(tas2, flavor = \"incidence\")\nt\n\nFisher's index of dispersion:\n(Version for incidence data)\n2.348\n\n\n\ncalpha.test(t)\n\n\n    C(alpha) test\n\ndata:  t\nz = 7.9886, p-value = 1.365e-15\n\n\n\n\n15.2.2.3 Binary power law\nWhen we have a collection of incidence data sets at the sampling unit scale the binary form of the power law can be used to assess the overall degree of heterogeneity. This spatial analysis method describes the relationship between the observed variance of diseased individuals within a data set and the corresponding variance under the assumption that the data have a random distribution distribution (i.e., Binomial for proportion data).\n\n\n\n\nBaddeley, A., Diggle, P. J., Hardegen, A., Lawrence, T., Milne, R. K., and Nair, G. 2014. On tests of spatial pattern based on simulation envelopes. Ecological Monographs. 84:477–489 Available at: http://dx.doi.org/10.1890/13-2042.1.\n\n\nBaddeley, A., Turner, R., Moller, J., and Hazelton, M. 2005. Residual analysis for spatial point processes (with discussion). Journal of the Royal Statistical Society: Series B (Statistical Methodology). 67:617–666 Available at: http://dx.doi.org/10.1111/j.1467-9868.2005.00519.x.\n\n\nCampbell, C. L., and Madden. L., V. 1990. Introduction to plant disease epidemiology. Wiley.\n\n\nEsser, D. S., Leveau, J. H. J., Meyer, K. M., and Wiegand, K. 2014. Spatial scales of interactions among bacteria and between bacteria and the leaf surface. FEMS Microbiology Ecology. 91 Available at: http://dx.doi.org/10.1093/femsec/fiu034.\n\n\nGigot, C. 2018. Epiphy: Analysis of plant disease epidemics.\n\n\nJesus Junior, W. C. de, and Bassanezi, R. B. 2004. Análise da dinâmica e estrutura de focos da morte súbita dos citros. Fitopatologia Brasileira. 29:399–405 Available at: http://dx.doi.org/10.1590/S0100-41582004000400007.\n\n\nLaranjeira, F. F., Bergamin Filho, A. R., and Amorim, L. I. 1998. Dinâmica e estrutura de focos da clorose variegada dos citros (CVC). Fitopatologia Brasileira. 23:36–41.\n\n\nLaranjeira, F. F., Bergamin Filho, A., Amorim, L., and Gottwald, T. R. 2004. Dinâmica espacial da clorose variegada dos citros em três regiões do estado de são paulo. Fitopatologia Brasileira. 29:56–65 Available at: http://dx.doi.org/10.1590/S0100-41582004000100009.\n\n\nLi, B., Madden, L. V., and Xu, X. 2011. Spatial analysis by distance indices: an alternative local clustering index for studying spatial patterns. Methods in Ecology and Evolution. 3:368–377 Available at: http://dx.doi.org/10.1111/j.2041-210x.2011.00165.x.\n\n\nMadden, L. V., Hughes, G., and van den Bosch, F. 2017a. Spatial aspects of epidemicsIII: Patterns of plant disease. In The American Phytopathological Society, p. 235–278. Available at: http://dx.doi.org/10.1094/9780890545058.009.\n\n\nMadden, L. V., Hughes, G., and van den Bosch, F. 2017b. The study of plant disease epidemics. The American Phytopathological Society. Available at: http://dx.doi.org/10.1094/9780890545058.\n\n\nMoran, P. A. P. 1950. Notes on continuous stochastic phenomena. Biometrika. 37:17.\n\n\nNelson, S. C. 1996. A simple analysis of disease foci. Phytopathology. 86:432–439.\n\n\nWiegand, T., and A. Moloney, K. 2004. Rings, circles, and null-models for point pattern analysis in ecology. Oikos. 104:209–229 Available at: http://dx.doi.org/10.1111/j.0030-1299.2004.12497.x.\n\n\nXu, X.-M., and Madden, L. V. 2004. Use of SADIE statistics to study spatial dynamics of plant disease epidemics. Plant Pathology. 53:38–49 Available at: http://dx.doi.org/10.1111/j.1365-3059.2004.00949.x."
  },
  {
    "objectID": "yieldloss-concepts.html#introduction",
    "href": "yieldloss-concepts.html#introduction",
    "title": "16  Definitions and concepts",
    "section": "16.1 Introduction",
    "text": "16.1 Introduction\nPlant disease epidemics significantly impact agricultural production, particularly affecting crop yield - the measurable produce such as seed, fruit, leaves, roots or tubers - and quality, which includes factors such as blemishes on fruit and toxins in grain. Studying these impacts is crucial to understanding the overall repercussions of plant diseases on agriculture.\nThe yield of some crops can be severely diminished if they host a pathogen for a prolonged period of time. The plant’s physiology is dynamically and negatively affected as the crop grows, leading to an increase in biomass and advancement through phenological stages. For some diseases that primarily infect the end product, like grains, yield is directly impacted with a reduction in size and weight of the affected plant part.\nCertain plant diseases cause visual damage to the product, such as fruit or tubers, which may not result in a reduction in yield, but the presence of the symptoms can adversely affect sales due to decreased marketability. Furthermore, the presence of toxins in the product caused by some diseases can significantly downgrade its value, posing both health risks and economic losses.\nLosses due to plant diseases can be categorized as direct, affecting the farm itself, or indirect, having broader impacts on society. Direct losses on the farm due to plant diseases are primarily due to reductions in the quantity and quality of yield, as well as the costs associated with disease control. These are classified as primary losses.\nSecondary losses on the farm are indirect consequences of disease epidemics, such as the buildup of inoculum in the soil, which can lead to subsequent disease outbreaks. Other secondary impacts include the reduced efficacy of disease control methods due to the emergence of resistance to chemicals within the pathogen population over time.\nIn addition to these on-farm losses, plant diseases can have significant indirect impacts on society. These can include increased food prices due to reduced supply, loss of export markets due to trade restrictions, and environmental damage due to increased use of pesticides. Understanding the full spectrum of losses caused by plant diseases is critical for developing effective disease management strategies and policies.\n\n\n\nFigure 16.1: Tipology of losses caused by plant diseases\n\n\nThe famous epidemics in the ancient history, such as the late blight of potatoes, serve us as a remind of worst-case scenarios of major impact of epidemics causing both direct and indirect losses. However, crop losses due to diseases occur regularly and at levels that depend on the intensity of epidemics (Madden et al. 2017). Expert opinion estimates have indicated that around 20% (on average) of the yield of major crops like wheat, rice, maize, potato and soybean is lost due to the pests and pathogens globally (Savary et al. 2019)."
  },
  {
    "objectID": "yieldloss-concepts.html#crop-loss-assessment",
    "href": "yieldloss-concepts.html#crop-loss-assessment",
    "title": "16  Definitions and concepts",
    "section": "16.2 Crop loss assessment",
    "text": "16.2 Crop loss assessment\nAccording to Madden et al. (2017), knowledge about the disease:yield relationship falls within crop loss assessment, a general branch of epidemiology that study the relationship between the attack by harmful organisms and the resulting yield (or yield loss) of crops. In fact, the study (analysis and modeling) of crop losses is considered central to plant pathology as no plant protection scientific reasoning could be possible without a measure of crop loss (Savary et al. 2006).\nThe concept of yield levels is important to recognize as a framework to study crop losses. There are three levels (from higher to lower) of yield: theoretical, attainable and actual.\n\nTheoretical (also known as potential) yield is determined mainly by defining factors such as the genotype of the crop grown under ideal conditions. It can be obtained in experimental plots managed with high input of fertilizers and pesticides.\nAttainable yield is obtained in commercial crops managed with a full range of modern technology to maximize yield. It considers the presence of limiting factors such as water and fertilizers.\nActual yield is generally less than or equal to attainable yield, and is obtained under the effect of reducing factors such as those caused by pest (disease, insects, weeds) injuries - defined as measurable symptom caused by a harmful organism. It is the crop yield actually harvested in a farmer’s field.\n\nYield loss (expressed in absolute or relative terms) is the difference between the attainable and the actual yield. Yield loss studies are only possible when reliable field data are collected in sufficient number to allow the development of statistical (empirical) models as well as the validation of mechanistic simulation yield loss models.\n\n\nCode\nlibrary(tidyverse)\nyl &lt;- tibble::tribble(\n  ~yield, ~value, ~class,\n  \"Theoretical\", 25,1,\n  \"Attainable\", 20,2,\n  \"Actual\", 15,3,\n  \"\", 0, 4\n)\nyl |&gt; \n  ggplot(aes(reorder(yield,-value), value, fill = class))+\n  geom_col(width = 0.5)+\n  theme_minimal(base_size = 16)+\n  ggthemes::scale_fill_gradient_tableau()+\n  geom_hline(yintercept = 25, linetype = 2, color = \"gray60\")+\n  geom_hline(yintercept = 20, linetype = 2, color = \"gray60\")+\n  geom_hline(yintercept = 15, linetype = 2, color = \"gray60\")+\n  theme(legend.position = \"none\", \n        axis.text.y=element_blank(),\n        axis.ticks.x = element_blank())+\n  annotate(geom = \"text\", x = 1.8, y = 22, label =\"Defining factors \n           (genotype and environment)\")+\n  annotate(geom = \"text\", x = 2.8, y = 17.5, label =\"Limiting factors\n        (fertilizers, water)\")+\n  annotate(geom = \"text\", x = 3.8, y = 12, label =\"Reducing factors\n           (pest, weeds, diseases)\")+\n  annotate(\"segment\", x = 4, y = 20, xend = 4, yend = 15,\n         arrow = arrow(type = \"closed\", length = unit(0.02, \"npc\")))+\n  annotate(geom = \"text\", x = 4.3, y = 17, label =\"Yield loss\")+\n  labs(x = \"\", y = \"\")\n\n\n\n\n\nFigure 16.2: Yield levels"
  },
  {
    "objectID": "yieldloss-concepts.html#diseaseyield-data-and-graphs",
    "href": "yieldloss-concepts.html#diseaseyield-data-and-graphs",
    "title": "16  Definitions and concepts",
    "section": "16.3 Disease:yield data and graphs",
    "text": "16.3 Disease:yield data and graphs\nThe datasets utilized to characterize a disease-yield relationship should ideally encompass a broad spectrum of yield and disease values. There are primarily two approaches to acquiring such data: 1) conducting experiments in controlled environments such as fields or greenhouses; or 2) conducting surveys in commercial fields that are naturally infected.\nIn experimental setups, researchers rely on different treatments that are designed to result in varying disease epidemics, under the assumption that the disease has an impact on yield. These treatments often include manipulating the level of inoculum when the disease is expected to be minimal. This is achieved through inoculations with different amounts of the pathogen. Conversely, when the disease is expected to be severe, researchers might use fungicides at different rates, frequencies, or timings.\nAn alternative strategy is to use different host genotypes, preferably isolines or near-isolines, which exhibit varying degrees of susceptibility to the disease. Another method is to manipulate the environment, for example by altering the irrigation levels.\nIn any case, the relationship between a measure of yield (either absolute or relative) and the disease variable can be evaluated using scatter plots that depict a “damage curve” (Madden et al. 2017). The disease variable most commonly represents the assessment of the disease at a singular critical point. However, sometimes data obtained from multiple assessments throughout the disease epidemic is used to calculate the area under the disease progress curve, which is then used to represent the disease variable. This offers a more comprehensive view of the disease’s impact over time, and can better capture the complex relationships between disease progression and yield loss.\nLet’s work with actual data on the incidence of white mold disease and yield of soybean determined across different locations and years in Brazil (Lehner et al. 2016). The variation in disease and yield was obtained by applying different fungicides that varied in efficacy, thus resulting in variable final disease incidence. The data was made freely available in this repository and was included the the package that accompanies the book.\n\nlibrary(tidyverse)\ntheme_set(theme_bw(base_size = 16))\nlibrary(r4pde)\nwm &lt;- WhiteMoldSoybean\n\nglimpse(wm)\n\nRows: 382\nColumns: 17\n$ study           &lt;dbl&gt; 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 18, 18, 18, 18, 18…\n$ treat           &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5, …\n$ season          &lt;chr&gt; \"2009/2010\", \"2009/2010\", \"2009/2010\", \"2009/2010\", \"2…\n$ harvest_year    &lt;dbl&gt; 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, …\n$ location        &lt;chr&gt; \"Agua Fria\", \"Agua Fria\", \"Agua Fria\", \"Agua Fria\", \"A…\n$ state           &lt;chr&gt; \"GO\", \"GO\", \"GO\", \"GO\", \"GO\", \"GO\", \"GO\", \"GO\", \"GO\", …\n$ country         &lt;chr&gt; \"Brazil\", \"Brazil\", \"Brazil\", \"Brazil\", \"Brazil\", \"Bra…\n$ elevation       &lt;dbl&gt; 891, 891, 891, 891, 891, 891, 891, 891, 891, 891, 891,…\n$ region          &lt;chr&gt; \"Northern\", \"Northern\", \"Northern\", \"Northern\", \"North…\n$ elevation_class &lt;chr&gt; \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\"…\n$ inc_check       &lt;dbl&gt; 37.7, 37.7, 37.7, 37.7, 37.7, 37.7, 37.7, 37.7, 37.7, …\n$ inc_class       &lt;chr&gt; \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\"…\n$ yld_check       &lt;dbl&gt; 3729, 3729, 3729, 3729, 3729, 3729, 3729, 3729, 3729, …\n$ yld_class       &lt;chr&gt; \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\"…\n$ inc             &lt;dbl&gt; 37.7, 11.6, 33.5, 1.0, 5.6, 1.0, 3.7, 0.0, 1.1, 0.0, 3…\n$ scl             &lt;dbl&gt; 5092, 6154, 200, 180, 1123, 641, 1203, 521, 20, 0, 847…\n$ yld             &lt;dbl&gt; 3729, 3739, 3863, 3904, 4471, 4313, 4177, 4001, 4090, …\n\n\nAs seen above using glimpse() function, the full data set has 17 variables. Let’s reduce the data set to a few variables (study, inc and yld) and the trials number 1 to 4.\n\nwm2 &lt;- wm |&gt; \n  select(study, inc, yld) |&gt; \n  filter(study %in% c(1,2, 3, 4)) \nwm2\n\n# A tibble: 52 × 3\n   study   inc   yld\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1     1    76  2265\n 2     1    53  2618\n 3     1    42  2554\n 4     1    37  2632\n 5     1    29  2820\n 6     1    42  2799\n 7     1    55  2503\n 8     1    40  2967\n 9     1    26  2965\n10     1    18  3088\n# ℹ 42 more rows\n\n\nWe can now produce the damage curves for each study. As it can be seen, the relationship can be adequately described by a straight line.\n\nwm2 |&gt; \n  ggplot(aes(inc, yld, \n             group = study, \n             color = factor(study)))+\n  geom_point(size = 2)+\n  ggthemes::scale_color_colorblind()+\n  geom_smooth(method = \"lm\", se = F, color = \"black\", fullrange = T)+\n  ylim(1800, 3500)+\n  facet_wrap(~study)+\n  labs(x = \"White mold incidence (%)\",\n       y = \"Soybean yield (kg/ha)\",\n       color = \"Study\")\n\n\n\n\nFigure 16.3: Relationship between soybean yield and incidence of white mold in two experiments\n\n\n\n\nWe can plot the relationships for all studies combined, which will resemble a “spaghetti” plot after adding the individual regression lines.\n\np1 &lt;- wm |&gt; \n  ggplot(aes(inc, yld, group = study))+\n  geom_point(size = 2, alpha = 0.5)+\n  ylim(0, 5000)+\n  labs(x = \"White mold incidence (%)\",\n       y = \"Soybean yield (kg/ha)\")\n\np2 &lt;- wm |&gt; \n  ggplot(aes(inc, yld, group = study))+\n  geom_smooth(method = \"lm\", se = F, fullrange = T, color = \"black\")+\n  ylim(0, 5000)+\n  labs(x = \"White mold incidence (%)\",\n       y = \"Soybean yield (kg/ha)\")\n\nlibrary(patchwork)\np1 | p2\n\n\n\n\nFigure 16.4: Relationship between soybean yield and incidence of white mold across trials. Observed (left) and fitted regression lines (right)\n\n\n\n\n\n\n\n\nLehner, M. S., Pethybridge, S. J., Meyer, M. C., and Del Ponte, E. M. 2016. Meta-analytic modelling of the incidenceyield and incidencesclerotial production relationships in soybean white mould epidemics. Plant Pathology. 66:460–468 Available at: http://dx.doi.org/10.1111/ppa.12590.\n\n\nMadden, L. V., Hughes, G., and Bosch, F. van den, eds. 2017. CHAPTER 12: Epidemics and crop yield. In The American Phytopathological Society, p. 353–388. Available at: http://dx.doi.org/10.1094/9780890545058.012.\n\n\nSavary, S., Teng, P. S., Willocquet, L., and Nutter, F. W. 2006. Quantification and Modeling of Crop Losses: A Review of Purposes. Annual Review of Phytopathology. 44:89–112 Available at: http://dx.doi.org/10.1146/annurev.phyto.44.070505.143342.\n\n\nSavary, S., Willocquet, L., Pethybridge, S. J., Esker, P., McRoberts, N., and Nelson, A. 2019. The global burden of pathogens and pests on major food crops. Nature Ecology & Evolution. 3:430–439 Available at: http://dx.doi.org/10.1038/s41559-018-0793-y."
  },
  {
    "objectID": "yieldloss-regression-models.html",
    "href": "yieldloss-regression-models.html",
    "title": "17  Statistical models",
    "section": "",
    "text": "This is a work in progress that is currently undergoing heavy technical editing and copy-editing\n\n\n\n\nlibrary(tidyverse)\ntheme_set(theme_bw(base_size = 16))\nwm &lt;- read_csv(\"https://raw.githubusercontent.com/emdelponte/paper-white-mold-meta-analysis/gh-pages/dat-white-mold-br.csv\")\n\n\nwm1 &lt;- wm |&gt; \n  select(study, inc, yld) |&gt; \n  filter(study %in% c(1)) \nwm1\n\n# A tibble: 13 × 3\n   study   inc   yld\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1     1    76  2265\n 2     1    53  2618\n 3     1    42  2554\n 4     1    37  2632\n 5     1    29  2820\n 6     1    42  2799\n 7     1    55  2503\n 8     1    40  2967\n 9     1    26  2965\n10     1    18  3088\n11     1    27  3044\n12     1    28  2925\n13     1    36  2867\n\n\n\nwm1 |&gt; \n  ggplot(aes(inc, yld))+\n  geom_point(size = 2)+\n  geom_smooth(method = \"lm\", se = F, color = \"black\", fullrange = T)+\n  ylim(1800, 3500)+\n  labs(x = \"White mold incidence (%)\",\n       y = \"Soybean yield (kg/ha)\",\n       color = \"Study\")\n\n\n\n\nFitting a linear regression model\n\nlm1 &lt;-  lm(yld ~ inc, data = wm1) \nsummary(lm1)\n\n\nCall:\nlm(formula = yld ~ inc, data = wm1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-178.41  -44.70   14.60   49.34  206.18 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 3329.142     86.844  38.335 4.60e-13 ***\ninc          -14.208      2.076  -6.845 2.78e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 110.4 on 11 degrees of freedom\nMultiple R-squared:  0.8099,    Adjusted R-squared:  0.7926 \nF-statistic: 46.86 on 1 and 11 DF,  p-value: 2.782e-05\n\n\nThe damage curves can be expressed in relative terms. For this, we divide the slope by the intercept and multiply by 100.\n\nslope &lt;- -14.2/3329.14*100\nx = seq(0,1,0.1)\ny = seq(0,1,0.1)\ndat &lt;- data.frame(x,y)\ndat |&gt; \n  ggplot(aes(x,y))+\n  geom_point(color = \"white\")+  \n  geom_abline(aes(intercept = 1, slope = slope))"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Agrios, G. N. 2005a. INTRODUCTION. In Elsevier, p. 3–75. Available at:\nhttp://dx.doi.org/10.1016/b978-0-08-047378-9.50007-5.\n\n\nAgrios, G. N. 2005b. Plant disease epidemiology. In Elsevier, p.\n265–291. Available at: http://dx.doi.org/10.1016/b978-0-08-047378-9.50014-2.\n\n\nAlves, K. S., Guimarães, M., Ascari, J. P., Queiroz, M. F., Alfenas, R.\nF., Mizubuti, E. S. G., et al. 2021. RGB-based phenotyping of foliar\ndisease severity under controlled conditions. Tropical Plant Pathology.\n47:105–117 Available at: http://dx.doi.org/10.1007/S40858-021-00448-Y.\n\n\nBaddeley, A., Diggle, P. J., Hardegen, A., Lawrence, T., Milne, R. K.,\nand Nair, G. 2014. On tests of spatial pattern based on simulation\nenvelopes. Ecological Monographs. 84:477–489 Available at: http://dx.doi.org/10.1890/13-2042.1.\n\n\nBaddeley, A., Turner, R., Moller, J., and Hazelton, M. 2005. Residual\nanalysis for spatial point processes (with discussion). Journal of the\nRoyal Statistical Society: Series B (Statistical Methodology).\n67:617–666 Available at: http://dx.doi.org/10.1111/j.1467-9868.2005.00519.x.\n\n\nBarnhart, H. X., Haber, M., and Song, J. 2002. Overall Concordance\nCorrelation Coefficient for Evaluating Agreement Among Multiple\nObservers. Biometrics. 58:1020–1027 Available at: http://dx.doi.org/10.1111/j.0006-341x.2002.01020.x.\n\n\nBock, C. H., Chiang, K.-S., and Del Ponte, E. M. 2021a. Plant disease\nseverity estimated visually: a century of research, best practices, and\nopportunities for improving methods and practices to maximize accuracy.\nTropical Plant Pathology. 47:25–42 Available at: http://dx.doi.org/10.1007/s40858-021-00439-z.\n\n\nBock, C. H., Pethybridge, S. J., Barbedo, J. G. A., Esker, P. D.,\nMahlein, A.-K., and Del Ponte, E. M. 2021b. A phytopathometry glossary\nfor the twenty-first century: towards consistency and precision in\nintra- and inter-disciplinary dialogues. Tropical Plant Pathology.\n47:14–24 Available at: http://dx.doi.org/10.1007/s40858-021-00454-0.\n\n\nBrooks, M. E., Kristensen, K., van Benthem, K. J., Magnusson, A., Berg,\nC. W., Nielsen, A., et al. 2017. glmmTMB balances speed and flexibility among\npackages for zero-inflated generalized linear mixed modeling. The R\nJournal. 9:378–400.\n\n\nBrown, V. A. 2021. An Introduction to Linear Mixed-Effects Modeling in\nR. Advances in Methods and Practices in Psychological Science.\n4:251524592096035 Available at: http://dx.doi.org/10.1177/2515245920960351.\n\n\nCampbell, C. L., and Madden. L., V. 1990. Introduction to plant\ndisease epidemiology. Wiley.\n\n\nChester, K. S. 1950. Plant disease losses : Their appraisal and\ninterpretation /. Available at: http://dx.doi.org/10.5962/bhl.title.86198.\n\n\nChiang, K.-S., and Bock, C. H. 2021. Understanding the ramifications of\nquantitative ordinal scales on accuracy of estimates of disease severity\nand data analysis in plant pathology. Tropical Plant Pathology. 47:58–73\nAvailable at: http://dx.doi.org/10.1007/s40858-021-00446-0.\n\n\nChiang, K.-S., Liu, S.-C., Bock, C. H., and Gottwald, T. R. 2014. What\nInterval Characteristics Make a Good Categorical Disease Assessment\nScale? Phytopathology®. 104:575–585 Available at: http://dx.doi.org/10.1094/phyto-10-13-0279-r.\n\n\nCruz, C. D., and Valent, B. 2017. Wheat blast disease: danger on the\nmove. Tropical Plant Pathology. 42:210–222 Available at: http://dx.doi.org/10.1007/s40858-017-0159-z.\n\n\nDel Ponte, E. M., Cazón, L. I., Alves, K. S., Pethybridge, S. J., and\nBock, C. H. 2022. How much do standard area diagrams improve accuracy of\nvisual estimates of the percentage area diseased? A systematic review\nand meta-analysis. Tropical Plant Pathology. 47:43–57 Available at: http://dx.doi.org/10.1007/s40858-021-00479-5.\n\n\nDel Ponte, E. M., Pethybridge, S. J., Bock, C. H., Michereff, S. J.,\nMachado, F. J., and Spolti, P. 2017. Standard Area Diagrams for Aiding\nSeverity Estimation: Scientometrics, Pathosystems, and Methodological\nTrends in the Last 25 Years. Phytopathology®. 107:1161–1174 Available\nat: http://dx.doi.org/10.1094/PHYTO-02-17-0069-FI.\n\n\nDuffeck, M. R., Santos Alves, K. dos, Machado, F. J., Esker, P. D., and\nDel Ponte, E. M. 2020. Modeling Yield Losses and Fungicide Profitability\nfor Managing Fusarium Head Blight in Brazilian Spring Wheat.\nPhytopathology®. 110:370–378 Available at: http://dx.doi.org/10.1094/PHYTO-04-19-0122-R.\n\n\nEsser, D. S., Leveau, J. H. J., Meyer, K. M., and Wiegand, K. 2014.\nSpatial scales of interactions among bacteria and between bacteria and\nthe leaf surface. FEMS Microbiology Ecology. 91 Available at: http://dx.doi.org/10.1093/femsec/fiu034.\n\n\nFranceschi, V. T., Alves, K. S., Mazaro, S. M., Godoy, C. V., Duarte, H.\nS. S., and Del Ponte, E. M. 2020. A new standard area diagram set for\nassessment of severity of soybean rust improves accuracy of estimates\nand optimizes resource use. Plant Pathology. 69:495–505 Available at: http://dx.doi.org/10.1111/ppa.13148.\n\n\nFrancl, L. J. 2001. The..disease triangle: A plant pathological paradigm\nrevisited. The Plant Health Instructor. Available at: http://dx.doi.org/10.1094/PHI-T-2001-0517-01.\n\n\nGigot, C. 2018. Epiphy: Analysis of plant disease epidemics.\n\n\nGodoy, C. V., Seixas, C. D. S., Soares, R. M., Marcelino-Guimarães, F.\nC., Meyer, M. C., and Costamilan, L. M. 2016. Asian soybean rust in\nbrazil: Past, present, and future. Pesquisa Agropecuária Brasileira.\n51:407–421 Available at: http://dx.doi.org/10.1590/S0100-204X2016000500002.\n\n\nGonzález-Domínguez, E., Martins, R. B., Del Ponte, E. M., Michereff, S.\nJ., García-Jiménez, J., and Armengol, J. 2014. Development and\nvalidation of a standard area diagram set to aid assessment of severity\nof loquat scab on fruit. European Journal of Plant Pathology. Available\nat: http://dx.doi.org/10.1007/s10658-014-0400-2.\n\n\nHebert, T. T. 1982. The rationale for the horsfall-barratt plant disease\nassessment scale. Phytopathology. 72:1269 Available at: http://dx.doi.org/10.1094/phyto-72-1269.\n\n\nIslam, M. T., Kim, K.-H., and Choi, J. 2019. Wheat Blast in Bangladesh:\nThe Current Situation and Future Impacts. The Plant Pathology Journal.\n35:1–10 Available at: http://dx.doi.org/10.5423/ppj.rw.08.2018.0168.\n\n\nJeger, M. J., and Viljanen-Rollinson, S. L. H. 2001. The use of the area\nunder the disease-progress curve (AUDPC) to assess quantitative disease\nresistance in crop cultivars. Theoretical and Applied Genetics.\n102:32–40 Available at: http://dx.doi.org/10.1007/s001220051615.\n\n\nJesus Junior, W. C. de, and Bassanezi, R. B. 2004. Análise da dinâmica e\nestrutura de focos da morte súbita dos citros. Fitopatologia Brasileira.\n29:399–405 Available at: http://dx.doi.org/10.1590/S0100-41582004000400007.\n\n\nLaranjeira, F. F., Bergamin Filho, A. R., and Amorim, L. I. 1998.\nDinâmica e estrutura de focos da clorose variegada dos\ncitros (CVC). Fitopatologia Brasileira. 23:36–41.\n\n\nLaranjeira, F. F., Bergamin Filho, A., Amorim, L., and Gottwald, T. R.\n2004. Dinâmica espacial da clorose variegada dos citros em três regiões\ndo estado de são paulo. Fitopatologia Brasileira. 29:56–65 Available at:\nhttp://dx.doi.org/10.1590/S0100-41582004000100009.\n\n\nLehner, M. S., Pethybridge, S. J., Meyer, M. C., and Del Ponte, E. M.\n2016. Meta-analytic modelling of the\nincidenceyield and incidencesclerotial\nproduction relationships in soybean white mould epidemics. Plant\nPathology. 66:460–468 Available at: http://dx.doi.org/10.1111/ppa.12590.\n\n\nLi, B., Madden, L. V., and Xu, X. 2011. Spatial analysis by distance\nindices: an alternative local clustering index for studying spatial\npatterns. Methods in Ecology and Evolution. 3:368–377 Available at: http://dx.doi.org/10.1111/j.2041-210x.2011.00165.x.\n\n\nLi, F., Upadhyaya, N. M., Sperschneider, J., Matny, O., Nguyen-Phuc, H.,\nMago, R., et al. 2019. Emergence of the Ug99 lineage of the wheat stem\nrust pathogen through somatic hybridisation. Nature Communications. 10\nAvailable at: http://dx.doi.org/10.1038/s41467-019-12927-7.\n\n\nLin, L. I.-K. 1989. A concordance correlation coefficient to evaluate\nreproducibility. Biometrics. 45:255 Available at: http://dx.doi.org/10.2307/2532051.\n\n\nLiu, H. I., Tsai, J. R., Chung, W. H., Bock, C. H., and Chiang, K. S.\n2019. Effects of Quantitative Ordinal Scale Design on the Accuracy of\nEstimates of Mean Disease Severity. Agronomy. 9:565 Available at: http://dx.doi.org/10.3390/agronomy9090565.\n\n\nMadden, L. V., Esker, P. D., and Pethybridge, S. J. 2021. Forrest W.\nNutter, Jr.: a career in phytopathometry. Tropical Plant Pathology.\n47:5–13 Available at: http://dx.doi.org/10.1007/s40858-021-00469-7.\n\n\nMadden, L. V., Hughes, G., and Bosch, F. van den, eds. 2017a. CHAPTER\n12: Epidemics and crop yield. In The American Phytopathological Society,\np. 353–388. Available at: http://dx.doi.org/10.1094/9780890545058.012.\n\n\nMadden, L. V., Hughes, G., and van den Bosch, F. 2017b. Spatial aspects\nof epidemicsIII: Patterns of plant disease. In The American\nPhytopathological Society, p. 235–278. Available at: http://dx.doi.org/10.1094/9780890545058.009.\n\n\nMadden, L. V., Hughes, G., and van den Bosch, F. 2017c. Temporal\nanalysis i: Quantifying and comparing epidemics. In The American\nPhytopathological Society, p. 63–116. Available at: http://dx.doi.org/10.1094/9780890545058.004.\n\n\nMadden, L. V., Hughes, G., and van den Bosch, F. 2017d. The study of\nplant disease epidemics. The American Phytopathological Society.\nAvailable at: http://dx.doi.org/10.1094/9780890545058.\n\n\nMalaker, P. K., Barma, N. C. D., Tiwari, T. P., Collis, W. J.,\nDuveiller, E., Singh, P. K., et al. 2016. First Report of Wheat Blast\nCaused by Magnaporthe oryzae Pathotype\ntriticum in Bangladesh. Plant Disease.\n100:2330–2330 Available at: http://dx.doi.org/10.1094/pdis-05-16-0666-pdn.\n\n\nMikaberidze, A., Mundt, C. C., and Bonhoeffer, S. 2015. Data from:\nInvasiveness of plant pathogens depends on the spatial scale of host\ndistribution. Available at: http://datadryad.org/stash/dataset/doi:10.5061/dryad.f2j8s.\n\n\nMoran, P. A. P. 1950. Notes on\ncontinuous stochastic phenomena. Biometrika. 37:17.\n\n\nMoreira, R. R., Silva Silveira Duarte, H. da, and De Mio, L. L. M. 2018.\nImproving accuracy, precision and reliability of severity estimates of\nGlomerella leaf spot on apple leaves using a new standard area diagram\nset. European Journal of Plant Pathology. 153:975–982 Available at: http://dx.doi.org/10.1007/s10658-018-01610-0.\n\n\nMundt, C. C., Ahmed, H. U., Finckh, M. R., Nieva, L. P., and Alfonso, R.\nF. 1999. Primary Disease Gradients of Bacterial Blight of Rice.\nPhytopathology®. 89:64–67 Available at: http://dx.doi.org/10.1094/phyto.1999.89.1.64.\n\n\nNelson, S. C. 1996. A simple analysis of disease foci. Phytopathology.\n86:432–439.\n\n\nNutter, F. W., and Esker, P. D. 2006. The Role of Psychophysics in\nPhytopathology: The WeberFechner Law Revisited. European\nJournal of Plant Pathology. 114:199–213 Available at: http://dx.doi.org/10.1007/s10658-005-4732-9.\n\n\nNutter, F. W., Esker, P. D., and Netto, R. A. C. 2006. Disease\nAssessment Concepts and the Advancements Made in Improving the Accuracy\nand Precision of Plant Disease Data. European Journal of Plant\nPathology. 115:95–103 Available at: http://dx.doi.org/10.1007/s10658-005-1230-z.\n\n\nOlivoto, T. 2022. Lights, camera, pliman! An R package for plant image\nanalysis. Methods in Ecology and Evolution. 13:789–798 Available at: http://dx.doi.org/10.1111/2041-210X.13803.\n\n\nOlivoto, T., Andrade, S. M. P., and M. Del Ponte, E. 2022. Measuring\nplant disease severity in R: introducing and evaluating the pliman\npackage. Tropical Plant Pathology. 47:95–104 Available at: http://dx.doi.org/10.1007/s40858-021-00487-5.\n\n\nParker, S. K., Nutter, F. W., and Gleason, M. L. 1997. Directional\nSpread of Septoria Leaf Spot in Tomato Rows. Plant Disease. 81:272–276\nAvailable at: http://dx.doi.org/10.1094/pdis.1997.81.3.272.\n\n\nPereira, W. E. L., Andrade, S. M. P. de, Del Ponte, E. M., Esteves, M.\nB., Canale, M. C., Takita, M. A., et al. 2020. Severity assessment in\nthe Nicotiana tabacum-Xylella fastidiosa subsp. pauca pathosystem:\ndesign and interlaboratory validation of a standard area diagram set.\nTropical Plant Pathology. 45:710–722 Available at: http://dx.doi.org/10.1007/s40858-020-00401-5.\n\n\nSackett, K. E., and Mundt, C. C. 2005. Primary Disease Gradients of\nWheat Stripe Rust in Large Field Plots. Phytopathology®. 95:983–991\nAvailable at: http://dx.doi.org/10.1094/PHYTO-95-0983.\n\n\nSavary, S., Teng, P. S., Willocquet, L., and Nutter, F. W. 2006.\nQuantification and Modeling of Crop Losses: A Review of Purposes. Annual\nReview of Phytopathology. 44:89–112 Available at: http://dx.doi.org/10.1146/annurev.phyto.44.070505.143342.\n\n\nSavary, S., Willocquet, L., Pethybridge, S. J., Esker, P., McRoberts,\nN., and Nelson, A. 2019. The global burden of pathogens and pests on\nmajor food crops. Nature Ecology & Evolution. 3:430–439 Available\nat: http://dx.doi.org/10.1038/s41559-018-0793-y.\n\n\nScott, P. R., and Hollins, T. W. 1974. Effects of eyespot on the yield\nof winter wheat. Annals of Applied Biology. 78:269–279 Available at: http://dx.doi.org/10.1111/j.1744-7348.1974.tb01506.x.\n\n\nShrout, P. E., and Fleiss, J. L. 1979. Intraclass correlations: Uses in\nassessing rater reliability. Psychological Bulletin. 86:420–428\nAvailable at: http://dx.doi.org/10.1037/0033-2909.86.2.420.\n\n\nSimko, I., and Piepho, H.-P. 2012. The Area Under the Disease Progress\nStairs: Calculation, Advantage, and Application. Phytopathology®.\n102:381–389 Available at: http://dx.doi.org/10.1094/phyto-07-11-0216.\n\n\nTembo, B., Mulenga, R. M., Sichilima, S., M’siska, K. K., Mwale, M.,\nChikoti, P. C., et al. 2020. Detection and characterization of fungus\n(Magnaporthe oryzae pathotype Triticum) causing wheat blast disease on\nrain-fed grown wheat (Triticum aestivum L.) in Zambia ed. Zonghua Wang.\nPLOS ONE. 15:e0238724 Available at: http://dx.doi.org/10.1371/journal.pone.0238724.\n\n\nThresh, J. M. 1998. In memory of James Edward Vanderplank\n19091997. Plant Pathology. 47:114–115 Available at: http://dx.doi.org/10.1046/j.1365-3059.2998.00220.x.\n\n\nVanderplank, J. 1963. Plant disease epidemics and control.\nElsevier. Available at: http://dx.doi.org/10.1016/C2013-0-11642-X.\n\n\nWiegand, T., and A. Moloney, K. 2004. Rings, circles, and null-models\nfor point pattern analysis in ecology. Oikos. 104:209–229 Available at:\nhttp://dx.doi.org/10.1111/j.0030-1299.2004.12497.x.\n\n\nXu, X.-M., and Madden, L. V. 2004. Use of SADIE statistics\nto study spatial dynamics of plant disease epidemics. Plant Pathology.\n53:38–49 Available at: http://dx.doi.org/10.1111/j.1365-3059.2004.00949.x.\n\n\nYadav, N. V. S., Vos, S. M. de, Bock, C. H., and Wood, B. W. 2012.\nDevelopment and validation of standard area diagrams to aid assessment\nof pecan scab symptoms on fruit. Plant Pathology. 62:325–335 Available\nat: http://dx.doi.org/10.1111/j.1365-3059.2012.02641.x.\n\n\nYorinori, J. T., Paiva, W. M., Frederick, R. D., Costamilan, L. M.,\nBertagnolli, P. F., Hartman, G. E., et al. 2005. Epidemics of Soybean\nRust (Phakopsora pachyrhizi) in Brazil and\nParaguay from 2001 to 2003. Plant Disease. 89:675–677 Available at: http://dx.doi.org/10.1094/PD-89-0675.\n\n\nZadoks, J. C., and Schein, R. D. 1988. James Edward Vanderplank:\nMaverick* and Innovator. Annual Review of Phytopathology. 26:31–37\nAvailable at: http://dx.doi.org/10.1146/annurev.py.26.090188.000335."
  }
]